% Based on http://nbviewer.jupyter.org/github/ipython/nbconvert-examples/blob/master/citations/Tutorial.ipynb , authored by Brian E. Granger
    % Declare the document class
    \documentclass[landscape,letterpaper,10pt,english]{article}


    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{GR-07}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
% Start the section counter at -1, so the Table of Contents is Section 0
   \setcounter{section}{-2}
% Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }

    % Slightly bigger margins than the latex defaults
    \geometry{verbose,tmargin=0.5in,bmargin=0.5in,lmargin=0.5in,rmargin=0.5in}


\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{general-relativity-problems-chapter-7-physics-in-a-curved-spacetime}{%
\section{General Relativity Problems Chapter 7: Physics in a Curved
Spacetime}\label{general-relativity-problems-chapter-7-physics-in-a-curved-spacetime}}

\hypertarget{authors-gabriel-m-steward}{%
\subsection{Authors: Gabriel M
Steward}\label{authors-gabriel-m-steward}}

    https://github.com/zachetienne/nrpytutorial/blob/master/Tutorial-Template\_Style\_Guide.ipynb

Link to the Style Guide. Not internal in case something breaks.

    \hypertarget{nrpy-source-code-for-this-module}{%
\subsubsection{\texorpdfstring{ NRPy+ Source Code for this
module:}{ NRPy+ Source Code for this module:}}\label{nrpy-source-code-for-this-module}}

None!

\hypertarget{introduction}{%
\subsection{Introduction:}\label{introduction}}

Now maybe we can apply what we've learned to some actual physical
problems. Maybe. One can hope.

\hypertarget{other-optional}{%
\subsection{\texorpdfstring{ Other
(Optional):}{ Other (Optional):}}\label{other-optional}}

Placeholder.

\hypertarget{note-on-notation}{%
\subsubsection{Note on Notation:}\label{note-on-notation}}

Any new notation will be brought up in the notebook when it becomes
relevant.

\hypertarget{citations}{%
\subsubsection{Citations:}\label{citations}}

{[}1{]} (Link) (Placeholder)

    \hypertarget{table-of-contents}{%
\section{Table of Contents}\label{table-of-contents}}

\[\label{toc}\]

\hyperref[p1]{Problem 1} (What are Manifolds?)

\hyperref[latex_pdf_output]{PDF} (turn this into a PDF)

    \hypertarget{problem-1-back-to-top}{%
\section{\texorpdfstring{Problem 1 {[}Back to
\hyperref[toc]{top}{]}}{Problem 1 {[}Back to {]}}}\label{problem-1-back-to-top}}

\[\label{P1}\]

\emph{Decide if the following sets are manifolds and say why. If there
are any exceptional points at which the sets are not manifolds, give
them:}

\emph{a) Phase space of Hamiltonian mechanics, the space of the
canonical coordinates and momenta \(p_i\) and \(q^i\)}

    \emph{b) Use this to establish 6.64}

    6.64:
\(\Gamma^\alpha_{\mu\nu,\sigma} = \frac12 g^{\alpha\beta} \left( g_{\beta\mu,\nu\sigma} + g_{\beta\nu,\mu\sigma} - g_{\mu\nu,\beta\sigma} \right)\)

    Okay so we have, in general:

\[ \nabla_\beta g_{\mu\nu} = g_{\mu\nu,\beta} - g_{\alpha\nu}\Gamma^\alpha_{\mu\beta} - g_{\mu\alpha}\Gamma^\alpha_{\mu\beta} = 0 \]

and

\[\frac{1}{2} g^{\alpha\gamma} (g_{\alpha\beta,\mu} + g_{\alpha\mu,\beta} - g_{\beta\mu,\alpha}) =\Gamma^\gamma_{\beta\mu}\]

    Adjust indeces and take the derivative.

\[\frac{1}{2} g^{\iota\alpha} (g_{\iota\mu,\nu} + g_{\iota\nu,\mu} - g_{\mu\nu,\iota}) =\Gamma^\alpha_{\mu\nu}\]

\[\frac{1}{2} \left[ g^{\iota\alpha} (g_{\iota\mu,\nu} + g_{\iota\nu,\mu} - g_{\mu\nu,\iota}) \right]_{,\sigma} =\Gamma^\alpha_{\mu\nu,\sigma}\]

    So what follows is simpler than it sounds. We use the product rule on
the stuff in the middle. Now, if we are evaluating at P, then one might
think the three terms in the middle go to zero. They would, if we
weren't differentiating. But once we differentiate the g on the outside
becomes a single derivative, and IT goes to zero, leaving only the other
side of the product rule behind.

\[\frac{1}{2}  g^{\iota\alpha} (g_{\iota\mu,\nu\sigma} + g_{\iota\nu,\mu\sigma} - g_{\mu\nu,\iota\sigma})  =\Gamma^\alpha_{\mu\nu,\sigma}\]

Which is equivalent to what we sought to show.

    \emph{c) Fill in the steps needed to establish 6.68.}

    6.68 is the full tensor:

\[ R_{\alpha\beta\mu\nu} = g_{\alpha\lambda}R^\lambda_{\beta\mu\nu} = \frac12 (g_{\alpha\nu,\beta\mu} - g_{\alpha\mu,\beta\nu} + g_{\beta\mu,\alpha\nu} - g_{\beta\nu,\alpha\mu}) \]

    From 6.63 we have

\[ R^\lambda_{\beta\mu\nu} = \Gamma^\gamma_{\beta\nu,\mu} - \Gamma^\gamma_{\beta\mu,\nu} + \Gamma^\gamma_{\sigma\nu} \Gamma^\sigma_{\mu\beta} - \Gamma^\gamma_{\sigma\beta} \Gamma^\sigma_{\mu\nu}  \]

    \[ \Gamma^\alpha_{\mu\nu,\sigma}  = \frac12 g^{\alpha\beta} \left( g_{\beta\mu,\nu\sigma} + g_{\beta\nu,\mu\sigma} - g_{\mu\nu,\beta\sigma} \right) \]

\[\frac{1}{2} g^{\alpha\gamma} (g_{\alpha\beta,\mu} + g_{\alpha\mu,\beta} - g_{\beta\mu,\alpha}) =\Gamma^\gamma_{\beta\mu}\]

    This is clearly an exercise in algebra. So let's DO THIS!

\[ R^\lambda_{\beta\mu\nu} = \frac12 g^{\gamma\iota} \left( g_{\iota\beta,\nu\mu} + g_{\iota\nu,\beta\mu} - g_{\beta\nu,\iota\mu} \right) -  \frac12 g^{\gamma\iota} \left( g_{\iota\beta,\mu\nu} + g_{\iota\mu,\beta\nu} - g_{\beta\mu,\iota\nu} \right) + \frac{1}{2} g^{\alpha\gamma} (g_{\alpha\sigma,\nu} + g_{\alpha\nu,\sigma} - g_{\sigma\nu,\alpha})\frac{1}{2} g^{\alpha\sigma} (g_{\alpha\mu,\beta} + g_{\alpha\beta,\mu} - g_{\mu\beta,\alpha}) - \frac{1}{2} g^{\alpha\gamma} (g_{\alpha\sigma,\beta} + g_{\alpha\beta,\sigma} - g_{\sigma\beta,\alpha})\frac{1}{2} g^{\alpha\sigma} (g_{\alpha\mu,\nu} + g_{\alpha\nu,\mu} - g_{\mu\nu,\alpha})  \]

    Remember derivatives can be taken in any order, so flipped bottom
indeces will cancel.

\[ R^\lambda_{\beta\mu\nu} = \frac12 g^{\gamma\iota} \left( g_{\iota\nu,\beta\mu} - g_{\iota\mu,\beta\nu} + g_{\beta\mu,\iota\nu} - g_{\beta\nu,\iota\mu}  \right) + \frac{1}{2} g^{\alpha\gamma} (g_{\alpha\sigma,\nu} + g_{\alpha\nu,\sigma} - g_{\sigma\nu,\alpha})\frac{1}{2} g^{\alpha\sigma} (g_{\alpha\mu,\beta} + g_{\alpha\beta,\mu} - g_{\mu\beta,\alpha}) - \frac{1}{2} g^{\alpha\gamma} (g_{\alpha\sigma,\beta} + g_{\alpha\beta,\sigma} - g_{\sigma\beta,\alpha})\frac{1}{2} g^{\alpha\sigma} (g_{\alpha\mu,\nu} + g_{\alpha\nu,\mu} - g_{\mu\nu,\alpha})  \]

    So obviously the leading term is what we want, which means all the other
terms better cancel. But do they? Yes. Re-index \(\beta\nu\) and they
automatically cancel, becoming:

\[ R^\lambda_{\beta\mu\nu} = \frac12 g^{\gamma\iota} \left( g_{\iota\nu,\beta\mu} - g_{\iota\mu,\beta\nu} + g_{\beta\mu,\iota\nu} - g_{\beta\nu,\iota\mu}  \right) \]

Which if \(\iota\alpha\) is adjusted, will cancel with the other
multiplied metric, giving us the R we wanted to show at the start. Done.

    \hypertarget{problem-18-back-to-top}{%
\section{\texorpdfstring{Problem 18 {[}Back to
\hyperref[toc]{top}{]}}{Problem 18 {[}Back to {]}}}\label{problem-18-back-to-top}}

\[\label{P18}\]

\emph{a) Derive 6.69 and 6.70 from 6.68}

Annoying to type out; these are just the symmetries of the Modified
Reimann Curvature Tensor.

6.69 points out that swapping the first two and last two indecies makes
the result negative, while there is a true symmetry from swapping 13 and
24.

6.70 states that the tensor in form 1234 plus itself in form 1423 and
1342 produces zero. not sure why this is useful but it's true.

    \emph{b) Show that 6.69 reduces the number of independent components of
\(R_{\alpha\beta\mu\nu}\) from 4x4x4x4 = 256 to 6x7/2 = 21. Hint: treat
pairs of indices. Calculate how many independent choices of pairs there
are for the first and second pairs of \(R_{\alpha\beta\mu\nu}\)}

    Okay so unlike our previous problems, this one's a 4D cube. Hard to
imagine the 4D cube and how its symmetries work. The best thing we can
note is that we have four numbers and four indeces: 0123.

Assumign only 6.69 is true, that is, the four-way identity relations, we
find numbers that are equal or opposite.

First of all, we need to recognize that R is \textbf{antisymmetric} and
as such the diagonals are all zero and irrelevant. This means 1111 2222
3333 and 4444 are all just zero. From \hyperref[6]{6} we also know that
having even half of the components the same, such as in 0011, also
equals zero. Why?

Well it becomes evident that we don't actually know what antisymmetry in
higher dimensions MEANS. However, its clear that the relation 6.69
contains the information: if it transforms something into the negative
of itself, it MUST be zero. Let's find all of these. There are a lot of
them.

First of all, anything composed of same-pairs has to be zero. 00, 11,
22, 33, etc. This removes a total of sixteen numbers (including the ones
where all four are the same).

However, what of things of the form xxyz? These and their
transformations also all have to be zero, since one of the transforms in
6.69 shuffles only the first pair, so all other combinations therein
must be lost.

xxyz, xxzy are automatically zero. So is yzxx but that's true due to
another reason so we don't need to count it twice.

So every number which so much as contains a direct pair is toast.
Counting only numbers with ONE pair in the first location, gives us six
more zeroes for each pair, so six times four is 24. these are completely
separate from the 16 before.

We also grab 24 from the second pair.

24+24+16 = 64. There are 64 zeroes in the matrix, which are simply not
counted at all. This still leaves 192 potential values.

    The cases of indeces with only one number in them are already proven to
be zero.

What about cases with only two? Well, anything of xxxy, xyyy, xxyy form
is automatically zero, but what of xyxy or xyyx?

xyxy = -yxxy = -xyyx = xyxy

These are perfectly safe, no self-equalizations here. But keep in mind
each result of the identity can also be acted upon as well, meaning:

yxxy = -xyxy = -yxyx = xyyx yxyx = -xyyx = -yxxy = yxyx xyyx = -yxyx =
-xyxy = yxxy

There are, in this shuffle, four numbers. So every unique combination of
two different indeces will consume 4 indeces. There are six of these:
01, 02, 03, 12, 13, 23. So we have (+6) independent values (finally,
we're not at zero!) and we reduce hte total number of elements we are
considering by 24 again, leaving us 168.

The consideration of three indeces is complicated, four is actually much
easier.

(Forgive us for not using zero here, we wrote this part first)

So all posisble combinations of four different numbers will be divided
by 4\ldots{} 4 times 3 times 2 times 1 divided by 4, or just 6
independent values. Or that's what you'd THINK, but no, each of the
values here can also twist into even more values with a sort of
cascading effect of crazyness! We can apply the cycle again and again
and again, oh boy! So instead of four numbers, we get quite a bit more.
Start with 1234, 2134, 1243, 3412\ldots{} and then apply it all to 2134!
(and then the others) see how many we get!

1234, 2134, 1243, 3412

\textbf{2134}, \textbf{1234}, 2143, 4321

\textbf{1243}, \textbf{2143}, \textbf{1234}, 4312

\textbf{3412}, \textbf{4312}, 3421, \textbf{1234}

And the last one only produces things that already exist. But wait, NOW
we have to check the new numbers and see what they produce! But that's
it, there are only 8. This could even have been reasoned out: we either
swap the first two, swap the last two, or swap the locations of the
first and last two, of course there are only eight combinations.

For the 4-number combinations, we have 4 times 3 times 2 times 1 divided
by 8 is just 3. (+3) to the total, giving us 9 total, and now we only
have 144 values left to consider.

Which now\ldots{} is only the three-index-case.

    We already know that all dual-indeces are zero, so we only concern
ourselves with non-dual-indeces:, which by nature have to take the forms
xyyz, xyzy, yxyz, yxzy. We suspect that each individual one is goign to
give us all four options, but let's try it out:

xyyz = -yxyz = -xyzy = yzxy yxyz = -xyyz = -yxzy = yzyx xyzy = -yxzy =
-xyyz = zyxy yzxy = -zyxy = -yzyx = xyyz yxzy = -xyzy = -yxyz = zyyx
yzyx = -zyyx = -yzxy = yxyz zyxy = -yzxy = -zyyx = xyzy zyyx = -yzyx =
-zyxy = yxzy

Each unique set of three will provide \emph{eight} combined indeces. So
what are the unique combinations of 3? We have to be careful here, since
1223 and 1332 are distinct, but 1223 and 3221 are not. So let's just
write them all out:

0112 0113 2113 0221 0223 1223 0331 0332 1332 1002 1003 2003

So there are (+12). 12 + 9 = 21. Which is exactly the number we wanted!

Let's go ahead and list ``representative'' values from all 21:

2 combos: 0101 0202 0303 1212 1313 2323

3 combos: 0112 0113 2113 0221 0223 1223 0331 0332 1332 1002 1003 2003

4 combos: 0123 0231 0132

    \emph{c) Show that 6.70 imposes only one further relation independent of
6.69 on teh components, reducing the total of independent ones to 20.}

In the notation we've been using to be fast at typing, 6.70 correlates:

xyzw + xwyz + xzwy = 0

First of all this can't possibly relate numbers together that don't
share numbers. All our 2-combos are completely unique, so they can't be
related to each other this way. Also even though they can be shuffled
into 0011 situations, this is perfectly fine--this does not demand that
they be zero because of this, just that one be the reverse of the other!

In the case of our 2-patterns, we get xyyx + xxyy + xyxy = 0 and while
the middle one is zero the last is the negative of the first. This will
apply to all of them.

3-combos are the same way, but it's not as obvious. However, shuffling
indeces around, no matter how it's done, can't change the number of each
type of index, keeping them all firmly planetd within their ``classes''.
The three-way sum doesn't change anythign either, as they take the same
``shapes'' as the 2-combos.

So now we go to the 4 combos, and there \emph{are} no zeroes hanging
around the 4 combos, and they certainly \emph{can} be shuffled outside
their group. That would mean all 4-combos are related, right, making the
independent indeces 19 rather than 20? No! The relation of 6.70 is a + b
+ c = 0. To find one of them, TWO of the others must be defined. It's
like a function f(x,y). Two indepenent parameters are inserted to find
the third. So we areduce from 21\ldots{} to 20.

    \hypertarget{problem-19-back-to-top}{%
\section{\texorpdfstring{Problem 19 {[}Back to
\hyperref[toc]{top}{]}}{Problem 19 {[}Back to {]}}}\label{problem-19-back-to-top}}

\[\label{P19}\]

\emph{Prove that \(R^\alpha_{\beta\mu\nu}=0\) for polar coordinates in
the Euclidean plane. Use 5.45 or equivalent results.}

5.45 just gives the Christoffel symbols. Not writing them down again,
but 1/r, 1/r, and -r are the only three solid values.

The metric has a diagonal of 1, \(r^2\). The inverse 1, \(1/r^2\).

\(\Gamma^\alpha_{\mu\nu,\sigma} = \frac12 g^{\alpha\beta} \left( g_{\beta\mu,\nu\sigma} + g_{\beta\nu,\mu\sigma} - g_{\mu\nu,\beta\sigma} \right)\)

\[ R^\lambda_{\beta\mu\nu} = \Gamma^\gamma_{\beta\nu,\mu} - \Gamma^\gamma_{\beta\mu,\nu} + \Gamma^\gamma_{\sigma\mu} \Gamma^\sigma_{\beta\nu} - \Gamma^\gamma_{\sigma\nu} \Gamma^\sigma_{\beta\mu}  \]

Thus we combine everything together to get the result. (this was
originally indexed wrong so above versions may also be indexed wrong.)

    R is 2x2x2x2 which means we'll have a grand total of 16 elements here.
ALL of them need to be zero. Regardless it should be obvious how to
carry out the problem now, it'll just take this thing called TIME.

Let's handle the last terms first since we already know the Christoffel
numbers for the non-derivatives.

There are only five resulting terms that exist, and they exist at
different ``times'', never does the sum have more than one component in
it. Represent \(\theta\) by t since we're going to be typing it out a
lot. trt = 1/r ttr = 1/r rtt = -r

The combinations require middle term to match the first term of the
second.

(rtt)(trt) = -1 (trt)(rtt) = -1 (rtt)(ttr) = -1 (ttr)(trt) = \(1/r^2\)
(ttr)(ttr) = \(1/r^2\)

The last term in R's definition is closely related. the only difference
is that it swaps the last indeces.

(rtt)(trt) = -1 (trt)(rtt) = -1 (rtr)(ttt) = 0 (!) (ttt)(trr) = 0 (!)
(ttr)(ttr) = \(1/r^2\)

This reveals \emph{two cases} where they simply don't cancel. In terms
of R, these cases are:

R(rttr) with -1, and R(trrt) with \(1/r^2\). There are also their
converses in R(rtrt) with +1 and R(trtr) with \(-1/r^2\). With luck
these will cancel with the derivative terms.

Now while we originally tried to find the derivatives of hte
coefficients with respect to the equation, we realized something rather
basic. We have the coefficients. Just take the derivatives directly. -r
becomes -1, 1/r becomes \(-1/r^2\), and only when the derivative is
taken with respect to r. This results in three separate places where the
derivative coefficients are not zero.

At one, all of the coefficients are ttr,r, and ttr,r - ttr,r is just
zero, so they cancel. (uh oh\ldots)

At the others, we have trt,r standing alone in two cases, and then rtt,r
standing alone in two cases. R(trtr) has \(1/r^2\), R(trrt) has
\(-1/r^2\). Then we have R(rttr) with 1, and R(rtrt) with -1.

You will note that when the location of R matches, the actual result is
opposite for both of what we've calculated. Which means EVERYTHING IS
ZERO! WOOHOO YEAH!

    \hypertarget{problem-20-back-to-top}{%
\section{\texorpdfstring{Problem 20 {[}Back to
\hyperref[toc]{top}{]}}{Problem 20 {[}Back to {]}}}\label{problem-20-back-to-top}}

\[\label{P20}\]

\emph{Fill in the algebra necessary to establish 6.73}

6.73:
\(\nabla_\alpha \nabla_\beta V^\mu = V^\mu_{,\beta\alpha} + \Gamma^\mu_{\nu\beta,\alpha} V^\nu\)

okay so this isn't as simple as it looks. The previous step, 6.72,
provides:

\[ \nabla_\alpha \nabla_\beta V^\mu = \nabla_\alpha (V^\mu_{;\beta}) = (V^\mu_{;\beta})_{,\alpha} + \Gamma^\mu_{\sigma\alpha} V^\sigma_{;\beta} + \Gamma^\sigma_{\beta\alpha} V^\mu_{;\sigma} \]

But we're evaluating this at the point P so any actual \(\Gamma\) are
zero. Which means we just have\ldots{}

\[= (V^\mu_{;\beta})_{,\alpha} \]

    Which we can expand into:

\[ = V^\mu_{,\beta\alpha} + \Gamma^mu_{\nu\beta}V^\mu_{,\alpha} +  \Gamma^mu_{\nu\beta,\alpha}V^\mu \]
\[ = V^\mu_{,\beta\alpha} + \Gamma^mu_{\nu\beta,\alpha}V^\mu \]

And hey look that's what we wanted.

    \hypertarget{problem-21-back-to-top}{%
\section{\texorpdfstring{Problem 21 {[}Back to
\hyperref[toc]{top}{]}}{Problem 21 {[}Back to {]}}}\label{problem-21-back-to-top}}

\[\label{P21}\]

\emph{Consider the sentences following 6.78. Why does the argument in
parenthesis not aply to the signs in:}

\[ V^\alpha_{;\beta} = V^\alpha_{,\beta} + \Gamma^\alpha_{\mu\beta} V^\mu ;; V_{\alpha;\beta} = V_{\alpha,\beta} - \Gamma^\mu_{\alpha\beta} V_\mu\]

    6.78 it essentially pointing out that the double covariant derivative
acting on a \(1\choose1\) tensor produces components of that tensor
acted upon by the R-tensor, but always with positive sign. We note above
that the relation there shows that, no, it does not have to be positive
in the case of a total derivative acting on a vector (or one-form). the
one-form version produces a minus sign.

The argument in parentehsis is ``They must all have the same sign
because rasiing and lowering indices with g is unaffected by
\(\nabla_\alpha\) since \(\nabla g = 0\).''

It seems as though the reason this doesn't work is because we're not
applying a coefficient to every term, like we are in 6.78. The partial
derivative still remains, and its not multiplied by any tensor or
tensor-like component.

In fact we recall from earlier that the Christoffel coefficietns aren't
even a tensor at \emph{all}, so the entire thing falls apart as the term
with the sign is not invariant (although the total is.)

    \hypertarget{problem-22-back-to-top}{%
\section{\texorpdfstring{Problem 22 {[}Back to
\hyperref[toc]{top}{]}}{Problem 22 {[}Back to {]}}}\label{problem-22-back-to-top}}

\[\label{P22}\]

\emph{Fill in the algebra necessary to establish 6.84, 6.85, and 6.86}

    Right, rather than trying to funble our way through this, since this
problem is basically asking us to work out the details of
``non-paralellism'', we're going to start from teh beginning, which is
6.79, and derive \emph{every} part of it since as of starting this
problem we are not sure what exactly we did to get here.

We start by considering two geodesics, let htem be V and V' so their
tangents are \(\vec V\) and \(\vec V'\). They start paralell to each
other, at points A and A'. Let the affine parameter be \(\lambda\).

Let there be another vector \(\vec\xi\) which connects the two geodesics
at a single value of the parameter \(\lambda\). Think of it as a line
straddling the distance between the two geodesics. At the `start' it
connects A and A', and will move on to connect B and B', etcetera.

To make this a simple version, we create a local inertial coordiante
system at A itself, and also say that the coordinate \(x^0\) points
along geodesic V and that the coordinate is scaled to match the
progression \(\lambda\). One case of this would be traveling in the x
direction on the cartesian plane at one unit distance per unit time. We
have \(V^\alpha = dx^\alpha / d\lambda\) which is just the definition of
the tangent vector, but because of the way we've defined everything we
have made at A the vector have components \(V^\alpha = \delta^\alpha_0\)
which is to say we are pointing directly in the (1,0,0,\ldots)
direction.

Then we note the equation of the geodesic at A is \$
\frac{d^2x^\alpha}{d\lambda^2} \textbar\_A = 0\$. But before we move on,
let's see where this comes from. The actual definition of the geodesic
is

\[ \frac{d^2 x^\alpha}{d\lambda^2} + \Gamma^\alpha_{\mu\beta} \frac{x^\mu}{d\lambda} \frac{x^\beta}{d\lambda} = 0 \].

However as we're evaluating this at a specific point A, the Christoffel
symbols vanish as they are all zero, thus our geodesic is correct. AT A.

At A' we have a different story, the symbols most certainly do not
vanish.

    Fortunately for us it does simplify quite a bit, as we defined the
vector V to be (1,0,0,\ldots) and since the geodesics start OUT tangent,
this is \(\vec V'\) as well. This means that only the \(x^0\) components
evaluate, leaving a single Christoffel symbol.

\[ \frac{d^2 x^\alpha}{d\lambda^2}|_{A'} + \Gamma^\alpha_{00}(A') = 0 \].

Where the ``of A''' portion reminds us that the Christoffel symbols
change based on what point they're at.

    The next step is a minor approximation. We don't know what \(\Gamma\) is
at A', but we do know A' is separated from A by our connecting vector
\(\vec\xi\). The approximation we make is that we assume the derivative
is mostly constnat over the path between A and A' which, if the
separation is small, is a pretty good approximation. This is, in math:

\[\Gamma^\alpha_{00}(A') \approx \Gamma^\alpha_{00,\beta} \xi^\beta\]

Note that while the Christoff symbol at A is zero, its derivative is not
(necessarily), which is why we can make the above statement. Also note
that there is a sum here over all directions that the connecting vector
points. Ideally we start the situaiton in such a way that there's only
one term, though.

We now have at A'\ldots{}

\[ \frac{d^2 x^\alpha}{d\lambda^2}|_{A'}  = -\Gamma^\alpha_{00,\beta}\xi^\beta \].

    Now we can combine our A and A' equations to say:

\[ \frac{d^2 x^\alpha}{d\lambda^2}|_{A'} - \frac{d^2x^\alpha}{d\lambda^2} |_A  = -\Gamma^\alpha_{00,\beta}\xi^\beta \].

Curiuosly, since A and A' are separated by \(\vec\xi\) we can also say

\[ \frac{d^2 x^\alpha}{d\lambda^2}|_{A'} - \frac{d^2x^\alpha}{d\lambda^2} |_A  = \frac{d^2\xi^\alpha}{d\lambda^2} \].

Which combines to

\[ -\Gamma^\alpha_{00,\beta}\xi^\beta  = \frac{d^2\xi^\alpha}{d\lambda^2}\].

Which gives us a more explicit description of how \(\vec\xi\) changes.

    Now we go grab another equation: 6.48. Which states:

\[U^\beta V^\alpha_{;\beta} = 0 \Leftrightarrow \frac{d}{d\lambda} \vec{V} = \nabla_{\vec U}\vec V = 0\]

    Our ultimate goal here is the full second covariant derivative of
\(\xi\). Using the above, we can actually write out

\[ \nabla_V \nabla_V \xi^\alpha = \nabla_V (\nabla_V \xi^\alpha)  = \frac{d}{d\lambda}(\nabla_V \xi^\alpha) \]

But this really doesn't seem right, if we extract it as we know we
should using
\(V^\alpha_{;\beta} = V^\alpha_{,\beta} + \Gamma^\alpha_{\mu\beta} V^\mu\),
we get:

\[ = \frac{d}{d\lambda}(\nabla_V \xi^\alpha) + \Gamma^\alpha_{\beta 0}(\nabla_V \xi^\beta) \]

IF this turns out well, this means 6.84 has a typo, an = instead of a +.
Now we can expand each internal term as well\ldots{}

\[ = \frac{d}{d\lambda}(\frac{d}{d\lambda} \xi^\alpha + \Gamma^\alpha_{\beta 0} \xi^\beta) + \Gamma^\alpha_{\beta 0}(\frac{d}{d\lambda} \xi^\alpha + \Gamma^\alpha_{\beta 0} \xi^\beta) \]

That term on the right is 0 since it's a Christoffel symbol without a
derivative being taken, and we are working in the A frame.

\[ = \frac{d}{d\lambda}(\frac{d}{d\lambda} \xi^\alpha + \Gamma^\alpha_{\beta 0} \xi^\beta)\]

Note that since we set the parameter to be in the same direction as
\(x^0\) we can adjust notation for it as ``0''

\[ = \frac{d^2}{d\lambda^2} \xi^\alpha + \Gamma^\alpha_{\beta 0,0} \xi^\beta + \Gamma^\alpha_{\beta 0} \xi^\beta_{,0} \]

\[ = \frac{d^2}{d\lambda^2} \xi^\alpha + \Gamma^\alpha_{\beta 0,0} \xi^\beta\]

This is 6.85. Which means that yes there was a typo up there. Hooo boy.

Anyway we can finally substitute in our second derivative to get:

\[ = -\Gamma^\alpha_{00,\beta} \xi^\beta + \Gamma^\alpha_{\beta 0,0} \xi^\beta\]
\[ = (\Gamma^\alpha_{\beta 0,0}-\Gamma^\alpha_{00,\beta}) \xi^\beta\]

    now the problem claims that this equals \(R^\alpha_{00\beta}\). While it
does you have to take the first two indeces as fungible to make it work.
The derivative coefficients remain, the non-derivative ones cancel each
other out as they are symmetric across our little point here.

\[ = R^\alpha_{00\beta} \xi^\beta\]
\[ = R^\alpha_{\mu\nu\beta} V^\mu V^\nu \xi^\beta\]

    Okay this last step needs some jusitifcation. Why does acting on our
vectors reduce their indeces to zero? Well, after all, we've excessively
defined V in terms of the point A, going in (1,0,0,0,\ldots) so there
WERE no other indeces. So yeah going that way checks out.

The question now is why we can go from 00 to genral indeces and the
equation isn't messed up\ldots{} but think of it this way. We could
ALWAYS define V to be in a singular direction, so naturally it has to
hold in general as well.

And now\ldots{} we are done.

Ooogh. What does this even SAY? Well, since R is zero in a flat space,
paralell lines remain parallel. However, R on a non-flat space have
their separation values change, as R scales it somehow.

And that's all this needed to show.

    \hypertarget{problem-23-back-to-top}{%
\section{\texorpdfstring{Problem 23 {[}Back to
\hyperref[toc]{top}{]}}{Problem 23 {[}Back to {]}}}\label{problem-23-back-to-top}}

\[\label{P23}\]

\emph{Prove 6.88} (oh no.) \emph{Be careful: one cannot simply
differentiate 6.67 since it is valid only at P, not in the neighborhood
of P.}

6.88:
\(R_{\alpha\beta\mu\nu,\lambda} = \frac12 (g_{\alpha\nu,\beta\mu\lambda} - g_{\alpha\mu,\beta\nu\lambda} + g_{\beta\mu,\alpha\nu\lambda} - g_{\beta\nu,\alpha\mu\lambda})\)

Oh BOY.

    Anyway, we are proving that the partial derivative of R is is the
derivative of all the g components that make it up. However, if we back
way way up, we note that all the equations we've been using so far are
only valid at P, since we've been removing the extra coefficients. So we
need to back up to:

\[ R^\lambda_{\beta\mu\nu} = \Gamma^\gamma_{\beta\nu,\mu} - \Gamma^\gamma_{\beta\mu,\nu} + \Gamma^\gamma_{\sigma\mu} \Gamma^\sigma_{\beta\nu} - \Gamma^\gamma_{\sigma\nu} \Gamma^\sigma_{\beta\mu}  \]

We can see obviously from the mentioned 6.67 and 6.68 that the
already-differentiated terms will become exactly the relation we want.
It's the terms we ignored at P that we need to prove cancel, that is:

\[ \Gamma^\gamma_{\sigma\mu} \Gamma^\sigma_{\beta\nu} - \Gamma^\gamma_{\sigma\nu} \Gamma^\sigma_{\beta\mu}  \]

These guys.

    Which we then apply the product rule to to actually take their
derivatives:

\[ \Gamma^\gamma_{\sigma\mu} \Gamma^\sigma_{\beta\nu,\lambda} + \Gamma^\gamma_{\sigma\mu,\lambda} \Gamma^\sigma_{\beta\nu} - \Gamma^\gamma_{\sigma\nu} \Gamma^\sigma_{\beta\mu,\lambda} - \Gamma^\gamma_{\sigma\nu,\lambda} \Gamma^\sigma_{\beta\mu} \]

Unfortunately it's not obvioust that they cancel, which means we'll have
to \emph{expand} them.

\[ \Gamma^\alpha_{\mu\nu,\sigma}  = \frac12 g^{\alpha\beta} \left( g_{\beta\mu,\nu\sigma} + g_{\beta\nu,\mu\sigma} - g_{\mu\nu,\beta\sigma} \right) \]

\[ \Gamma^\gamma_{\beta\mu} = \frac{1}{2} g^{\alpha\gamma} (g_{\alpha\beta,\mu} + g_{\alpha\mu,\beta} - g_{\beta\mu,\alpha})  \]

At which point we went ``we're not tpying that up'' and wrote down the
substitutions in a notebook. Index salad, index salad\ldots{}

    First we noted the leading terms are all 1/4 inverse-g. The inverse-g
terms combined into two distinct types, meaning that the first and third
could add, as could the second and fourth. Meaning that if one of them
canceled, both of them would cancel. Furthermore, the only swap between
the pairs was a \(\mu\nu\) swap, so all we needed to find was the result
for ONE of the terms. This still wasn't exactly trivial.

Work implies that nothing cancels. Then we realize that the two
``different'' leading coefficients we found really are not, since the
metric is by definition SYMMETRIC. So really all of them can add
together as they wish.

We showed (on the paper) that the pairs 13 and 24 did not cancel.
HOWEVER, it is clear from the coefficietns \(\mu\nu\) swap AND the term
the derivative acts on swaps, then everything is in fact equal and
cancels.

Here's an example term:
\(g_{\alpha\sigma,\mu}g_{\iota\beta,\nu\lambda}\). If we perform the
swap we end up with \(g_{\alpha\sigma,\nu\lambda}g_{\iota\beta,\nu}\)
which actually IS the same because by index salading we can set all the
dummy indeces to anything.

Note: wouldn't this change R? It seems like for an arbitrary R these
wouldn't line up perfectly. Ah, but let's look at which indeces are
being adjusted: \(\alpha\iota\) are summation indeces, they have no
relevance on R. Which leaves \(\sigma\) and \(\beta\). The thing is, by
swapping it on one term, we have to swap it on all terms, which makes
them fly past each other except when \(\sigma\) = \(\beta\), which can't
always be true as \(\beta\) only takes one value on any given sum.

And so we are at a loss but think that maybe spending more time isn't
worth it.

HOLD ON A SECOND.

WE'RE STUPID.

We're still evaluating at point P. Which means, while we needed to open
up the Christoffel symbols to take their derivatives, WE ARE STILL IN P.
EVERY ONE OF THOSE TERMS IS ZERO. EVERY ONE OF THEM.

\textbf{AGH}.

    \hypertarget{problem-24-back-to-top}{%
\section{\texorpdfstring{Problem 24 {[}Back to
\hyperref[toc]{top}{]}}{Problem 24 {[}Back to {]}}}\label{problem-24-back-to-top}}

\[\label{P24}\]

\emph{Establish 6.89 from 6.88}

    6.88 is what we were yelling at in the previous problem.

\(R_{\alpha\beta\mu\nu,\lambda} = \frac12 (g_{\alpha\nu,\beta\mu\lambda} - g_{\alpha\mu,\beta\nu\lambda} + g_{\beta\mu,\alpha\nu\lambda} - g_{\beta\nu,\alpha\mu\lambda})\)

Now we wish to show that
\(R_{\alpha\beta\mu\nu,\lambda} + R_{\alpha\beta\lambda\mu,\nu} + R_{\alpha\beta\nu\lambda,\mu}= 0\)
Which, since we are really tired of typing out all these greek letters,
we shall just represent as R(1234,5) + R(1253,4) + R(1245,3) = 0.

Expanding we don't care about the fractional coefficient. We end up
with:

g(14,235) - g(13,245) + g(23,145) - g(24,135)

+g(13,254) - g(15,234) + g(25,134) - g(23,154)

+g(15,243) - g(14,253) + g(24,153) - g(25,143)

Now we can re-arrange on eitehr side of the comma. Ascending order seems
reasonable.

g(14,235) - g(13,245) + g(23,145) - g(24,135)

+g(13,245) - g(15,234) + g(25,134) - g(23,145)

+g(15,234) - g(14,235) + g(24,135) - g(25,134)

Now, does EVERYTHING cancel?

YES! And we're done.

    \hypertarget{problem-25-back-to-top}{%
\section{\texorpdfstring{Problem 25 {[}Back to
\hyperref[toc]{top}{]}}{Problem 25 {[}Back to {]}}}\label{problem-25-back-to-top}}

\[\label{P25}\]

\emph{a) Prove that the Ricci tensor is the only independent contraction
of \(R^\alpha_{\beta\mu\nu}\), all others are multiples of it.}

    The Ricci tensor is \(R_{\alpha\beta}\) derived from
\(R^\mu_{\alpha\mu\beta}\), which is to say a contraction along two
indeces. (We'll just assume we're always contracting along two indeces
and not worry about other options, such as three.)

We wish to show that all other possible contractions are either null, or
some multiple of the Ricci tensor. For now we shall \emph{assume} the
tensor is symmetric so 12 and 21 would be the same tensor, but notably
in the next part we have to prove that property.

Regardless, let's label our indeces xyzw since we're lazy. The
2-combinations on offer are:

xy xz xw yz yw (the definition) zw

So there are five other options. Using ``a'' as the ``singular''
element, these become:

xyaa xaza xaaw ayza ayaw (definition) aazw

So first of all from \textbf{Problem 18} we know that anything with
``aa'' in on either the left or right side just flat out reduces to
zero. So that gets rid of two of our options right away.

xaza xaaw ayza ayaw (definition)

So now the trick is to show that these are equivalent to each other,
give or take a sign. This can actually be shown simply by the
``shuffling'' of combinations we once did. Like so:

a1a2 = -1aa2 = -a12a = a2a1

And as we know from \textbf{Problem 18} the three-combinations will
cycle through EVERY possible option. Thus, every other combination has
to be plus or minus the others.

We don't even have to assume symmetry to know this, actually, as the
inverted versions will also be hit!

    \emph{b) Show that the Ricci tensor is symmetric}

So, basically, \(R^\mu_{\alpha\mu\beta} = R^\mu_{\beta\mu\alpha}\)

    So basically, can we say a1a2 = a2a1? Well\ldots{} let's see.

a1a2 = -1aa2 = -a12a = a2a1.

Hey look at that, we've shown it trivially. Wow. Glad we did
\textbf{Problem 18} to completion, it made thinking about this easy.

    \hypertarget{problem-26-back-to-top}{%
\section{\texorpdfstring{Problem 26 {[}Back to
\hyperref[toc]{top}{]}}{Problem 26 {[}Back to {]}}}\label{problem-26-back-to-top}}

\[\label{P26}\]

\emph{Use \textbf{Problem 17} to prove 6.94}

    6.94 states, simply, that \(g^{\alpha\beta}_{;\mu} = 0\)

Which. This is extremely trivial, it seems, as \textbf{Problem 17} has
\(g^{\alpha\beta}_{,\mu}(P)=0\)

The trivial adjustment is that while the partial derivative at P is
zero, that means the Chrsitoffel symbol is zero since we are at P, so
the partial derivative is equal to the total derivative.

So. Uh. Yeah. That's it. Go home, it's over.

    \hypertarget{problem-27-back-to-top}{%
\section{\texorpdfstring{Problem 27 {[}Back to
\hyperref[toc]{top}{]}}{Problem 27 {[}Back to {]}}}\label{problem-27-back-to-top}}

\[\label{P27}\]

\emph{Fill in the algebra necessary to establish 6.95, 6.97, 6.99.}

So since this is an extended derivation, we're going to start from the
beginning of the section, that is, by applying the Ricci contraction to
the Bianchi identities. The Bianchi identities are
\(R_{\alpha\beta\mu\nu; \lambda} + R_{\alpha\beta\lambda\mu;\nu} + R_{\alpha\beta\nu\lambda;\mu} = 0\)

The actual Ricci concentraiton is given by
\(R_{\alpha\beta} = R^\mu_{\alpha\mu\beta}\).

We specifically accomplish this applicaiton by applying a raising metric
to the Bianchi identities. We can apply it independently of the
derivative since the full derivative of the metric is zero and can thus
be treated as a cosntant. All the contraction really does is adjust
indeces.

\[g^{\alpha\mu}(R_{\alpha\beta\mu\nu;\lambda} + R_{\alpha\beta\lambda\mu;\nu} + R_{\alpha\beta\nu\lambda;\mu}) = 0\]

\[\Rightarrow (R^\mu_{\beta\mu\nu;\lambda} + R^\mu_{\beta\lambda\mu;\nu} + R^\mu_{\beta\nu\lambda;\mu}) = 0\]

\[\Rightarrow R{\beta\nu;\lambda} - R_{\beta\lambda;\nu} + R^\mu_{\beta\nu\lambda;\mu} = 0\]

The subtraction is there because we had to shuffle some indeces to get
the right form for conversion. Which apparently is 6.95, but that's
trivially true, at least it seems so. Shuffle index 3 and 4, get a minus
sign.

We now have the contracted Bianchi identities.

Apparently this isn't sueful, so we contract AGAIN, this time to the
Ricci Scalar, which is \(R = g^{\mu\nu}R_{\mu\nu}\). If we apply another
raising metric\ldots{}

\[g^{\beta\nu} (R{\beta\nu;\lambda} - R_{\beta\lambda;\nu} + R^\mu_{\beta\nu\lambda;\mu}) = 0\]

\[\Rightarrow R_{;\lambda} - R^\nu_{\lambda;\nu} + g^{\beta\nu}R^\mu_{\beta\nu\lambda;\mu} = 0\]

\[\Rightarrow R_{;\lambda} - R^\nu_{\lambda;\nu} - g^{\beta\nu}R^\mu_{\beta\lambda\nu;\mu} = 0\]

\[\Rightarrow R_{;\lambda} - R^\nu_{\lambda;\nu} - R^{\mu}_{\lambda;\mu} = 0\]

That last step was us essentially defining a new contraction. (Mildly
confused on validity\ldots{} need to do it in the same order as the
metric perhaps? Addendum: what apears to be happening is an ignoring of
the first term, and using the last four terms to do the collapse. This
involves swapping \(\nu\lambda\) positions which are the 34 index, and
there you have it) To match the 9.96 given in the book, we adjust
indeces.

\[\Rightarrow R_{;\lambda} - R^\mu_{\lambda;\mu} - R^{\mu}_{\lambda;\mu} = 0\]

    Which we can simplify to

\[ (2R^\mu_\lambda - \delta^\mu_\lambda R)_{;\mu} = 0\]

the 2R term is obvious, thos parts add, and the signs can be inverted by
carrying everything across the equals sign. But where did the delta come
from? Well, do note that we are SUMMING over \(\mu\), so it hits every
value. The point is to say that the R term only exists when
\(\mu = \lambda\). And then we have our result. This is 6.97.

To get to 6.99 we have to define a symmetric tensor, specifically G.

\[ G^{\alpha\beta} = R^{\alpha\beta} - \frac12 g^{\alpha\beta}R = G^{\beta\alpha} \]

Our goal is to find G hidden within 6.97. Let's work it out.

\[ (2R^\mu_\lambda - \delta^\mu_\lambda R)_{;\mu} = 0\]
\[ \Rightarrow 2(R^\mu_\lambda - \frac12\delta^\mu_\lambda R)_{;\mu} = 0\]
\[ \Rightarrow 2g^{\lambda\beta}(R^\mu_\lambda - \frac12g^\mu_\lambda R)_{;\mu} = 0\]

Here we remembered that the dirac is the metric with but up and down
indeces.

\[ \Rightarrow 2(R^{\mu\beta} - \frac12g^{\mu\beta} R)_{;\mu} = 0\]

Change index.

\[ \Rightarrow 2(R^{\alpha\beta} - \frac12g^{\alpha\beta} R)_{;\mu} = 0\]

Hey look, that's G.

\[ \Rightarrow 2(G^{\alpha\beta})_{;\mu} = 0\]
\[ \Rightarrow 2G^{\alpha\beta}_{;\mu} = 0\]
\[ \Rightarrow G^{\alpha\beta}_{;\mu} = 0\]

And we're done here, that is 6.99.

    \hypertarget{problem-28-back-to-top}{%
\section{\texorpdfstring{Problem 28 {[}Back to
\hyperref[toc]{top}{]}}{Problem 28 {[}Back to {]}}}\label{problem-28-back-to-top}}

\[\label{P28}\]

\emph{a) Derive 6.19 by using the usual coordiante transformation from
Cartesian to spherical polars.}

    6.19 is the spherical metric, that is, the metric with the diagonal
\(1, r^2, r^2sin\theta\). However, we need to actually find it from
scratch to truly solve the problem. So basically, we just know the
answer: now we need to derive it.

The ``simple'' way to find the metric is 6.11,
\((g) = (\Lambda)(\eta)(\Lambda)^T\), where \(\eta\) is the standard
metric, (1,1,1) diagonal in this case. In tensor notaiton, this is
\(g_{\alpha\beta} = \Lambda^\mu_\alpha \Lambda^\nu_\beta \eta_{\mu\nu}\)

This requires knowing the translation matrix from cartesian to
spherical, which is defined by the Jacobian. 5.13 gives the exact format
for 2x2, which we extend into 3x3. We do admit to having to look up the
exact relations for xyz to spherical. \hyperref[7]{7} reveals\ldots{}

\[x=rsin\theta cos\phi; y = rsin\theta sin\phi; z = rcos\theta\]

Which we now put into a Jacobian matrix. Rows are by cartesian xyz, rows
are by r\(\theta\phi\).

\[ \begin{bmatrix}
sin\theta cos\phi & rcos\theta cos\phi & - rsin\theta sin\phi \\
sin\theta sin\phi & rcos\theta sin\phi & rsin\theta cos\phi \\
cos\theta & -rsin\theta & 0 
\end{bmatrix}\]

Since the cartesian metric is the identity, our operation is the same as
multiplying this matrix by its transpose.

\[ \begin{bmatrix}
sin\theta cos\phi & sin\theta sin\phi & cos\theta \\
rcos\theta cos\phi & rcos\theta sin\phi & -rsin\theta \\
- rsin\theta sin\phi & rsin\theta cos\phi & 0 
\end{bmatrix}\]

This took some notebook work to fully calculate, as there were nine
separate terms.

    After reviewing the definitions we realized we had the transpose
backwards. Whoops. This rather quickly gave us our diagonal, though,
just reverse the transposes and out pop \(1, r^2, r^2sin\theta\),
tah-dah!

We did not test every single off-diagonal to see if they were zero
because it should be automatic, but we did test one just to see. And yes
it was zero.

    \emph{b) Deduce from 6.19 that the metric of the surface of a sphere of
radius r has components \$ g\_\{\theta\theta\} = r\^{}2, g\_\{\phi\phi\}
= r\^{}2 sin\^{}2\theta, g\_\{\theta\phi\}=0 \$ in the usual spherical
coordinates.}

    Obviously the transform the metric provides must still hold even for
points restricted to a spherical shell of constant radius, so the
diagonal becomes (\(r^2, r^2sin^2\theta\)) rather trivially.

    \emph{c) Find the componetnst \(g^{\alpha\beta}\) for the sphere.}

Finding the inverse is simple: invert everything, the diagonal is now
\(1/r^2, 1/(r^2sin^2\theta)\). Tah-dah!

    \hypertarget{problem-29-back-to-top}{%
\section{\texorpdfstring{Problem 29 {[}Back to
\hyperref[toc]{top}{]}}{Problem 29 {[}Back to {]}}}\label{problem-29-back-to-top}}

\[\label{P29}\]

\emph{In polar coordinates, calculate the Reimann curvature tensor of
the spehre of unit radius, whose metric is given in \textbf{Problem 28}.
Note that in two dimensions there is onely one independent component, by
the same argument as \textbf{Problem 18b}. So calculate
\(R_{\theta\phi\theta\phi}\) and obtain all other components in terms of
it.}

    Right, so, R has 16 components in a two-dimensional case. We can
actually write them all out in BINARY!

0000, 0001, 0010, 0011, 0100, 0101, 0110, 0111, 1000, 1001, 1010, 1011,
1100, 1101, 1110, 1111

Naturally anything with any doubled anything is zero, so we ignore
those.

0101, 0110, 1001, 1010

only four components are potentially independent, and we know from
\textbf{Problem 18} shuffling that they are all related to each other.
By the suggestion in the problem, we have:

0101 = -1001 = -0110 = 0101

-1001 = 0101 = 1010 = -0110

Which correlates all four of the values. Which means\ldots{} now we have
to figure out how to CALCULATE one of the terms. \emph{Shocked and
terrified gasp,}

    From 6.62 we know the tensor is defined by the christoffel coefficients
and their derivatives. Which means we're gonna have to grab everything
and do some tedious calculaitons\ldots{} but since we've never found an
actual value for R before, we're gonna actually do it.

\[ R^\lambda_{\beta\mu\nu} = \Gamma^\gamma_{\beta\nu,\mu} - \Gamma^\gamma_{\beta\mu,\nu} + \Gamma^\gamma_{\sigma\mu} \Gamma^\sigma_{\beta\nu} - \Gamma^\gamma_{\sigma\nu} \Gamma^\sigma_{\beta\mu}  \]

\[ \Gamma^\alpha_{\mu\nu,\sigma}  = \frac12 g^{\alpha\beta} \left( g_{\beta\mu,\nu\sigma} + g_{\beta\nu,\mu\sigma} - g_{\mu\nu,\beta\sigma} \right) \]

\[ \Gamma^\gamma_{\beta\mu} = \frac{1}{2} g^{\alpha\gamma} (g_{\alpha\beta,\mu} + g_{\alpha\mu,\beta} - g_{\beta\mu,\alpha})  \]

    So, just calculate ONE.

R(0101) is our starting point. This becomes

\[R^0_{101} = \Gamma^0_{11,0} - \Gamma^0_{10,1} + \Gamma^0_{\sigma 0} \Gamma^\sigma_{11} - \Gamma^0_{\sigma 1} \Gamma^\sigma_{10} \]

\[ = \Gamma^0_{11,0} - \Gamma^0_{10,1} + \Gamma^0_{0 0} \Gamma^0_{11} - \Gamma^0_{0 1} \Gamma^0_{10} + \Gamma^0_{1 0} \Gamma^1_{11} - \Gamma^0_{1 1} \Gamma^1_{10} \]

    Now all these coefficients are given by the various metrics within them.
Rather than writing it all down, since that would be qutie tedious, we
talk it out. The only metrics that exist are on the diagonals. Lower
metric is \(r^2, r^2sin^2\theta\) and the upper metric is
\(1/r^2, 1/(r^2sin^2\theta)\). All off-diagonal terms are zero, which
will reduce quite a lot to actually zero. In fact, the ``sum'' in every
one of the coefficients reduces to a single number, since the upper
metric in each one only exists on one of the terms.

After all of it, only one of the derivative coefficients and one of the
non-derivative terms remains, combining to be

\[cos^2\theta - sin^2\theta + \frac{1}{tan^2\theta}\]

Which, with a sign adjustment, are all the terms in the R tensor.

Most of this was just double and triple checking indeces. It takes time.

    \hypertarget{problem-30-back-to-top}{%
\section{\texorpdfstring{Problem 30 {[}Back to
\hyperref[toc]{top}{]}}{Problem 30 {[}Back to {]}}}\label{problem-30-back-to-top}}

\[\label{P30}\]

\emph{Calculate the Reimann curvature tensor of the cylinder. Since the
cylidner is flat, this should vanish. Use whatever coordinates you likem
and make sure you write down the metric properly!}

Tempting to move on past this one, but more metric calculation is
worthwhile.

    The nice thing about cylindrical is that it's basically just fancy
polar.

x = \(rcos\theta\)

y = \(rsin\theta\)

z = z (nice!)

The polar metric is just a condensed version of this one. The only
change is the addition of z=z, which makes a rather interesting addition
of just\ldots{} 1. Thus the full metric has diagonal (1, \(r^2\), 1), in
terms of \(r\theta z\).

Notably, every portion of the Reimann curvature tensor is composed of
derivatives of these metrics with respect to the coordinates. \emph{Only
the middle term has a derivative that survives: 2r, and then a second
derivative of 2.} Virtually everything goes to zero. We only need to
concern oursevles with \(g_{\theta\theta,r}\) and
\(g_{\theta\theta,rr}\)

Thus, we might be able to LOOK BACKWARD. Our equations:

\[ R^\gamma_{\beta\mu\nu} = \Gamma^\gamma_{\beta\nu,\mu} - \Gamma^\gamma_{\beta\mu,\nu} + \Gamma^\gamma_{\sigma\mu} \Gamma^\sigma_{\beta\nu} - \Gamma^\gamma_{\sigma\nu} \Gamma^\sigma_{\beta\mu}  \]

\[ \Gamma^\alpha_{\mu\nu,\sigma}  = \frac12 g^{\alpha\beta} \left( g_{\beta\mu,\nu\sigma} + g_{\beta\nu,\mu\sigma} - g_{\mu\nu,\beta\sigma} \right) \]

\[ \Gamma^\gamma_{\beta\mu} = \frac{1}{2} g^{\alpha\gamma} (g_{\alpha\beta,\mu} + g_{\alpha\mu,\beta} - g_{\beta\mu,\alpha})  \]

    So rather than working out each part, we work out all possible
coefficients that contain the only terms that exist and see if they
cancel or not.

Of the standard coefficients there are only 1/r, 1/r, -r. Which makes a
lot of sense, really.

The signs seem a slight bit off, but the derivatives have
\(1/r^2, 1/r^2, -1\)

There is significant annoyance in showing that all these things cancel.

The singular coefficients pair up to form three -1 terms, and one
\(1/r^2\) term. Two of those -1 terms are entirely self-canceling.

The rest better cancel with the derivatives. The -1 term in fact cancels
with the -1 term from the derivatives in both cases.

One of the derivatives' \(1/r^2\) case cancels with itself
\(\Gamma^\theta_{\theta r,r}\).

However, the last two seem to add. This problem woudl be fixed if the
derivative coefficietns were NEGATIVE. Which ostentiably they should be,
as they are the derivatives of hte other coefficients, which should just
be able to be taken without issue. The derivative of 1/r is flat out
\(-1/r^2\). But the result we get from the formula up above is positive,
no sign change. Is it typed down wrong\ldots? No\ldots{}

Well clearly we've shown that it does cancel, but the issue of why the
formula above doesn't put in the right sign is greatly concerning.

This would be fixed if the inverse metric was \(-1/r^2\). But it's not.
Because that doesn't reduce to the 111 diagonal.

Annoyingly looking things up doesn't help here since everyone else just
uses symmetry. Faster, to be sure\ldots{}

No multiplying by the lowering metric at the end to get R into a
different form doesn't change anything.

So, in conclusion, yes the cylidner is flat. We are not sure why the
derivative formula doesn't do the proper negative stuff. Concerning.

Man even using it in a different metric didn't work\ldots{} the sign
error still occurs\ldots{}

So basically let's take derivatives directly and not use that equation.
There may be some validity criteria we have forgotten.

    \hypertarget{problem-31-back-to-top}{%
\section{\texorpdfstring{Problem 31 {[}Back to
\hyperref[toc]{top}{]}}{Problem 31 {[}Back to {]}}}\label{problem-31-back-to-top}}

\[\label{P31}\]

\emph{Prove that covariant differnetiation obeys the usual product
rule.}

Skipped. Would be tedious. Is kind of obvious. Also already proven in
other math courses.

    \hypertarget{problem-32-back-to-top}{%
\section{\texorpdfstring{Problem 32 {[}Back to
\hyperref[toc]{top}{]}}{Problem 32 {[}Back to {]}}}\label{problem-32-back-to-top}}

\[\label{P32}\]

\emph{A four-dimensional manifold has coordinsates (u,v,w,p) in which
the metric has components \(g_{uv}=g_{ww}=g_{pp}=1\), all other
indepdendent componetns vanishing.}

\emph{a) Show that the manifold is flat and the signature is +2}

The signature is usually the sum of the diagonals, and that is the same
as taking the determinant\ldots{} except apparently not, as the
determinant is shown to be zero. So let's go back and figure out what
exactly signature MEANS.

ALSO metrics are symmetric by definition so \(g_{vu}\) better also be 1.

The signature is just the sum of the diagonal elements. So +2. That was
much easier than we thought it was.

    \emph{b) The result in a) implies the manifold must be Minkowski
spacetime. Find a coordinate transformation to the usual coordinates
(t,x,y,z). Hint: you may find it useful to calculate
\(\vec e_v \cdot \vec e_v\) and \(\vec e_u \cdot \vec e_u\)}

    well w=y p=z, so we can just ignore them.

So what matrix transforms (0,1)(1,0) to (-1,0)(0,1)?

That matrix is (0,1)(-1,0)

Which basically states t = -v and x = u.

    \hypertarget{problem-33-back-to-top}{%
\section{\texorpdfstring{Problem 33 {[}Back to
\hyperref[toc]{top}{]}}{Problem 33 {[}Back to {]}}}\label{problem-33-back-to-top}}

\[\label{P33}\]

\emph{A `three-sphere' is the three-dimensional surface in
four-dimensional Euclidean space (coordinates x y z w) given by the
equation \(x^2+y^2+z^2+w^2 = r^2\), where r is the radius of the
sphere.}

\emph{a) Define new coordinates (\(r,\theta,\phi,\chi\)) by the
equations
\(w=rcos\chi, z=rsin\chi cos\theta, x=rsin\chi sin\theta cos\phi, y = rsin\chi sin\theta sin\phi\)
Show that \((\theta,\phi,\chi)\) are coordinates for the sphere. These
genrealize to the familiar polar coordinates.}

    Tempting to do a by-words argument, but this is 4D, so let's try to
figure out how to show it mathematically.

Perhaps the best way is to take the definition of r and show it's
independent from the values of the angles. Which is actually pretty
easy! insert the definitions of x, y, z, and w into the r definition,
the radius completely cancels out. However, we will need to prove that
the sum of all the squares equals 1 to confirm this.

\[ cos^2\chi + sin^2\chi cos^2\theta + sin^2\chi sin^2\theta cos^2\phi + sin^2\chi sin^2\theta sin^2\phi\]
\[ = cos^2\chi + sin^2\chi cos^2\theta + sin^2\chi sin^2\theta\]
\[ = cos^2\chi + sin^2\chi\] \[ = 1\]

Well would you look at that, the equality is satisfied and adjusting any
of the three angles does absolutely nothing to the radius. Therefore,
the three angles are all \emph{on} the three-sphere.

There is a minor point that remains though: how can we show that the
angles span the entire three-sphere, and that we haven't just gotten
part of it? Well, we can reason this one out. Since r is always
positive, it can't provide the sign to the various x, y, z, w
components, to the sign must come from the angles. So every possible x w
y z can be made with them, given an r, there's no bounds they can't
reach.

Arguably this points to a much simpler two-line proof: the sphere is
defined by constant r, thus the other three coordinates have to
characterize it. Since they span Cartesian space, they must span the
entire sphere.

    \emph{b) Show that the metric of the three-sphere of radius r has
components in these coordinates
\(g_{\chi\chi} = r^2, g_{\theta\theta} = r^2sin^2\chi, g_{\phi\phi} = r^2sin^2\chi sin^2\theta\),
all other components vanishing. (Use the same method as \textbf{Problem
28}.)}

    Basically, find the conversion from cartesian metric. Except we aren't
exactly converting from cartesian, but rather the matrix with the
(1,1,1,1) diagonal.

This actually will be a lot of steps and not particuarly illuminating.
The method to be outlined is simple: take the Jacobian. Since the
4-cartesian metric is just the identity, to find the terms all one has
to do is multiply the transformation matrix (Jacobian) with its own
transpose. This will result in 16 rather long evaluations that should
result in the 4-metric. Whatever portion of the metric is on the radius
section can be ignored. (It'll probably be 1 anyway).

Actually let's go ahead and calculate the radius portion of the metric,
since it's not given. All we need to do is find the dot product of
everything with a derivative taken with respect to r\ldots{}

\ldots{}

\ldots we arleady calculated this in part a). The metric \(g_{rr}=1\).
Nice.

Anyway this means we can actually find rather easily the diagonals by
taking dot products of the obvious derivatives. The \(g_{\phi\phi}\)
result is actually self evident, since the first two become zero and the
last two have the same terms affixed to the usual trig addition to 1
rule.

But still, we're not going to show the diagonals are zero. Let someone
else do that.

    \hypertarget{problem-34-back-to-top}{%
\section{\texorpdfstring{Problem 34 {[}Back to
\hyperref[toc]{top}{]}}{Problem 34 {[}Back to {]}}}\label{problem-34-back-to-top}}

\[\label{P34}\]

\emph{Establish the following identities for a general metric tensor in
a general coordinate system. You may find 6.39 and 6.40 useful.}

6.39: \(g_{,\mu} = gg^{\alpha\beta}g_{\beta\alpha,\mu}\)

6.40: \(\Gamma^\alpha_{\mu\alpha} = \frac{\sqrt{-g}_{,\mu}}{\sqrt{-g}}\)

\emph{a) \(\Gamma^\mu_{\mu\nu} = \frac12 (ln|g|)_{,\nu}\)}

    Okay so first of all Christoff Symbols are symmetric,
\$\Gamma\^{}\{a\}\emph{\{bc\} = \Gamma\^{}\{a\}}\{cb, so really what we
want to show is

\[ \frac{\sqrt{-g}_{,\mu}}{\sqrt{-g}} = \frac12 (ln|g|)_{,\nu} \]

    By the rule of the logarithmic derivative\ldots{}

\[ \frac12 \frac{g_{,\mu}}{g}  = \frac12 (ln|g|)_{,\nu} \]

And by \textbf{Problem 8} we know this correlates to:

\[ \frac{\sqrt{-g}_{,\mu}}{\sqrt{-g}} = \frac12 \frac{g_{,\mu}}{g} \]

    \emph{b)
\(g^{\mu\nu}\Gamma^\alpha_{\mu\nu} = -\frac{(g^{\alpha\beta}\sqrt{-g})_{,\beta}}{\sqrt{-g}}\)}

    This looks trivial at first, but it turns out to be something else
entirely. Namely, we note that the indexes aren't the same as 6.40 or
part a.

So the steps here are a little obtuse and strange, so let's go through
them slowly.

First, we note that \(g^{\alpha\beta}_{;\beta}=0\) for all metrics in
all refernce frames, so
\(g^{\alpha\beta}_{,\beta} + \Gamma^\alpha_{\mu\beta}g^{\mu\beta} + \Gamma^\beta_{\mu\beta}g^{\mu\alpha} = 0\),
or perhaps more importantly phrased as

\[ \Gamma^\alpha_{\mu\beta}g^{\mu\beta} = - g^{\alpha\beta}_{,\beta} - \Gamma^\beta_{\mu\beta}g^{\mu\alpha} \]

    Which gives us a direct substitute. The tricky thing to do is to reverse
transform the second Christoffel symbol. We also multiply the first term
by 1. Because reasons that will become obvious.

\[ = - g^{\alpha\beta}_{,\beta} \frac{\sqrt{-g}}{\sqrt{-g}} - \frac{g^{\alpha\beta}(\sqrt{-g})_{,\beta}}{\sqrt{-g}} \]

Which we can just use the product rule backwards on to get..

\[ g^{\mu\nu}\Gamma^\alpha_{\mu\nu} = -\frac{(g^{\alpha\beta}\sqrt{-g})_{,\beta}}{\sqrt{-g}}\]

    \emph{c) for an antisymmetric tensor
\(F^{\mu\nu}, F^{\mu\nu}_{;\nu} = \frac{(\sqrt{-g}F^{\mu\nu})_{,\nu}}{\sqrt{-g}}\)}

    As before, we note:
\(F^{\alpha\beta}_{,\beta} + \Gamma^\alpha_{\mu\beta}F^{\mu\beta} + \Gamma^\beta_{\mu\beta}F^{\alpha\mu} = F^{\alpha\beta}_{;\beta}\).
Notably it doesn't equal zero.

    Antisymmetry time! the middle term is 0. All flipped terms cancel, and
all diagonal terms are zero. Thus\ldots{}

\(\Rightarrow F^{\alpha\beta}_{,\beta} + \Gamma^\beta_{\mu\beta}F^{\alpha\mu} = F^{\alpha\beta}_{;\beta}\).

\(\Rightarrow F^{\alpha\beta}_{,\beta} + \frac{\sqrt{-g}_{,\mu}}{\sqrt{-g}}F^{\alpha\mu} = F^{\alpha\beta}_{;\beta}\).

    We note that this is effectively the same inverse derivative as before.
All we have to do is adjust indeces, let \(\beta \mu -> \nu\) and then
we get what we sought.

Finally.

    \emph{d)
\(g^{\alpha\beta}g_{\beta\mu,\nu} = -g^{\alpha\beta}_{,\nu} g_{\beta\mu}\)
(hint, what is \(g^{\alpha\beta}g_{\beta\mu}\)?)}

    Actually we can show this one by argument. This ALSO suggests that the
Cirstoffel equation for the derviative is wrong since this relation is
taken without adjusting the minus sign. HAH. Funny.

Regardless we can think of this like taking the derivative of the whole.
Take the metric and inverse metric as g and G for simplicity. (Gg)' =
gG' + g'G. except gG is just the identity matrix, which becomes the zero
matrix. This is only possible if gG' = -g'G or vice versa. Proven.

    \emph{e)
\(g^{\mu\nu}_{,\alpha} = -\Gamma^{\mu}_{\beta\alpha}g^{\beta\nu} - \Gamma^{\nu}_{\beta\alpha}g^{\mu\beta}\)
Hint: use 6.31}

6.31: \(g_{\alpha\beta;\gamma}=0\) in any basis.

    First, we note that \(g^{\mu\nu}_{;\alpha}=0\) for all metrics in all
refernce frames, so
\(g^{\mu\nu}_{,\alpha} + \Gamma^\mu_{\beta\alpha}g^{\beta\nu} + \Gamma^\nu_{\beta\alpha}g^{\beta\mu} = 0\).
Which trivially becomes what we want.

Turns out this hint applies to the problems above too!

    \hypertarget{problem-35-back-to-top}{%
\section{\texorpdfstring{Problem 35 {[}Back to
\hyperref[toc]{top}{]}}{Problem 35 {[}Back to {]}}}\label{problem-35-back-to-top}}

\[\label{P35}\]

\emph{Compute 20 independent ocmponetns of
\(R_{\alpha\beta\mu\nu}\)\ldots{}}

I'm going to put this nicely.

Heck no. It was hard enough and annoying enough to compute \emph{ONE}
component in \textbf{Problem 30}.

The method is simple enough. Calculate metric and inverse metric (which,
for this problem, are provided via the length of the line element. The
integration factor is everyone's friend!) From that calculate the
Christoffel symbols that we have done MULTIPLE TIMES already. And then
the derivatives. Since we're actually calculating we can take the
derivatives directly. Do this twenty times.

My goodness that would be beyond tedious\ldots{}

    \hypertarget{problem-36-back-to-top}{%
\section{\texorpdfstring{Problem 36 {[}Back to
\hyperref[toc]{top}{]}}{Problem 36 {[}Back to {]}}}\label{problem-36-back-to-top}}

\[\label{P36}\]

\emph{A four-dimensional manifold has coordinates (t,x,y,z) and line
element \(ds^2 = -(1+2\phi)dt^2 + (1-2\phi)(dx^2,dy^2,dz^2)\), where
\(|\phi(t,x,y,z)|\) \textless\textless{} 1 everywhere. At any point P
with coordinates \((t_0,x_0,y_0,z_0)\), find a coordinate transformation
to a locally inertial coordinate system, to first order in \(\phi\). At
what rate does such a frame accelerate with respect to the original
coordinates, agian to first order in \(\phi\)?}

    The metric's diagonal can be taken directly from the line element,
\((-1-2\phi, 1-2\phi, 1-2\phi, 1-2\phi)\) Note that this is close to
-1,1,1,1 but not quite, given the sign on \(\phi.\)

The determinant of this is \(-1-2\phi+(1-2\phi)^3\) and we can start to
see where the first-order approximation comes in. If we expand out the
cubed term, we'll arrive at \(-1-2\phi+1-6\phi+12\phi^2-8\phi^3.\)
Combining and ignoring second order terms, the determinant is simply
\(-8\phi\)

At any point, \(\phi\) has a value betwewn 1 and -1, so we can just
treat it like a constant, or perhaps more accurately a parameter.
Provided a \(\phi\), we will be able to find a coordinate transform to
the locally inertial coordinate system. In terms of matrices, this is
rather trivial:
\((-1/(-1-2\phi), 1/(1-2\phi), 1/(1-2\phi), 1/(1-2\phi))\). The matrix
with this diagonal will turn the metric into (-1,1,1,1).

This is sufficient to define a coordinate transformation. What we've
essentially done is apply a metric to the metric. We can then translate
this backward to get a new line element:

\[ds^2 = \frac{1}{(1+2\phi)}dt^2 + \frac{1}{(1-2\phi)}(dx^2,dy^2,dz^2)\]

    Keep in mind this is not the actual line element of our transformed
matrix, just the metric we used. Our ultimate goal is to find an
acceleration rate of the NEW frame in relation to the old one. Though,
naturally, the line element of the new frame is constant (whih is what
we wanted for it to be locally inertial). Hmm\ldots{} how DO we find an
acceleration\ldots{} or a \emph{speed} for that matter?

    Perhaps we shouldn't use the alternate metric to accomplish the
transformation but actually find the result directly. For any inertial
metric, there is always a transformation that transforms to every other
metric, and vice-versa. This transformation is determined by the
Jacobian. Which we usually calculate by \emph{knowing} the coordinate
transformation (x=whateverx') first, not the other way around.

Let our ``inertial'' forms be t', x', y', and z'.

If we think of transforming FROM the primed ineces, we get a much easier
problem, for then the metric we're transforming from is ``nearly'' the
identity, and the matrix that equals the new metric follows a
discernable pattern. Specifically, we can derive the diagonals rather
easily:

\[ \frac{\partial}{\partial t} (-t' + x' + y' + z') = -(1+2\phi) \]
\[ \frac{\partial}{\partial x} (-t' + x' + y' + z') = 1-2\phi \]
\[ \frac{\partial}{\partial y} (-t' + x' + y' + z') = 1-2\phi \]
\[ \frac{\partial}{\partial z} (-t' + x' + y' + z') = 1-2\phi \]

And naturally all of the diagonals are zero, but those relations are
harder to write. However, they are necessary conditions, otherwise there
are far too many solutions above up there. (making the four variables
translate directly along a linear path is a solution, for instance, but
that doesn't keep zero diagonals.)

Diagonals, by the way, look like this:

\[\frac{\partial t'}{\partial t}\frac{\partial t'}{\partial t} - \frac{\partial x'}{\partial t}\frac{\partial t'}{\partial x} - \frac{\partial y'}{\partial t}\frac{\partial t'}{\partial y} - \frac{\partial z'}{\partial t}\frac{\partial t'}{\partial z} = 0\]

Remember that \(\partial t'\) sections are always negative.

    So while these may not help us they do give us helpful bounds by which
to test our possible solutions.

Examining determinants, we have our determinant of \(-8\phi\). we know
this is equal to the negative square of the transformation matrix's
determinant, via 6.15, so we find it's determinant to be
\(\pm\sqrt{8\phi}\). In terms of volume element, this becomes
unambiguously \(\sqrt{8\phi}\).

Put more characteristically, \(\sqrt{8\phi}\)dtdxdydz = dt'dx'dy'dz'.

    \hypertarget{problem-37-back-to-top}{%
\section{\texorpdfstring{Problem 37 {[}Back to
\hyperref[toc]{top}{]}}{Problem 37 {[}Back to {]}}}\label{problem-37-back-to-top}}

\[\label{P37}\]

\emph{a) ``Proper Volume'' of a two-dimensional manifold is usually
called ``proper area''. Using the metric in \textbf{Problem 28},
integrate 6.18 to find the proper area of a sphere of radius r.}

    Ah, this is a matter of the integration factor!

The diagonal was \(r^2, r^2sin^2\theta\). Multiply it all together and
then square root to get the actual integration factor of
\(r^2sin\theta\) which we've used before.

For our bounds, we have two angles: \(\theta\) goes from 0 to \(\pi\)
and \(\phi\) goes twice that. The integral over \(sin\theta\) gives 2,
so the total is \(4\pi r^2\), the well known surface area of a sphere.

    \emph{b) Do the same for the three-sphere of \textbf{Problem 33}.}

    See the problem here is that we don't know our bounds.

The integration factor itself isn't that difficult:
\(r^3sin^2\chi sin\theta\). But what are the limits on our angles? We
can DEDUCE it from the original coordinate transforms. Parameters that
are only inside a cosine function only need to vary from 0 to \(\pi\) to
span all possible values, but sine functions have to go further. So we
posit that only \(\phi\) goes to \(2\pi.\) Let's see if this is
reasonable.

We do need the integral of \(sin^2\chi\) from 0 to \(\pi\). Geogebra
gives \(\pi/2\) This gets rid of the 2 from the \(sin\theta\),
suggesting that the ``surface area'' of a 3-sphere is\ldots{}
\(2\pi^2r^3\).

And Wikipedia agrees YES! Boo-yeah.

    \hypertarget{problem-38-back-to-top}{%
\section{\texorpdfstring{Problem 38 {[}Back to
\hyperref[toc]{top}{]}}{Problem 38 {[}Back to {]}}}\label{problem-38-back-to-top}}

\[\label{P38}\]

\emph{Integrate 6.8 to find the length of a circle of constant
coordinate \(\theta\) on a sphere of radius r.}

6.8: \$l = \int\_\{\lambda\_0\}\^{}\{\lambda\_1\} \textbar{}\vec V
\cdot \vec V\textbar\^{}\{1/2\} d\lambda \$

The dot product of the tangent vector of a circle to itself would be
\((0,1) \cdot (0,1)\) The metric is (1,\(r^2\)) in the case of a circle.
And yes, we are aware the problem says constant \(\theta\) but we don't
have to listen to that, we can turn this into a purely polar problem
with no loss of generality.

Thus, the dot product is \(r^2\). We take the root of this and are just
left with r.

So the full integral is \(r(\lambda_1 - \lambda_0)\)

Which means the REAL question is how much \(\lambda\) do we have on this
integral? Well\ldots{} 2\(\pi\). We're going all the way around once.
Though we should probably find the mathematical reason for this rather
than just because ``we know the trig functions.''

To do that we leave polar coordinates behind for a moment. We know that
a circle in parametric cartesian is some form of
\((sin\lambda,cos\lambda)\) for (x,y). It is easy to show that this
cycles every \(2\pi\), and in cartesian coordinates the integration is
direct 1 to 1. And if we increased the ``speed'', we would need to
increase the vectors we used at the start! So that's why it's this way.

Just to prove it to ourselves, let the circle be given by
\((sin2\lambda,cos2\lambda)\). The tengent vector given by the
derivative will be \((2sin2\lambda,2cos2\lambda)\). In pola, this is
(0,2). Which would make our dot product \(4r^2\) which is square rooted
to 2r. Then we integrate and since we're going twice as fast, we should
in the same ``time'' lambda get twice as much distance. And we do,
\(8\pi\). Tah-dah!

    \hypertarget{problem-39-back-to-top}{%
\section{\texorpdfstring{Problem 39 {[}Back to
\hyperref[toc]{top}{]}}{Problem 39 {[}Back to {]}}}\label{problem-39-back-to-top}}

\[\label{P39}\]

\emph{a) For any two vector fields \(\vec U\) and \(\vec V\), their
\textbf{Lie Bracket} is defined to be the vector field
\([\vec U, \vec V]\) with components}

\[ [\vec U, \vec V]^\alpha = U^\beta \nabla_\beta V^\alpha - V^\beta \nabla_\beta U^\alpha \]

\emph{Show that}

\[ [\vec U, \vec V] = -[\vec V, \vec U] \]

\[ [\vec U, \vec V]^\alpha = U^\beta \frac{\partial V^\alpha}{\partial x^\beta} - V^\beta \frac{\partial U^\alpha}{\partial x^\beta} \]

\emph{This is one tensor field in which partial derivatives need not be
accompanied by Christoffel symbols!}

    This is\ldots{} trivially true. Just flip U and V, note that it results
in a sign change. Huh.

    \emph{b) Show that \([\vec U, \vec V]\) is a derivative operator on
\(\vec V\) along \(\vec U\), i.e., show that for any scalar f}

\[ [\vec U, f\vec V] = f[\vec U, \vec V] + \vec V(\vec U \cdot \nabla f). \]

\emph{This is sometimes called the \textbf{Lie Derivative} with respect
to \(\vec U\) and is denoted by}

\[ [\vec U, \vec V] = \$_{\vec U} \vec V, \vec U \cdot \nabla f = \$_{\vec U} f \]

*Then eq 6.101 (the first one in this part) would be written in the more
conventional form of the Leibnitz rule for the derivative operator \$
\$\_\{\vec U\} \$ (agh, this is supposed to be the pound sign, but that
can't be typed!)*

\[ \$_{\vec U}(f\vec V) = f\$_{\vec U}\vec V + \vec V \$_{\vec U}f \]

\emph{The result of a) shows that this derivative operator may be
defined without a connection or metric, and is therefore very
fundamental.}

    This actually isn't bad at all. Just physically evaluate it, though do
so in tensor notaiton.

\[ fU^\beta \nabla_\beta V^\alpha - fV^\beta \nabla_\beta U^\alpha + V^\alpha U^\beta\nabla_\beta f f\]
First and last terms can be adjusted via product rule.
\[ = U^\beta \nabla_\beta fV^\alpha - fV^\beta \nabla_\beta U^\alpha \]

\[ = [\vec U, f\vec V]^\alpha\]

    *c)Calculate the components of the Lie Derivative of a one-form field
\(\tilde\omega\) from the knowledge that, for any vector field
\(\vec V\), \(\tilde\omega(\vec V)\) is a scalar like f above, and from
the definition that \$ \$\_\{\vec U\} \tilde\omega \$ is a one-form
field:*

\[ \$_{\vec U}[\tilde\omega(\vec V)] = (\$_{\vec U} \tilde\omega)(\vec V) + (\tilde\omega)(\$_{\vec U} \vec V) \]

\emph{This is the analog of 6.103.}

    So we're going to solve for the Lie Derivative. This is going to be a
little funky. Treat the part we're going for as G, which means the
middle term is \(G(V^\alpha)\). With this, we can start solving.

\[ U^\beta\nabla_\beta \omega_\alpha(V^\alpha) - \omega_\beta( V^\beta) \nabla_\beta  U^\alpha = G_\alpha(V^\alpha) + \omega_\alpha \left[ U^\beta \nabla_\beta V^\alpha - V^\beta \nabla_\beta U^\alpha \right]  \]

The simple and ugly answer is:

\[ \Rightarrow \left( U^\beta\nabla_\beta \omega_\alpha(V^\alpha) - \omega_\beta( V^\beta) \nabla_\beta  U^\alpha - \omega_\alpha \left[ U^\beta \nabla_\beta V^\alpha - V^\beta \nabla_\beta U^\alpha \right] \right)/V^\alpha = G_\alpha \]

Let's at least try to simplify this.

    \[ \Rightarrow \left( U^\beta\nabla_\beta \omega_\alpha V^\alpha - \omega_\beta V^\beta \nabla_\beta  U^\alpha - \omega_\alpha U^\beta \nabla_\beta V^\alpha + \omega_\alpha V^\beta \nabla_\beta U^\alpha \right)/V^\alpha = G_\alpha \]

\[ \Rightarrow \left( U^\beta\nabla_\beta \omega_\alpha V^\alpha - \omega_\alpha U^\beta \nabla_\beta V^\alpha  \right)/V^\alpha = G_\alpha \]

    Good enough.

    \hypertarget{addendum-output-this-notebook-to-latex-formatted-pdf-file-back-to-top}{%
\section{\texorpdfstring{Addendum: Output this notebook to
\(\LaTeX\)-formatted PDF file {[}Back to
\hyperref[toc]{top}{]}}{Addendum: Output this notebook to \textbackslash LaTeX-formatted PDF file {[}Back to {]}}}\label{addendum-output-this-notebook-to-latex-formatted-pdf-file-back-to-top}}

\[\label{latex_pdf_output}\]

The following code cell converts this Jupyter notebook into a proper,
clickable \(\LaTeX\)-formatted PDF file. After the cell is successfully
run, the generated PDF may be found in the root NRPy+ tutorial
directory, with filename \url{GR-06.pdf} (Note that clicking on this
link may not work; you may need to open the PDF file through another
means.)

\textbf{Important Note}: Make sure that the file name is right in all
six locations, two here in the Markdown, four in the code below.

\begin{itemize}
\tightlist
\item
  GR-06.pdf
\item
  GR-06.ipynb
\item
  GR-06.tex
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{k+kn}{import} \PY{n+nn}{cmdline\PYZus{}helper} \PY{k}{as} \PY{n+nn}{cmd}    \PY{c+c1}{\PYZsh{} NRPy+: Multi\PYZhy{}platform Python command\PYZhy{}line interface}
\PY{n}{cmd}\PY{o}{.}\PY{n}{output\PYZus{}Jupyter\PYZus{}notebook\PYZus{}to\PYZus{}LaTeXed\PYZus{}PDF}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{GR\PYZhy{}06}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Created GR-06.tex, and compiled LaTeX file to PDF file GR-06.pdf
    \end{Verbatim}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
