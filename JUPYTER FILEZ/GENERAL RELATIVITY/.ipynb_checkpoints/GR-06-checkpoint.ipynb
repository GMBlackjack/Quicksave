{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c1bfe81",
   "metadata": {},
   "source": [
    "# General Relativity Problems Chapter 6: Curved Manifolds\n",
    "\n",
    "## Authors: Gabriel M Steward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479540e4",
   "metadata": {},
   "source": [
    "https://github.com/zachetienne/nrpytutorial/blob/master/Tutorial-Template_Style_Guide.ipynb\n",
    "\n",
    "Link to the Style Guide. Not internal in case something breaks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10780970",
   "metadata": {},
   "source": [
    "### </list_source_code> NRPy+ Source Code for this module:\n",
    "None! \n",
    "\n",
    "## Introduction:\n",
    "Are we finally giong to get to actual curved space? Will the land of special relativity be left behind at long last? We've certainly spent a lot of work building up to this point...\n",
    "\n",
    "## </other>  Other (Optional): \n",
    "Placeholder. \n",
    "\n",
    "### Note on Notation:\n",
    "Any new notation will be brought up in the notebook when it becomes relevant. \n",
    "\n",
    "### Citations:\n",
    "\n",
    "<a id='1'></a>\n",
    "[1] https://www.mathwords.com/c/cofactor_matrix.htm (Cofactors)\n",
    "\n",
    "<a id='2'></a>\n",
    "[2] https://people.math.carleton.ca/~kcheung/math/notes/MATH1107/wk07/07_cofactor_expansion.html#:~:text=One%20way%20of%20computing%20the,(i%E2%88%A3n)). (Determinant method with cofactors)\n",
    "\n",
    "<a id='3'></a>\n",
    "[3] https://en.wikipedia.org/wiki/Del_in_cylindrical_and_spherical_coordinates (Spherical divergence.) \n",
    "\n",
    "<a id='4'></a>\n",
    "[4] https://math.stackexchange.com/questions/623643/divergence-in-spherical-coordinates-problem (divergence and lengths and different basis vectors)\n",
    "\n",
    "<a id='5'></a>\n",
    "[5] http://www.physics.usu.edu/Wheeler/GenRel2013/Notes/Geodesics.pdf Geodesics, spherical metrics. \n",
    "\n",
    "<a id='6'></a>\n",
    "[6] https://physics.stackexchange.com/questions/506086/counting-independent-components-of-the-riemann-curvature-tensor (what antisymmetry means for R)\n",
    "\n",
    "<a id='7'></a>\n",
    "[7] https://math.libretexts.org/Bookshelves/Calculus/Book%3A_Calculus_(OpenStax)/12%3A_Vectors_in_Space/12.7%3A_Cylindrical_and_Spherical_Coordinates#:~:text=To%20convert%20a%20point%20from,and%20z%3D%CF%81cos%CF%86. (spherical Coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56664bc2",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "\n",
    "# Table of Contents\n",
    "$$\\label{toc}$$\n",
    "\n",
    "[Problem 1](#P1) (What are Manifolds?)\n",
    "\n",
    "[Problem 2](#P2) (Manifold Metrics)\n",
    "\n",
    "[Problem 3](#P3) (Proof of Metric Transform's Existence)\n",
    "\n",
    "[Problem 4](#P4) (Local Flatness Theorem)\n",
    "\n",
    "[Problem 5](#P5) (Curved and Flat Christoffel Coefficients)\n",
    "\n",
    "[Problem 6](#P6) (A Vanishing Proof)\n",
    "\n",
    "[Problem 7](#P7) (Derivative of the Metric Determinant)\n",
    "\n",
    "[Problem 8](#P8) (Divergence Algebra)\n",
    "\n",
    "[Problem 9](#P9) (Divergence Algebra II)\n",
    "\n",
    "[Problem 10](#P10) (Triangles R Round, skipped, too nightmarish--but includes the paralell transport method)\n",
    "\n",
    "[Problem 11](#P11) (Christoffel Coefficients and Index Manipulaiton Again)\n",
    "\n",
    "[Problem 12](#P12) (Affine Parameters)\n",
    "\n",
    "[Problem 13](#P13) (Dot Prodcuts, Transport, and Spacetime Geodesics)\n",
    "\n",
    "[Problem 14](#P14) (Geodesics and Affine Parameters)\n",
    "\n",
    "[Problem 15](#P15) (Geodesic Perturbation, skipped)\n",
    "\n",
    "[Problem 16](#P16) (Curvature Derivations)\n",
    "\n",
    "[Problem 17](#P17) (Messing with the R-tensor)\n",
    "\n",
    "[Problem 18](#P18) (Independent Terms of R)\n",
    "\n",
    "[Problem 19](#P19) (Confirmation that polar coordiantes are stil flat)\n",
    "\n",
    "[Problem 20](#P20) (Double Covariant Derivative)\n",
    "\n",
    "[Problem 21](#P21) (Clever Arguments about \"Paralellism\")\n",
    "\n",
    "[Problem 22](#P22) (Full Derivation of Why Curved Spaces Do Not Retain Paralellism)\n",
    "\n",
    "[Problem 23](#P23) (\"Simple Proof\")\n",
    "\n",
    "[Problem 24](#P24) (Clever Cancelations)\n",
    "\n",
    "[Problem 25](#P25) (Ricci Tensor Probabilities)\n",
    "\n",
    "[Problem 26](#P26) (Callback)\n",
    "\n",
    "[Problem 27](#P27) (The Einstein Tensor Full Derivation)\n",
    "\n",
    "[Problem 28](#P28) (Spherical Metric)\n",
    "\n",
    "[Problem 29](#P29) (Actually Calculate R. Oh no.)\n",
    "\n",
    "[Problem 30](#P30) (Cylinderical Metric and R. Solved, but had to use an alt method, official one resulted in a sign error.)\n",
    "\n",
    "[Problem 31](#P31) (Covariant differentiation, skipped.)\n",
    "\n",
    "[Problem 32](#P32) (Signature of Determinant)\n",
    "\n",
    "[Problem 33](#P33) (Three-Sphere, part b's detials skipped.)\n",
    "\n",
    "[Problem 34](#P34) (Additional Properties of the Metric and Tensors.)\n",
    "\n",
    "[Problem 35](#P35) (Compute a full R. Skipped, for obvious reasons.)\n",
    "\n",
    "[Problem 36](#P36) (trying to define a coordinate transform backward.)\n",
    "\n",
    "[Problem 37](#P37) (Surface area of sphere and 3-sphere.)\n",
    "\n",
    "[Problem 38](#P38) (The length of a circle the hard way.)\n",
    "\n",
    "[Problem 39](#P39) (Lie Algebra)\n",
    "\n",
    "[PDF](#latex_pdf_output) (turn this into a PDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daf72fa",
   "metadata": {},
   "source": [
    "<a id='P1'></a>\n",
    "\n",
    "# Problem 1 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P1}$$ \n",
    "\n",
    "*Decide if the following sets are manifolds and say why. If there are any exceptional points at which the sets are not manifolds, give them:*\n",
    "\n",
    "*a) Phase space of Hamiltonian mechanics, the space of the canonical coordinates and momenta $p_i$ and $q^i$*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fdcca3",
   "metadata": {},
   "source": [
    "A manifold is best thought of as just a parameterizable space. The space of coordinates and momentum are perfectly fine in this way, and are in fact often mapped to cartesian grids in the first place. So yes, this is a manifold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0d8a4",
   "metadata": {},
   "source": [
    "*b) The interior of a circle of unit radius in two-dimensional Euclidian space*\n",
    "\n",
    "Is a manifold everywhere except the center, much like polar coordinates. (Note: we are definitely assuming that we can parameterize however we want.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5152680e",
   "metadata": {},
   "source": [
    "*c) The set of permutations of n objects.*\n",
    "\n",
    "This would be a no. Because we need CONTINUOUS parameterization. No matter how fancy the set of permutations is, it's still discrete. "
   ]
  },
  {
   "attachments": {
    "Screenshot%20from%202022-05-29%2014-18-43.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "68c8eb3d",
   "metadata": {},
   "source": [
    "*d) The subset of Euclidean space of two dimensions (coordinates x and y) which is a solution to xy$(x^2+y^2-1)$=0*\n",
    "\n",
    "Well this is interesting...\n",
    "\n",
    "![Screenshot%20from%202022-05-29%2014-18-43.png](attachment:Screenshot%20from%202022-05-29%2014-18-43.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd866a",
   "metadata": {},
   "source": [
    "The circle by itself can clearly be a manifold (of one dimension too!) but the rest? Discontinuities all over the place... no, I don't think this is a manifold, as trying to parameterize it doesn't seem to pan out. \n",
    "\n",
    "As for a more strict reason why not... er... So define the angle around the circle as one dimension, right? Well, suddenly that dimension can't be used if the distance from the origin is anything but 1--that is, it becomes FOUR DISCRETE VALUES, not continuous. \n",
    "\n",
    "If we could trace a single line through the shape that covers every portion, we would have a way out. However we have four \"exit\" points which makes that impossible, meaning we do need two parameters for this space, of which no continouous one exists. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8575b66",
   "metadata": {},
   "source": [
    "<a id='P2'></a>\n",
    "\n",
    "# Problem 2 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P2}$$ \n",
    "\n",
    "*Of the manifolds in **Problem 1**, on which is it customary to use a metric, and what is that metric? On which would a metric not normally be defined and why?*\n",
    "\n",
    "First of all the permutaiions and \"sniper shot\" set can be dismissed, as they are not manifolds, which just leaves Phase Space and The Circle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67fd7b",
   "metadata": {},
   "source": [
    "For Phase Space, it's generally just a cartesian metric, so it's the cartesian metric. \n",
    "\n",
    "For the circle, one would use the radial metric. However, it's not actually customary to do this, as most use unit vectors which are decidedly not coordinate bases. usually this isn't a problem as cartesian circles have identical one forms and vectors so there's no need to convert. \n",
    "\n",
    "((Perhaps later understanding will be gained that makes all of this look silly. Maybe the \"sniper shot\" really is a manifold, though clearly a metric wouldn't be very helpful as it's not smooth at all anywhere. Look at those holes...))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27331da9",
   "metadata": {},
   "source": [
    "<a id='P3'></a>\n",
    "\n",
    "# Problem 3 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P3}$$ \n",
    "\n",
    "*It is well known that for any symmetric matrix A (with real entries) ther exists a matrix H for which the matrix $H^TAH$ is a diagonal matrix whos entries are the eigenvalues of A.*\n",
    "\n",
    "*a) Show that there is a matrix R such that $R^TH^TAHR$ is the same matrix as $H^TAH$ except with the eigenvalues rearranged in ascending order along the main diagonal from top to bottom.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976c2b0",
   "metadata": {},
   "source": [
    "So we start by knowing that there is a diagonal matrix. What we need to show is that there exists a \"shuffling\" matrix that can re-arrange the eigenvalues. Note: we just need to show that one exists. It could be anything, and it doesn't have to be \"smart\" about it, that is, it doesn't have to *choose* the highest value to go to the highest place. \n",
    "\n",
    "R will be a matrix with 1 and 0 values off the diagonal (or on the diagonal if a value is already in the right spot). Note that R itself will be a symmetric matrix, using \"1\" values off the edge to swap the position of two eigenvalues. If more than one swap needs to be done, R can just be a combination of all the matrices required to do the swap. \n",
    "\n",
    "Good stuff, proven. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d70265",
   "metadata": {},
   "source": [
    "*b) Show that there exists a third matrix such that $N^TR^TH^TAHRN$ is a diagonal matrix whose entries on the diagonal are -1,0, or +1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff633b",
   "metadata": {},
   "source": [
    "This one's even easier. Let N itself be a diagonal matrix, so that all the values are simply diagnonal values multiplied by diagonal values, there is no swapping or moving. In this case, transpose matrix multiplicaiton is commutative, so we can just make $N^TN$ = NN. We do this so we can define N to be its own transpose and say that the NN matrix is just 1/|eigenvalue| of every eigenvalue in the right position. This will reduce everything into units. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1f1102",
   "metadata": {},
   "source": [
    "*c) Show that if A has an inverse, none of the diagonal elements in b) is zero.*\n",
    "\n",
    "If you have a zero eigenvalue, then the determinant is zero, which means the matrix has no inverse. \n",
    "\n",
    "So you have to have all your eigenvalues to be invertible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b06b1",
   "metadata": {},
   "source": [
    "*d) Show from a)-c) that there exists a transformation matrix $\\Lambda$ which produces 6.2*\n",
    "\n",
    "6.2 is just the general metric tensor $\\eta$ with diagonal. (-1,1,1,1). \n",
    "\n",
    "Assuming A is invertible (it better be), then we automatically have a way to convert to $(\\pm1,\\pm1,\\pm1,\\pm1)$. When building your nice transformation matrix, just be sure to add a final matrix to the end: one that changes the signs along the diagonal to what we need. \n",
    "\n",
    "What about the fact that some of our matrices are past the right side? We can easily move N across, but what about R and H? All we can really say for sure is that there exists a SANDWICH around A that produces the correct metric, that is $L^TAL = \\textbf{g}$. \n",
    "\n",
    "But let's think about what this means, expanding it into tensor notation.\n",
    "\n",
    "$$ L^{\\alpha'}_{\\beta} A^\\beta_{\\delta} L^{\\delta}_{\\gamma'} = L^{\\alpha'}_{\\beta} L^{\\delta}_{\\gamma'}  A^\\beta_{\\delta} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b11c02",
   "metadata": {},
   "source": [
    "So the quesiton now is, can the actions of the two matrices be done by one? The only fact we have is that one is the transpose of the other. Playing the game of transposes does nothing. \n",
    "\n",
    "How on earth does $ L^T A L = \\eta \\rightarrow \\Lambda A = \\eta $.\n",
    "\n",
    "All we've proven is that there exists a \"sandwich\" that will transform A into the standard metric, not a **single** matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e342e45",
   "metadata": {},
   "source": [
    "Wait, hold on, we're stupid. \n",
    "\n",
    "The transformation matrix IS NOT USED ONLY ONCE TO TRANSFORM A MATRIX. \n",
    "\n",
    "The matrix transforms one of the basis vectors. \n",
    "\n",
    "TO GET A FULL TRANSFORM ANY MATRIX MUST BE USED TWICE. Once for the rows, once for the columns.\n",
    "\n",
    "That's what the transpose notaiton MEANS. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee857e",
   "metadata": {},
   "source": [
    "<a id='P4'></a>\n",
    "\n",
    "# Problem 4 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P4}$$ \n",
    "\n",
    "*Prove the following results used in the proof of the local flatness theorem in Section 6.2*\n",
    "\n",
    "*a) the number of independent values of $\\partial^2x^\\alpha/\\partial x^{\\gamma'} \\partial x^{\\mu'}|_0$ is 40*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a0bcc",
   "metadata": {},
   "source": [
    "We're looking for independent values of a matrix, here. We know we are symmetric in $\\gamma$ and $\\mu$ since the order you take derivatives in does not matter. For a symmetric 2x2 matrix, there are 10 independnet values (4 along the diagonal, 6 off-diagonals).\n",
    "\n",
    "Simply multiply this by the four indeces on top to get 40. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7bab0",
   "metadata": {},
   "source": [
    "*b) the number of independent values of $\\partial^3x^\\alpha/\\partial x^{\\lambda'} \\partial x^{\\mu'} \\partial x^{\\nu'}|_0$ is 80*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8028e18",
   "metadata": {},
   "source": [
    "What is the symmetry along a 4x4x4 3D symmetry matrix? We have to look at combinations here, every simple two-fold shuffling will be the same. So let's just list unique numbers. \n",
    "\n",
    "000\n",
    "\n",
    "111\n",
    "\n",
    "222\n",
    "\n",
    "333\n",
    "\n",
    "These are the diagonal, they are independent, and there are four of them. Now let's classify all the others:\n",
    "\n",
    "001 = 010 = 100\n",
    "\n",
    "110 = 101 = 011\n",
    "\n",
    "So each combination of two numbers has 3 permutations. We have 10, 12, 13, 20, 23, 30. That Gives us 12 independent places. \n",
    "\n",
    "123 = 231 = 312 = 321 = 213 = 132\n",
    "\n",
    "Every combination of three numbers gives 6 permutation. as there are four different combinations of three, we have 4 independent places.\n",
    "\n",
    "4 + 12 + 4 = 20. \n",
    "\n",
    "20 differentiated four ways produces 80. As we were supposed to have. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa86a6e",
   "metadata": {},
   "source": [
    "*c) The corresponding number for $g_{\\alpha\\beta,\\gamma',\\mu'}|_0$ is 100*\n",
    "\n",
    "First of all, on page 150, we see that the metric itself has 10 independent terms. Why? While it is symmetric, aren't all numbers aside from the diagonal zero? Well, no actually, the metric can be transformed into many things, not all of which are along the diagonal, but it must be symmetric, so we have 10 independent for hte base matric. \n",
    "\n",
    "The base metric differentiated once is obviously just 10 times 4 = 40. \n",
    "\n",
    "However, what we want is the metric differentiated *twice*. \n",
    "\n",
    "Fortunately we know that taking derivatives in eitehr order don't change anything, so the \"derivative\" matrix itself is symmetric, arriving at 10 independent terms. \n",
    "\n",
    "10 by 10 is 100, and we are done! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875fc34",
   "metadata": {},
   "source": [
    "<a id='P5'></a>\n",
    "\n",
    "# Problem 5 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P5}$$ \n",
    "\n",
    "*a) Prove that $\\Gamma^\\mu_{\\alpha\\beta} = \\Gamma^\\mu_{\\beta\\alpha}$ in any coordinate system in a curved Reimannian space.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e3ec6a",
   "metadata": {},
   "source": [
    "Actually 5.74 points out that it is already true for ANY coordinate system, but lets go through the proof as to why.\n",
    "\n",
    "To start, we consider an arbitrary scalar field $\\phi$, that is, a rule for getting numbers out of every point on some space. Plug in various numbers, get a single number out. It's first derivative is a one-form: $\\nabla \\phi$ with components $\\phi_{,\\beta}$, that is to day derivatives taken with respect to every single coordinate. We don't care how many there are, there could be thousands. \n",
    "\n",
    "the second covariant derivative $\\nabla\\nabla\\phi$ has components $\\phi_{,\\beta ;\\alpha}$ and it should be rather obvious that this is a $0\\choose2$ tensor. (one form it twice). We do find ourselves asking why one of them has a comma and the other a semicolon... the reason, it turns out, is because first we were differentiating a scalar, but the second one had us differentiating a one-form which will always add the Christoffel symbol. \n",
    "\n",
    "Regardless, since this second derivative is a tensor, we note that it is the same no matter what basis it is in. Since we can alter the order of differentiation and change absolutely nothing in cartesian coordiantes, we can alter the order here. So...\n",
    "\n",
    "$\\phi_{,\\alpha;\\beta} = \\phi_{,\\beta;\\alpha}$\n",
    "\n",
    "Now if we expand these we end up with things of the form $\\phi_{,\\alpha,\\beta} - \\phi_{,\\mu} \\Gamma^\\mu_{\\beta\\alpha} = \\phi_{,\\beta,\\alpha} - \\phi_{,\\mu} \\Gamma^\\mu_{\\alpha\\beta} $\n",
    "\n",
    "Of course we ALSO know that the individual derivative terms are also always interchangeable in any coordinate system. So that jsut leaves...\n",
    "\n",
    "$$ \\phi_{,\\mu} \\Gamma^\\mu_{\\beta\\alpha} = \\phi_{,\\mu} \\Gamma^\\mu_{\\alpha\\beta} $$\n",
    "\n",
    "Which rather trivially shows that the Christoffel coefficients are the same no matter WHAT coordinate system we are in. This hinges on two main facts: 1) that derivative order does not matter and 2) tensors are the same in every coordinate system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec566d1b",
   "metadata": {},
   "source": [
    "*b) Use this to prove that 6.32 can be derived in the same manner as in flat space.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0dd0bc",
   "metadata": {},
   "source": [
    "The derivation, so far as we can tell, is exactly the same since any curved space is locally flat. By that rule alone, anything that can have a metric assigned to it can have calculated Christoffel coefficietns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed823c8",
   "metadata": {},
   "source": [
    "<a id='P6'></a>\n",
    "\n",
    "# Problem 6 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P6}$$ \n",
    "\n",
    "*Prove that the first term in 6.37 vanishes.*\n",
    "\n",
    "6.37: $ \\Gamma^\\alpha_{\\mu\\alpha}=\\frac12 g^{\\alpha\\beta} (g_{\\beta\\mu,\\alpha} - g_{\\mu\\alpha,\\beta}) + \\frac12 g^{\\alpha\\beta} g_{\\alpha\\beta,\\mu} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d31e2",
   "metadata": {},
   "source": [
    "First of all, note that $g^{\\alpha\\beta}$ is symmetric by definition. \n",
    "\n",
    "The term in the parenthesis is antisymmetric in $\\alpha\\beta$ since when they flip, the two terms essentially swap places. (note: the first two indeces on g make no change as g itself is symmetric.) Thus, every difference is also going to have it's inverse. \n",
    "\n",
    "We note that we are summing over the exact antisymmetric indeces, so every single value is going to be added to every other one. If the magnitudes of both are the same, they cancel. and whatddoyaknow, we already established that our leading term was symmetric! So it alllll vanishes! \n",
    "\n",
    "Proof complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee5b7d",
   "metadata": {},
   "source": [
    "<a id='P7'></a>\n",
    "\n",
    "# Problem 7 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P7}$$ \n",
    "\n",
    "*a) Give the definition of the determinant of a matrix A in terms of cofactors of elements.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b0e322",
   "metadata": {},
   "source": [
    "We actually know this method from linear albegra: it's how you calculate determinants of large matrices by hand since the \"rules\" no longer apply. The cofactor of a term is defined as the number that pops out when one takes the determinant of the rest of the matrix via [1](#1).\n",
    "\n",
    "This means if, somehow, one HAS the cofactors, they also have the determinant for every matrix with a row and column removed from the total matrix. It does require that we have a SQUARE MATRIX, but that is exactly what we're workng with below so we're good. \n",
    "\n",
    "The exact method by which the determinant is found is given by [2](#2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd771fbb",
   "metadata": {},
   "source": [
    "First, pick any row or column. Multiply the terms of that row by their cofactors AND by a sign adjustment matrix. The sign adjustment cares about even/odd indeces, and can be written as:\n",
    "\n",
    "$$ I^{\\alpha\\beta} = \\begin{bmatrix}\n",
    "1 & -1 & 1 & ... \\\\ \n",
    "-1 & 1 & -1 & ... \\\\\n",
    "1 & -1 & 1 & ... \\\\\n",
    "... & ... & ... & ...\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Which basicaly just assigns even-ness and odd-ness to the various locations. \n",
    "\n",
    "Anyway, let our matrix be $A^{\\alpha\\beta}$, our cofactors be $C^\\alpha_\\beta$, and our adjustor (it is kind of like a metric) be $I^{\\alpha\\beta}$. Then the result is...\n",
    "\n",
    "$$ I^{\\alpha\\beta}A^{\\alpha\\beta}C^\\alpha_\\beta $$.\n",
    "\n",
    "Essentially a sum over a single row or column (row in the above case) that results in a number with only one index, $\\alpha$. An important part of the determinant is that no matter what $\\alpha$ is, the number is always the same. It doesn't matter which row or column we expanded over. \n",
    "\n",
    "(Not sure this works... but only the concept is required for c), which genrealizes b). b) is the part that needs to be shown.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32405e",
   "metadata": {},
   "source": [
    "*b) Differentiate the determinant of an arbitrary 2x2 matrix and show that it satisfies 6.39*\n",
    "\n",
    "6.39: $g_{,\\mu} = g g^{\\alpha\\beta}g_{\\beta\\alpha,\\mu}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a86b3",
   "metadata": {},
   "source": [
    "So our goal is to show this is true for all matrices, not just metrics. Okay, let's define an matrix (a,b)(c,d) and indicate differentiation by '--seeing as we're only differentiating with respect to one variable at a time. \n",
    "\n",
    "The determinant woudl be ad-cb. Differentiating this would produce a'd+ad' - c'b-cb'. \n",
    "\n",
    "Differentiating the matrix gives (a',b')(c'.d'). \n",
    "\n",
    "We will now represent INVERSE terms with an exponent -1, which is exactly what we need in the inverse matrix. \n",
    "\n",
    "$(a^{-1},b^{-1})(c^{-1},d^{-1})$\n",
    "\n",
    "So putting it ALL together, we get:\n",
    "\n",
    "$$ a'd+ad' - c'b-cb' = (ad-cb)(a^{-1}a' + d^{-1}d' + c^{-1}b' + b^{-1}c') $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a8f098",
   "metadata": {},
   "source": [
    "It may help to note down all the sums of a 2x2 inverse and how exactly they relate to results:\n",
    "\n",
    "$$ a^{-1}a + b^{-1}c = 1 $$\n",
    "$$ a^{-1}b + b^{-1}d = 0 $$\n",
    "$$ c^{-1}a + d^{-1}c = 0 $$\n",
    "$$ c^{-1}b + d^{-1}d = 1 $$\n",
    "\n",
    "So when we expand our sum we get:\n",
    "\n",
    "$$ \\Rightarrow a'd+ad' - c'b-cb' = ada^{-1}a' + add^{-1}d' + adc^{-1}b' + adb^{-1}c' - cba^{-1}a' - cbd^{-1}d' - cbc^{-1}b' - cbb^{-1}c' $$\n",
    "\n",
    "By converting various terms that have hte form $x^-1 x = 1 - b^-1 b$ we are able to use the \"1\" term to get individual temrs out fron that will compeltely cancel the left side of the equation. The result is an =0 situation:\n",
    "\n",
    "$$ \\Rightarrow 0 = -b^{-1}cda' - c^{-1}bd'a + adc^{-1}b' + adb^{-1}c' - cba^{-1}a' - cbd^{-1}d' + d^{-1}dcb' + a^{-1}abc' $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ca336",
   "metadata": {},
   "source": [
    "Unfortunately the things don't jsut \"cancel\" yet. Perhaps the =0 relations can help us. \n",
    "\n",
    "Actually yes! all the terms we DIDN'T change can be transformed by this. Take, for example: $-cba^{-1}a' = +cdb^{-1}a'$ which is the same as the first term but inverted. This happens for all four terms, reducing to zero, thus we have proven the relation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bf24d4",
   "metadata": {},
   "source": [
    "*c) Generalize 6.39 (by induction or otherwise) to arbitrary nxn matrices.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2fead",
   "metadata": {},
   "source": [
    "Assuming b) to be true... (we did go back and prove it.)\n",
    "\n",
    "Every matrix in existence can be disassembled into 2x2 matrices using the cofactors. Thus, the derivative of the determinant can be split into a sum of various 2x2 matrices, all of which are part of the original determinant in the same way. What we end up with is a bunch of 2x2 matrices that can correlated directly with other 2x2 matrices of the determinant times the strange addition of the inverse and normal matrix. \n",
    "\n",
    "Thus, it works for any nxn matrix. \n",
    "\n",
    "Now if only we had actually proven b)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fdf555",
   "metadata": {},
   "source": [
    "<a id='P8'></a>\n",
    "\n",
    "# Problem 8 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P8}$$ \n",
    "\n",
    "*Fill in the missing algebra leading to 6.40 and 6.42*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dbd19b",
   "metadata": {},
   "source": [
    "We seek: 6.40: $ \\Gamma^\\alpha_{\\mu\\alpha} = \\frac{(\\sqrt{-g})_{,\\mu}} {\\sqrt{-g}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cebc754",
   "metadata": {},
   "source": [
    "We have:\n",
    "\n",
    "6.38: $\\Gamma^\\alpha_{\\mu\\alpha} = \\frac12 g^{\\alpha\\beta} g_{\\alpha\\beta,\\mu}$\n",
    "\n",
    "6.39: $g_{,\\mu} = g g^{\\alpha\\beta}g_{\\beta\\alpha,\\mu}$\n",
    "\n",
    "Which becomes\n",
    "\n",
    "$\\frac{g_{,\\mu}}{g} = g^{\\alpha\\beta}g_{\\beta\\alpha,\\mu}$\n",
    "\n",
    "Which would imply, since the metric is symmetric and the indeces can be swapped at will...\n",
    "\n",
    "$$\\Gamma^\\alpha_{\\mu\\alpha} = \\frac12 \\frac{g_{,\\mu}}{g}$$\n",
    "\n",
    "One would think this is wrong, and it really looks it... but let's take a moment to work backward. Take the derivative of $\\sqrt{-g}$, the result is $\\frac{-1}{2\\sqrt{-g}}g_{,\\mu}$. Which means the seemingly improbable relation\n",
    "\n",
    "$$ \\frac12 \\frac{g_{,\\mu}}{g} = \\frac{-1}{2\\sqrt{-g}}g_{,\\mu} \\frac{1}{\\sqrt{-g}} = \\frac{(\\sqrt{-g})_{,\\mu}} {\\sqrt{-g}} $$\n",
    "\n",
    "is true. Funky."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25511c21",
   "metadata": {},
   "source": [
    "With 6.40 to be true, we have the divergence 6.36:\n",
    "\n",
    "$$ V^\\alpha_{;\\alpha} = V^\\alpha_{,\\alpha} + \\Gamma^\\alpha_{\\mu\\alpha} V^\\mu$$\n",
    "$$  = V^\\alpha_{,\\alpha} +  \\frac{(\\sqrt{-g})_{,\\mu}} {\\sqrt{-g}} V^\\mu$$\n",
    "\n",
    "Since there's only one index left on every term might as well make it all $\\alpha$. (it's what the multiplication would do anyway).\n",
    "\n",
    "$$  = V^\\alpha_{,\\alpha} +  \\frac{(\\sqrt{-g})_{,\\alpha}} {\\sqrt{-g}} V^\\alpha$$\n",
    "\n",
    "My, this looks a lot like the chain rule, doesn't it? If we invert it, we arrive at 6.42 directly. \n",
    "\n",
    "$$  = \\frac{1}{\\sqrt{-g}}( V^\\alpha \\sqrt{-g})_{,\\alpha}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78643af9",
   "metadata": {},
   "source": [
    "<a id='P9'></a>\n",
    "\n",
    "# Problem 9 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P9}$$ \n",
    "\n",
    "*Show that 6.42 leads to 5.56. Derive the divergence formula for the metric in 6.19*\n",
    "\n",
    "6.42: $V^\\alpha_{;\\alpha} = \\frac{1}{\\sqrt{-g}}( V^\\alpha \\sqrt{-g})_{,\\alpha}$\n",
    "\n",
    "5.56: $V^\\alpha_{;\\alpha} = \\frac{1}{r} \\frac{\\partial}{\\partial r} (rV^r) + \\frac{\\partial}{\\partial\\theta} V^\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a74ae",
   "metadata": {},
   "source": [
    "Well first of all the metric for polar coordinates has the diagonal (1,$r^2$), making its determinant a rather evident $r^2$. Do note that we have a lot of annoying negative roots now--HOWEVER, we are NOT in four space, so we recognize that the minus sign actually isn't there, instead, the proper volume is just $\\sqrt g$ which, in this case, is just r. \n",
    "\n",
    "$$V^\\alpha_{;\\alpha} = \\frac{1}{r}( V^\\alpha r)_{,\\alpha}$$\n",
    "$$ = \\frac{1}{r}( V^r r)_{,r} + \\frac{1}{r}( V^\\theta r)_{,\\theta} $$\n",
    "$$ = \\frac{1}{r}(r V^r)_{,r} + V^\\theta_{,\\theta} $$\n",
    "\n",
    "Which is just another way of writing 5.56."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163eccbf",
   "metadata": {},
   "source": [
    "Now 6.19 is the spherical coordinates. The proper volume is still the positive square root of g, and the determinant itself is $r^4sin^2\\theta$ which gives us $r^2sin\\theta$ as what we used to know as the *integration factor*. \n",
    "\n",
    "With that, we start writing it out.\n",
    "$$V^\\alpha_{;\\alpha} = \\frac{1}{r^2 sin\\theta}( V^\\alpha r^2 sin\\theta)_{,\\alpha}$$\n",
    "$$V^\\alpha_{;\\alpha} = \\frac{1}{r^2 sin\\theta}( V^r r^2 sin\\theta)_{,r} + \\frac{1}{r^2 sin\\theta}( V^\\theta r^2 sin\\theta)_{,\\theta} + \\frac{1}{r^2 sin\\phi}( V^\\phi r^2 sin\\theta)_{,\\phi}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb52dd",
   "metadata": {},
   "source": [
    "$$V^\\alpha_{;\\alpha} = \\frac{1}{r^2}( V^r r^2)_{,r} + \\frac{1}{sin\\theta}( V^\\theta sin\\theta)_{,\\theta} + V^\\phi_{,\\phi}$$"
   ]
  },
  {
   "attachments": {
    "Screenshot%20from%202022-05-31%2011-28-48.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "1d7ce56f",
   "metadata": {},
   "source": [
    "Which seems fine, but googling the spherical divergence doesn't actually produce this. The radial term is correct, but the others maybe not. However, we did note that it was possible to have other bases in the same thing making the divergence change, so that may not mean this is wrong. It sure seems reasonable that the $\\phi$ term is the way it is, for instance, since there is no $\\phi$ dependence in the proper volume. \n",
    "\n",
    "The result it should be, by the way, from [3](#3) is\n",
    "\n",
    "![Screenshot%20from%202022-05-31%2011-28-48.png](attachment:Screenshot%20from%202022-05-31%2011-28-48.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08716d",
   "metadata": {},
   "source": [
    "Which, agian, we suppose might be equivalent if the bases are defined somewhat differently, we really aren't sure. Looking at [4](#4) this appears to actually be the case. If we divide each interior term by its \"length\" notated by the metric itself, we get a different result:\n",
    "\n",
    "$$V^\\alpha_{;\\alpha} = \\frac{1}{r^2 sin\\theta}( V^r r^2 sin\\theta)_{,r} + \\frac{1}{r^2 sin\\theta}( V^\\theta r^2 sin\\theta \\frac{1}{r})_{,\\theta} + \\frac{1}{r^2 sin\\phi}( V^\\phi r^2 sin\\theta \\frac{1}{r sin\\theta})_{,\\phi}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8210ab6a",
   "metadata": {},
   "source": [
    "Which rather immediately reduces to the correct divergence. \n",
    "\n",
    "Which raises a question, what happens if we do this to the radial version?\n",
    "\n",
    "$$V^\\alpha_{;\\alpha} = \\frac{1}{r}( V^r r)_{,r} + \\frac{1}{r}( V^\\theta r \\frac{1}{r})_{,\\theta} = \\frac{1}{r}( V^r r)_{,r} + \\frac{1}{r}V^\\theta_{,\\theta}$$\n",
    "\n",
    "Which is equation 5.87. \n",
    "\n",
    "All this confusion arose from a simple misunderstanding: we read 5.56 and thought it was the unit vector version. No, no it isn't, it's the coordinate basis version.\n",
    "\n",
    "Now we also know the coordinate version of spherical divergence. Neat!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743b6cf",
   "metadata": {},
   "source": [
    "<a id='P10'></a>\n",
    "\n",
    "# Problem 10 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P10}$$ \n",
    "\n",
    "*A 'straight line' on a sphere is a great circle, and it is well known that the sum of the interior angles of any triangle on a sphere whose sides are arcs of great circles exceeds 180 degrees. Show that the amount by which a vector is rotated by parallel transport around such a triangle (Fig 6.3) equals the excess of the sum of the angles over 180 degrees.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27810a3",
   "metadata": {},
   "source": [
    "This isn't the general case, but for hte case of a triangle with two right angles it's easy to see: draw a line from the pole to the equator, and then draw a line on the equator. The third line will go from somewhere on the equator to the pole. \n",
    "\n",
    "Vector transport is accomplished visually: go directly down the first line, then while it's transported along the equator the vector will always point \"south.\" Then on the line back up we'll go back to the pole, pointing away from the original vector at the same angle as the third non-90-degree angle. The two 90 degree angles add to 180, and the third is equal to the transport. \n",
    "\n",
    "The issue is how do we genrealize this to ALL spherical triangles? This is only a specific class of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975fcf4e",
   "metadata": {},
   "source": [
    "Oh boy this is going to be harder than it sounds. \n",
    "\n",
    "Let's assume WLOG that our triangle starts at the \"north pole\" of the sphere, effectively (1,0,0), and remember that $(r,\\theta,\\phi)$ means, physically, radius, up/down angle, and xy plane angle. We note that at the pole there is no deifned xy plane angle, but consider that \"0\" to be the direction we start \"pointing\" and drawing the first part of our triangle, again WLOG. \n",
    "\n",
    "The idea is that we will parallel transport along this $\\phi=0$ line for a while, stop, turn, and travel again. Once we've established these two sides and one angle, we now have to turn back to the pole diretly. The exact geometry for this is going to be tricky, but that means we have three completely independent variables: $S_1, S_2, \\alpha$. The angles $\\beta, \\gamma$ and $S_3$ will be determined by the others. It seems that the problem doesn't expect us to know the spherical trig rules, so the way to prove it is probably simpler and involves the paralell transport function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012da4e",
   "metadata": {},
   "source": [
    "Let's consider our vector in 3D space rather than on the surface of the sphere. How much it changes by parallel transport depends entirely on the arc length it crosses, or rather the angle that arc length is associated with. To make it simple to think about let's consider a unit sphere, so we can make radians a direct length. Traveling $\\pi$ radians flips the vector around a full one-eighty around the plane it is traveling in. A direct equation would be, with s being the distance and a being the vector's change in orientation: s=a. \n",
    "\n",
    "We can think of each \"side\" of the triangle as a rotation of the vector aroudn a specific axis. We turn around one some distance, we turn around another some distance, and then we turn around a third to get the \"physical point\" back to where we started. \n",
    "\n",
    "This means the best way to find out what's happening to our vector is to find the total length of a triangle, that is, the surface length between any three points on a sphere in the spherial coordinates. If we're going directly on one of the angular unit vectors, this is easy, but we have an arbitrary triangle, so we look up the length of a path on the surface of a sphere. \n",
    "\n",
    "Actually, wait, we can just *ignore* the length and use the change in angle directly! Each great circle could be considered a motion through $\\theta$ and THEN a motion through $\\phi$ no matter what! ...except this acutally doesn't work because this isn't cartesian and this calcluation would ignore the change due to paralell transport. We *cannot* rotate by components. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310dad6",
   "metadata": {},
   "source": [
    "So instead we fall back on looking up information in [5](#5), specifically the metric and the Christoffel coefficients for spherical space. \n",
    "\n",
    "The metric for spherical shell is:\n",
    "\n",
    "$$ \\begin{bmatrix} \n",
    "r^2 & 0 \\\\\n",
    "0 & r^2sin^2\\theta\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Which is just the spherical metric with the radial component ignored, it turns out. \n",
    "\n",
    "What we need now is a way to devise a length element from two arbitrary points and the pole. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24980215",
   "metadata": {},
   "source": [
    "New way to think about it: The relative orientation of the tangent vector and the vector being translated needs to be the same. In the case of going down from the pole, the vector doesn't change as far as the polar coordinates are concerned. But at that point all bets are off. \n",
    "\n",
    "THIS is what the equation $U^\\beta V^\\alpha_{;\\beta} = 0$ MEANS. U is the tangent vector, V is the vector we're transporting. The change in the vector related to the tangent vector needs to be zero. This does NOT necessarily mean the vector itself is not changing, for the tangent vector can be changing. \n",
    "\n",
    "We just need to DEFINE that tangent vector in terms of the ARBITRARY GEODESIC. Which... egh, okay that's not easy either. We can require that two of the geodesics be perfectly vertical as they both need to pass through the pole, which does simplify our math because in those cases the tangetn U never changes in spherical coordinates. (always in the $\\theta$ direction). It's the THIRD geodesic that's the problem here. \n",
    "\n",
    "In order to do this we need the parametric equation for an arbitrary geodesic. All we'll have is two points. Our question is equivalent to asking how much does the opposite side change a vector when the vertex is situated at a pole? We only have to translate ONCE. Just ONCE. \n",
    "\n",
    "Found a parametric geodesic. It's a nightmare. What are we supposed to do here??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed491a8e",
   "metadata": {},
   "source": [
    "Final Addendum: Not even Leo knew how to do this in a general case. We did, however, find the method on how to actually carry out a paralell transport given some vector and its basis. \n",
    "\n",
    "**PARALELL TRANSPORT METHOD**\n",
    "\n",
    "Paralell transport is defined as \n",
    "\n",
    "$$\\nabla_{\\vec U} \\vec V = 0$$\n",
    "\n",
    "Which can be expanded in full as \n",
    "\n",
    "$$ U^\\beta V^\\alpha_{,\\beta} + \\Gamma^\\alpha_{\\mu\\beta}V^\\mu U^\\beta = 0$$\n",
    "\n",
    "Now, we let $U^\\beta \\partial / \\partial x^\\beta = d/d\\lambda$, where $\\lambda$ is the parameter. This gets us to:\n",
    "\n",
    "$$ \\frac{dV^\\alpha}{d\\lambda} + \\Gamma^\\alpha_{\\mu\\beta} \\frac{dx^\\beta}{d\\lambda}V^\\mu = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2628bd",
   "metadata": {},
   "source": [
    "Which has justificaiton on page 156 (it's a bit confusing, but we think it has to do with if one differentiates along U in every direction it becomes identical to differentiating along the parameter of the path U is on.)\n",
    "\n",
    "This will produce $\\alpha$ differential equations that will need to be solved as a system. Not exactly simple, but it is acutally doable. The equations will need to be set to whatever the starting vector was at 0, and it will be a function of the parameter $\\lambda$. \n",
    "\n",
    "This requires us eitehr knowing the original equation's components as a function of lambda, OR parameterizing in such a way that we only go across one direction at a time, turning $\\lambda$ into some coordinate directly. (Such as x or y). \n",
    "\n",
    "For this problem it'd involve having the third geodesic in parametric form. which is a pain. Which is why we aren't doing it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659baaf5",
   "metadata": {},
   "source": [
    "<a id='P11'></a>\n",
    "\n",
    "# Problem 11 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P11}$$ \n",
    "\n",
    "*In this exercise we will consider the condition that a vector field $\\vec V$ can be considered to be globally parallel on a manifold. More precisely, what guarantees that we can find a vector field $\\vec V$ satisfying the equaiton $(\\nabla\\vec V)^\\alpha_\\beta = V^\\alpha_{;\\beta} = V^\\alpha_{,\\beta} + \\Gamma^\\alpha_{\\mu \\beta} V^\\mu = 0$?*\n",
    "\n",
    "*a) A necessary condition, called the **integrability condition** for this equation, follows from the commuting of partial derivatives. Show that $V^\\alpha_{,\\nu\\beta} = V^\\alpha_{,\\beta\\nu}$ implies*\n",
    "\n",
    "$$ (\\Gamma^\\alpha_{\\mu\\beta,\\nu} - \\Gamma^\\alpha_{\\mu\\nu,\\beta}) V^\\mu = (\\Gamma^\\alpha_{\\mu\\beta}\\Gamma^\\mu_{\\sigma\\nu} - \\Gamma^\\alpha_{\\mu\\nu} \\Gamma^\\mu_{\\sigma\\beta})V^\\sigma $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb81df6",
   "metadata": {},
   "source": [
    "This is basically saying that, so long as the derivatives commute, we end up with... this. \n",
    "\n",
    "By taking the derivatives of both the third part of the above equality and setting both versions equal to each other, we get rather quickly:\n",
    "\n",
    "$$ \\Gamma^\\alpha_{\\mu\\beta,\\nu}V^\\mu + \\Gamma^\\alpha_{\\mu\\beta}V^\\mu_{,\\nu} = \\Gamma^\\alpha_{\\mu\\nu}V^\\mu_{,\\beta} + \\Gamma^\\alpha_{\\mu\\nu,\\beta}V^\\mu $$\n",
    "$$ \\Rightarrow (\\Gamma^\\alpha_{\\mu\\beta,\\nu} - \\Gamma^\\alpha_{\\mu\\nu,\\beta}) V^\\mu = \\Gamma^\\alpha_{\\mu\\nu}V^\\mu_{,\\beta} - \\Gamma^\\alpha_{\\mu\\beta}V^\\mu_{,\\nu} $$\n",
    "\n",
    "Now we extract those derivatives by realizing we still have $V^\\alpha_{,\\beta} + \\Gamma^\\alpha_{\\mu\\beta} V^\\mu = 0$. So we can pull out a new coefficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f447155b",
   "metadata": {},
   "source": [
    "$$ \\Rightarrow (\\Gamma^\\alpha_{\\mu\\beta,\\nu} - \\Gamma^\\alpha_{\\mu\\nu,\\beta}) V^\\mu = - \\Gamma^\\alpha_{\\mu\\nu} \\Gamma^\\mu_{\\sigma\\beta} V^\\sigma + \\Gamma^\\alpha_{\\mu\\beta}\\Gamma^\\mu_{\\sigma\\nu} V^\\sigma $$\n",
    "\n",
    "Which is what we sought. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c2bec",
   "metadata": {},
   "source": [
    "*b) By relabeling indcies, work this into the form:*\n",
    "\n",
    "$$ (\\Gamma^\\alpha_{\\mu\\beta,\\nu} - \\Gamma^\\alpha_{\\mu\\nu,\\beta} + \\Gamma^\\alpha_{\\sigma\\nu} \\Gamma^\\sigma_{\\mu\\beta} - \\Gamma^\\alpha_{\\sigma\\beta} \\Gamma^\\sigma_{\\mu\\nu})V^\\mu=0 $$\n",
    "\n",
    "*this turns out to be **sufficient** as well.*\n",
    "\n",
    "Now THIS is finally something that's trivial. Taking the previous equation, all you have to do is make the swap $\\sigma <-> \\mu$ on the right side and then it falls out in one step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4927b6b3",
   "metadata": {},
   "source": [
    "<a id='P12'></a>\n",
    "\n",
    "# Problem 12 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P12}$$ \n",
    "\n",
    "*Prove that 6.52 defines a new affine parameter.*\n",
    "\n",
    "Basically, we want to show that if $\\lambda$ satisfies \n",
    "\n",
    "$$ \\frac{d^2x^\\alpha}{d\\lambda^2} + \\Gamma^\\alpha_{\\mu\\beta} \\frac{dx^\\mu}{d\\lambda} \\frac{dx^\\beta}{d\\lambda} = 0 $$\n",
    "\n",
    "Then a $\\phi$ defined by the linear transformation $\\phi = a\\lambda + b$ satisfies the equation as well.\n",
    "\n",
    "$$ \\frac{d^2x^\\alpha}{d\\phi^2} + \\Gamma^\\alpha_{\\mu\\beta} \\frac{dx^\\mu}{d\\phi} \\frac{dx^\\beta}{d\\phi} = 0 $$\n",
    "\n",
    "This is 6.51, the geodesic equation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114edce1",
   "metadata": {},
   "source": [
    "Now, the only part that changes are the derivatievs, as the coefficient should remain the same. \n",
    "\n",
    "Perhaps the best way to do this would be to imagine some entirely general functions, let's call them F, G, and H. They are all functions of $\\lambda$, and so when their derivative is taken they become f, g, and h. So we end up with, for hte $\\lambda$ case...\n",
    "\n",
    "$$ f' + \\Gamma g h = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44daf19f",
   "metadata": {},
   "source": [
    "Now, does something similar result when we take things as a funciton of phi? $\\lambda = (\\phi-b)/a$. Using the chain rule, we can show $F(\\phi/a-b/a) \\rightarrow (1/a)f(\\phi/a - b/a) \\rightarrow (1/a^2)f'(\\phi/a - b/a) $ and similar for the others. This gives a result of:\n",
    "\n",
    "$$ (1/a^2) f' + \\Gamma (1/a) g (1/a) h = 0$$\n",
    "\n",
    "Which can have the $1/a^2$ divided out to get the exact same relation we got above. So assuming $\\lambda$ qualifies, so too must $\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc82d5a",
   "metadata": {},
   "source": [
    "<a id='P13'></a>\n",
    "\n",
    "# Problem 13 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P13}$$ \n",
    "\n",
    "*a) Show that if $\\vec A$ and $\\vec B$ are parallel-transported along a curve, then $\\textbf{g}(\\vec A, \\vec B) = \\vec A \\cdot \\vec B$ is constant on the curve.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5209b",
   "metadata": {},
   "source": [
    "This is actually rather trivial. A dot product can alternatively be represented as $ABcos\\theta$ where $\\theta$ is the angle between them. (We define the angle between them as the local angle on the \"small\" area that acts like a Euclidean plane.) During parallel transport the angle between them is conserved, so their dot product must be as well. \n",
    "\n",
    "However, this would only apply to pure-space arguments, what if we had a time dimension? The reasoning after this was really stupid, so we now turn to defining it mathematically. (if one thinks the angle between the vectors is fixed for a dot product, hah, try drawing a circle in tx space, the dot product between \"same angles\" is drastically different.) Return to the definition of parallel transport.\n",
    "\n",
    "$\\nabla_{\\vec U} \\vec V = U^\\beta V^\\alpha_{;\\beta} = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24773234",
   "metadata": {},
   "source": [
    "And recall the component form of the dot product. \n",
    "\n",
    "$g_{\\alpha\\beta}A^\\alpha B^\\beta$\n",
    "\n",
    "So now we just try to change this based on the parameter, which we let be $\\tau$ today.. \n",
    "\n",
    "$$ \\frac{d}{d\\tau} g_{\\alpha\\beta}A^\\alpha B^\\beta$$\n",
    "$$ = \\frac{dg_{\\alpha\\beta}}{d\\tau} A^\\alpha B^\\beta + g_{\\alpha\\beta} \\frac{dA^\\alpha}{d\\tau} B^\\beta + g_{\\alpha\\beta}A^\\alpha \\frac{dB^\\beta}{d\\tau} $$\n",
    "\n",
    "via product rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb57e199",
   "metadata": {},
   "source": [
    "Consider each term separately. We can extract the tangent from the metric derivative. The partial / not-partial stuff is... annoying, but let's just accept it for now. \n",
    "\n",
    "$$ \\frac{d g_{\\alpha\\beta}}{d\\tau} = \\frac{\\partial g_{\\alpha\\beta}}{\\partial x^\\rho}\\frac{dx^\\rho}{d\\tau} = \\frac{\\partial g_{\\alpha\\beta}}{\\partial x^\\rho}U^\\rho $$\n",
    "\n",
    "from the paralell transport method we have:\n",
    "\n",
    "$$ \\frac{dV^\\alpha}{d\\lambda} + \\Gamma^\\alpha_{\\mu\\beta} \\frac{dx^\\beta}{d\\lambda}V^\\mu = 0$$\n",
    "\n",
    "Which suggests an obvious substitution\n",
    "\n",
    "$$ \\frac{dV^\\alpha}{d\\lambda} = - \\Gamma^\\alpha_{\\mu\\beta} \\frac{dx^\\beta}{d\\lambda}V^\\mu = - \\Gamma^\\alpha_{\\mu\\beta} U^\\beta V^\\mu  $$\n",
    "\n",
    "So we can radjust everything to: \n",
    "\n",
    "$$ = \\frac{\\partial g_{\\alpha\\beta}}{\\partial x^\\rho} U^\\rho A^\\alpha B^\\beta - g_{\\alpha\\beta} \\Gamma^\\alpha_{\\mu\\rho} U^\\rho A^\\mu B^\\beta - g_{\\alpha\\beta}A^\\alpha \\Gamma^\\alpha_{\\mu\\beta} U^\\beta B^\\mu $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12abd767",
   "metadata": {},
   "source": [
    "Time to play the index carnival. we want UAB to be of the same sort. \n",
    "\n",
    "$$ = \\frac{\\partial g_{\\alpha\\beta}}{\\partial x^\\rho} U^\\rho A^\\alpha B^\\beta - g_{\\mu\\beta} \\Gamma^\\mu_{\\alpha\\rho} U^\\rho A^\\alpha B^\\beta - g_{\\alpha\\rho}A^\\alpha \\Gamma^\\alpha_{\\beta\\rho} U^\\rho B^\\beta $$\n",
    "\n",
    "$$ = U^\\rho A^\\alpha B^\\beta \\left( \\frac{\\partial g_{\\alpha\\beta}}{\\partial x^\\rho} - g_{\\mu\\beta} \\Gamma^\\mu_{\\alpha\\rho} - g_{\\alpha\\rho} \\Gamma^\\alpha_{\\beta\\rho} \\right) $$\n",
    "\n",
    "$$ = U^\\rho A^\\alpha B^\\beta \\left( \\frac{\\partial g_{\\alpha\\beta}}{\\partial x^\\rho} - g_{\\mu\\beta} \\Gamma^\\mu_{\\alpha\\rho} - g_{\\mu\\rho} \\Gamma^\\mu_{\\beta\\rho} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e272ef9",
   "metadata": {},
   "source": [
    "That last step is just adjusting the indeces to match 5.64. That is, the part in the parenthesis is identical to the derivative of the metric tensor with respect to one variable. Which 5.71 tells us is simply 0. In all coordinate systems. Therefore, there is no change in the dot product as the parameter changes, thus the dot product has to be conserved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc466d4",
   "metadata": {},
   "source": [
    "*b) Conclude fron this that if a geodesic is spacelike (or timelike or null) somewhere, it is spacelike (or timelike or null) everywhere.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecdb26e",
   "metadata": {},
   "source": [
    "The result above reminds us that the derivative of the metric is zero. \n",
    "\n",
    "We also remember that the spacelike, timelike, or null classification is defined *by the dot product of the vectors*.\n",
    "\n",
    "If the dot product is conserved, so too must its spacelike, timelike, or null classification. \n",
    "\n",
    "Hold on, this seems to be a contradiction: a curve can easily be devised that connects a timelike and a spacelike curve. While it is obviously a geodesic, the dot product must stil be conserved. So let's look a little closer at how we would take the curvature of the geodesic: we would take its velocity components and dot product them with themselves, $\\vec U \\cdot \\vec U = g_{\\alpha\\beta}U^\\alpha U^\\beta$, and the sign determines the type of curve.\n",
    "\n",
    "In a geodesic the value of U actually cannot change, it must be constant. Therefore the spacelike/timelike nature must also remain constant.The reason this doesn't apply to curves in general is becasue curves in general do not maintain the tangent nature of their vector. Imagine going around a circle in the cartesian plane: every tangent vector on that circle is a DIFFERENT tangent vector, so the transport changes it. But on a straight line, every point has the exact same vector on it, there is no turning. Trying to imagine this happening on the surface of a sphere leads to brain-numbing images, so it's probably best to not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaa8237",
   "metadata": {},
   "source": [
    "We noted below in **Problem 14** that it is possible that the tangent vector for a geodesic changes in a non-cartesian coordinate system. (Just imagine a great circle that goes across a sphere sideways: sometimes it has increasing theta, sometimes decreasing). However, we know that the dot product of the tangent vector with itself is constant as it is being transported along a curve. If the geodesic ever changed from timelike to spacelike, that would require its self-dot product to change. Which we already established is impossible. \n",
    "\n",
    "Yay, logic! Shaky logic, but logic nonetheless! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f553f",
   "metadata": {},
   "source": [
    "<a id='P14'></a>\n",
    "\n",
    "# Problem 14 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P14}$$ \n",
    "\n",
    "*The proper distance along a curve whose tangent is $\\vec V$ is given by 6.8. Show that if the curve is a geodesic then the proper length is an affine parameter. (use the result of **Problem 13**)*\n",
    "\n",
    "$$6.8: l = \\int_{\\lambda_0}^{\\lambda_1} |\\vec V \\cdot \\vec V|^{1/2} d\\lambda$$\n",
    "\n",
    "Where V is the tangent vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154fb071",
   "metadata": {},
   "source": [
    "First of all, we know the dot product is just a number. Everywhere on the path, it's the same number. No changes, no nothing. This means we can just evaluate it as some constant V and get the result...\n",
    "\n",
    "$$ l = \\sqrt{|V|} (\\lambda_1 - \\lambda_0)$$\n",
    "\n",
    "If we let the length be arbitrary and start at 0...\n",
    "\n",
    "$$ l = \\sqrt{|V|}\\lambda $$\n",
    "\n",
    "Which matches the form of 6.52 so it is an affine parameter. \n",
    "\n",
    "Why wouldn't this work on a non-geodesic? The dot product is still constant even then...\n",
    "\n",
    "Ah, but the TANGENT VECTOR is not. The tangent vector for a non-geodesic will change. Strictly speaking, the tangent vector for a geodesic can change as well, but when coupled with the metric its dot product cannot. Thus, we have accomplished what we set out to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0352992",
   "metadata": {},
   "source": [
    "<a id='P15'></a>\n",
    "\n",
    "# Problem 15 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P15}$$ \n",
    "\n",
    "*Use **Problems 13** and **14** to prove that the proper length of a geodesic between two points is uncahgned to first order by small changes in the curve that do not change its endpoints.*\n",
    "\n",
    "Oh boy, a \"to the first order\" problem. Egh, not even sure where to start here...\n",
    "\n",
    "You know what \"to the first order\" problems are typically a pain, let's just skip this and qualify the answer instead. ...Which is difficult because we aren't even sure what \"small changes\" even mean. A tiny perturbation in the path? In that case it's not really a geodesic anymore, is it? And such a thing would be trivially true: adding a small bend in a line will always only increase its length by an infinitesimal amount, which will vanish in the first order approximation. The fact that it's trivially true makes us think the problem should be worded differently to go for the calculaiton that's actually desired, whatever it actually might be. \n",
    "\n",
    "Yeah, baffling, and seemingly obvious. Skip. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d5414",
   "metadata": {},
   "source": [
    "<a id='P16'></a>\n",
    "\n",
    "# Problem 16 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P16}$$ \n",
    "\n",
    "*a) Derive 6.59 and 6.60 from 6.58*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1a74a",
   "metadata": {},
   "source": [
    "6.58 is\n",
    "\n",
    "$$ \\delta V^\\alpha = \\int_{x^1=a} \\Gamma^\\alpha_{\\mu 2} V^\\mu dx^2 - \\int_{x^1=a+\\delta a} \\Gamma^\\alpha_{\\mu 2} V^\\mu dx^2 + \\int_{x^2=b+\\delta b} \\Gamma^\\alpha_{\\mu 1} V^\\mu dx^1 - \\int_{x^2=b} \\Gamma^\\alpha_{\\mu 1} V^\\mu dx^1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6523e1",
   "metadata": {},
   "source": [
    "All of these are path integrals, which means they're going from one end to another while the variable itself is held constant. The bounds are, curiously, given by the other integrals. So, for instance, the first one $x^1=a$ is actually going from b to $b+\\delta b$, the limits of the other variable in this little square. So the paths have the same range. \n",
    "\n",
    "We note that the difference between tehm will be the difference between the two paths. That is, along $x^1$, there will be a difference of $d\\delta a$ between the two. \n",
    "\n",
    "Lastly, these paths aren't necessarily straight, or reasonable. We need to be integrating tangent to the path, and to enforce that we add the derivative with respect to the unit vector the path is on. \n",
    "\n",
    "Annoyingly it's not really posisble to do this in steps, because the moment the integral bounds are put in, the derivaiton with respect to the path is required, but that also removes the information about the difference between the paths... which is just plain annoying. Regardless this produces 6.59 basically immediately. \n",
    "\n",
    "The result is 6.59:\n",
    "\n",
    "$$ \\delta V^\\alpha = - \\delta a \\int_b^{b+\\delta b} \\frac{\\partial}{\\partial x^1}(\\Gamma^\\alpha_{\\mu 2} V^\\mu) dx^2 + \\delta b \\int_a^{a+\\delta a} \\frac{\\partial}{\\partial x^2} (\\Gamma^\\alpha_{\\mu 1} V^\\mu) dx^1 $$\n",
    "\n",
    "Note the signs, which depend on which side of the relaiton the $\\delta$ was on. \n",
    "\n",
    "6.60 is a first order approximation, which is to say it treats the integrand as a constant and jsut spits out the length of the integral, leaving us with:\n",
    "\n",
    "$$ \\delta V^\\alpha \\approx \\delta a\\delta b \\left( - \\frac{\\partial}{\\partial x^1}(\\Gamma^\\alpha_{\\mu 2} V^\\mu) + \\frac{\\partial}{\\partial x^2} (\\Gamma^\\alpha_{\\mu 1} V^\\mu)\\right)$$\n",
    "$$ = \\delta a\\delta b \\left( - (\\Gamma^\\alpha_{\\mu 2 ,1} V^\\mu + \\Gamma^\\alpha_{\\mu 2} V^\\mu_{,1}) + (\\Gamma^\\alpha_{\\mu 1,2} V^\\mu + \\Gamma^\\alpha_{\\mu 1} V^\\mu_{,2})\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12267c5",
   "metadata": {},
   "source": [
    "*b) Fill in the algebra needed to justify 6.61*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e60f9d",
   "metadata": {},
   "source": [
    "6.53 says $V^\\alpha_{,1} = -\\Gamma^\\alpha_{\\mu 1} V^\\mu$ which allows us to expand the above into:\n",
    "\n",
    "$$ = \\delta a\\delta b \\left( - (\\Gamma^\\alpha_{\\mu 2 ,1} V^\\mu + \\Gamma^\\alpha_{\\mu 2} (-\\Gamma^\\mu_{\\iota 1} V^\\iota)) + (\\Gamma^\\alpha_{\\mu 1,2} V^\\mu + \\Gamma^\\alpha_{\\mu 1} (-\\Gamma^\\mu_{\\iota 2} V^\\iota)\\right)$$\n",
    "$$ = \\delta a\\delta b V^\\mu \\left( - (\\Gamma^\\alpha_{\\mu 2 ,1} + \\Gamma^\\alpha_{\\nu 2} (-\\Gamma^\\nu_{\\mu 1} )) + (\\Gamma^\\alpha_{\\mu 1,2}+ \\Gamma^\\alpha_{\\nu 1} (-\\Gamma^\\nu_{\\iota 2})\\right)$$\n",
    "\n",
    "This is known as the indexing nightmare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c8011",
   "metadata": {},
   "source": [
    "$$ = \\delta a\\delta b V^\\mu \\left( \\Gamma^\\alpha_{\\mu 1,2} - \\Gamma^\\alpha_{\\mu 2 ,1} + \\Gamma^\\alpha_{\\nu 2} \\Gamma^\\nu_{\\mu 1} - \\Gamma^\\alpha_{\\nu 1} \\Gamma^\\nu_{\\mu 2}\\right)$$\n",
    "\n",
    "Which is 6.61."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce3a27",
   "metadata": {},
   "source": [
    "<a id='P17'></a>\n",
    "\n",
    "# Problem 17 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P17}$$ \n",
    "\n",
    "*a) Prove that 6.5 implies $g^{\\alpha\\beta}_{,\\mu}(P)=0$*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c17310",
   "metadata": {},
   "source": [
    "6.5: $\\frac{\\partial}{\\partial x^\\gamma} g_{\\alpha\\beta}(P) = 0$\n",
    "\n",
    "Which is basically just saying\n",
    "\n",
    "$g_{\\alpha\\beta,\\gamma}(P) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f34ac6",
   "metadata": {},
   "source": [
    "Written down, the metric at a point P with the derivative taken with respect to any basis is zero everywhere. \n",
    "\n",
    "We need to show that this is true of the reverse metric as well. \n",
    "\n",
    "What we need to know about is the context. 6.4 states that $g_{\\alpha\\beta}(P) = \\eta_{\\alpha\\beta}$, which is to say when g is evaluated at a point, it might as well be the Lorentz frame. In the Lorentz frame, the metric and inverse metric are *equal to each other*, so obviously every operation involving them will result in the exact same thing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c1631b",
   "metadata": {},
   "source": [
    "*b) Use this to establish 6.64*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff405f7",
   "metadata": {},
   "source": [
    "6.64: $\\Gamma^\\alpha_{\\mu\\nu,\\sigma} = \\frac12 g^{\\alpha\\beta} \\left( g_{\\beta\\mu,\\nu\\sigma} + g_{\\beta\\nu,\\mu\\sigma} - g_{\\mu\\nu,\\beta\\sigma} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34aa21",
   "metadata": {},
   "source": [
    "Okay so we have, in general:\n",
    "\n",
    "$$ \\nabla_\\beta g_{\\mu\\nu} = g_{\\mu\\nu,\\beta} - g_{\\alpha\\nu}\\Gamma^\\alpha_{\\mu\\beta} - g_{\\mu\\alpha}\\Gamma^\\alpha_{\\mu\\beta} = 0 $$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\frac{1}{2} g^{\\alpha\\gamma} (g_{\\alpha\\beta,\\mu} + g_{\\alpha\\mu,\\beta} - g_{\\beta\\mu,\\alpha}) =\\Gamma^\\gamma_{\\beta\\mu}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3add2",
   "metadata": {},
   "source": [
    "Adjust indeces and take the derivative. \n",
    "\n",
    "$$\\frac{1}{2} g^{\\iota\\alpha} (g_{\\iota\\mu,\\nu} + g_{\\iota\\nu,\\mu} - g_{\\mu\\nu,\\iota}) =\\Gamma^\\alpha_{\\mu\\nu}$$\n",
    "\n",
    "$$\\frac{1}{2} \\left[ g^{\\iota\\alpha} (g_{\\iota\\mu,\\nu} + g_{\\iota\\nu,\\mu} - g_{\\mu\\nu,\\iota}) \\right]_{,\\sigma} =\\Gamma^\\alpha_{\\mu\\nu,\\sigma}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb8d150",
   "metadata": {},
   "source": [
    "So what follows is simpler than it sounds. We use the product rule on the stuff in the middle. Now, if we are evaluating at P, then one might think the three terms in the middle go to zero. They would, if we weren't differentiating. But once we differentiate the g on the outside becomes a single derivative, and IT goes to zero, leaving only the other side of the product rule behind. \n",
    "\n",
    "$$\\frac{1}{2}  g^{\\iota\\alpha} (g_{\\iota\\mu,\\nu\\sigma} + g_{\\iota\\nu,\\mu\\sigma} - g_{\\mu\\nu,\\iota\\sigma})  =\\Gamma^\\alpha_{\\mu\\nu,\\sigma}$$\n",
    "\n",
    "Which is equivalent to what we sought to show. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b245a1be",
   "metadata": {},
   "source": [
    "*c) Fill in the steps needed to establish 6.68.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3d7d1",
   "metadata": {},
   "source": [
    "6.68 is the full tensor:\n",
    "\n",
    "$$ R_{\\alpha\\beta\\mu\\nu} = g_{\\alpha\\lambda}R^\\lambda_{\\beta\\mu\\nu} = \\frac12 (g_{\\alpha\\nu,\\beta\\mu} - g_{\\alpha\\mu,\\beta\\nu} + g_{\\beta\\mu,\\alpha\\nu} - g_{\\beta\\nu,\\alpha\\mu}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76cf78",
   "metadata": {},
   "source": [
    "From 6.63 we have \n",
    "\n",
    "$$ R^\\lambda_{\\beta\\mu\\nu} = \\Gamma^\\gamma_{\\beta\\nu,\\mu} - \\Gamma^\\gamma_{\\beta\\mu,\\nu} + \\Gamma^\\gamma_{\\sigma\\nu} \\Gamma^\\sigma_{\\mu\\beta} - \\Gamma^\\gamma_{\\sigma\\beta} \\Gamma^\\sigma_{\\mu\\nu}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7de119",
   "metadata": {},
   "source": [
    "$$ \\Gamma^\\alpha_{\\mu\\nu,\\sigma}  = \\frac12 g^{\\alpha\\beta} \\left( g_{\\beta\\mu,\\nu\\sigma} + g_{\\beta\\nu,\\mu\\sigma} - g_{\\mu\\nu,\\beta\\sigma} \\right) $$\n",
    "\n",
    "$$\\frac{1}{2} g^{\\alpha\\gamma} (g_{\\alpha\\beta,\\mu} + g_{\\alpha\\mu,\\beta} - g_{\\beta\\mu,\\alpha}) =\\Gamma^\\gamma_{\\beta\\mu}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c029e",
   "metadata": {},
   "source": [
    "This is clearly an exercise in algebra. So let's DO THIS! \n",
    "\n",
    "$$ R^\\lambda_{\\beta\\mu\\nu} = \\frac12 g^{\\gamma\\iota} \\left( g_{\\iota\\beta,\\nu\\mu} + g_{\\iota\\nu,\\beta\\mu} - g_{\\beta\\nu,\\iota\\mu} \\right) -  \\frac12 g^{\\gamma\\iota} \\left( g_{\\iota\\beta,\\mu\\nu} + g_{\\iota\\mu,\\beta\\nu} - g_{\\beta\\mu,\\iota\\nu} \\right) + \\frac{1}{2} g^{\\alpha\\gamma} (g_{\\alpha\\sigma,\\nu} + g_{\\alpha\\nu,\\sigma} - g_{\\sigma\\nu,\\alpha})\\frac{1}{2} g^{\\alpha\\sigma} (g_{\\alpha\\mu,\\beta} + g_{\\alpha\\beta,\\mu} - g_{\\mu\\beta,\\alpha}) - \\frac{1}{2} g^{\\alpha\\gamma} (g_{\\alpha\\sigma,\\beta} + g_{\\alpha\\beta,\\sigma} - g_{\\sigma\\beta,\\alpha})\\frac{1}{2} g^{\\alpha\\sigma} (g_{\\alpha\\mu,\\nu} + g_{\\alpha\\nu,\\mu} - g_{\\mu\\nu,\\alpha})  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593b7d9",
   "metadata": {},
   "source": [
    "Remember derivatives can be taken in any order, so flipped bottom indeces will cancel. \n",
    "\n",
    "$$ R^\\lambda_{\\beta\\mu\\nu} = \\frac12 g^{\\gamma\\iota} \\left( g_{\\iota\\nu,\\beta\\mu} - g_{\\iota\\mu,\\beta\\nu} + g_{\\beta\\mu,\\iota\\nu} - g_{\\beta\\nu,\\iota\\mu}  \\right) + \\frac{1}{2} g^{\\alpha\\gamma} (g_{\\alpha\\sigma,\\nu} + g_{\\alpha\\nu,\\sigma} - g_{\\sigma\\nu,\\alpha})\\frac{1}{2} g^{\\alpha\\sigma} (g_{\\alpha\\mu,\\beta} + g_{\\alpha\\beta,\\mu} - g_{\\mu\\beta,\\alpha}) - \\frac{1}{2} g^{\\alpha\\gamma} (g_{\\alpha\\sigma,\\beta} + g_{\\alpha\\beta,\\sigma} - g_{\\sigma\\beta,\\alpha})\\frac{1}{2} g^{\\alpha\\sigma} (g_{\\alpha\\mu,\\nu} + g_{\\alpha\\nu,\\mu} - g_{\\mu\\nu,\\alpha})  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdae3e2",
   "metadata": {},
   "source": [
    "So obviously the leading term is what we want, which means all the other terms better cancel. But do they? Yes. Re-index $\\beta\\nu$ and they automatically cancel, becoming:\n",
    "\n",
    "$$ R^\\lambda_{\\beta\\mu\\nu} = \\frac12 g^{\\gamma\\iota} \\left( g_{\\iota\\nu,\\beta\\mu} - g_{\\iota\\mu,\\beta\\nu} + g_{\\beta\\mu,\\iota\\nu} - g_{\\beta\\nu,\\iota\\mu}  \\right) $$\n",
    "\n",
    "Which if $\\iota\\alpha$ is adjusted, will cancel with the other multiplied metric, giving us the R we wanted to show at the start. Done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0cf85",
   "metadata": {},
   "source": [
    "<a id='P18'></a>\n",
    "\n",
    "# Problem 18 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P18}$$ \n",
    "\n",
    "*a) Derive 6.69 and 6.70 from 6.68*\n",
    "\n",
    "Annoying to type out; these are just the symmetries of the Modified Reimann Curvature Tensor. \n",
    "\n",
    "6.69 points out that swapping the first two and last two indecies makes the result negative, while there is a true symmetry from swapping 13 and 24. \n",
    "\n",
    "6.70 states that the tensor in form 1234 plus itself in form 1423 and 1342 produces zero. not sure why this is useful but it's true. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d39cf6c",
   "metadata": {},
   "source": [
    "*b) Show that 6.69 reduces the number of independent components of $R_{\\alpha\\beta\\mu\\nu}$ from 4x4x4x4 = 256 to 6x7/2 = 21. Hint: treat pairs of indices. Calculate how many independent choices of pairs there are for the first and second pairs of $R_{\\alpha\\beta\\mu\\nu}$*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263dd876",
   "metadata": {},
   "source": [
    "Okay so unlike our previous problems, this one's a 4D cube. Hard to imagine the 4D cube and how its symmetries work. The best thing we can note is that we have four numbers and four indeces: 0123. \n",
    "\n",
    "Assumign only 6.69 is true, that is, the four-way identity relations, we find numbers that are equal or opposite. \n",
    "\n",
    "First of all, we need to recognize that R is **antisymmetric** and as such the diagonals are all zero and irrelevant. This means 1111 2222 3333 and 4444 are all just zero. From [6](#6) we also know that having even half of the components the same, such as in 0011, also equals zero. Why?\n",
    "\n",
    "Well it becomes evident that we don't actually know what antisymmetry in higher dimensions MEANS. However, its clear that the relation 6.69 contains the information: if it transforms something into the negative of itself, it MUST be zero. Let's find all of these. There are a lot of them. \n",
    "\n",
    "First of all, anything composed of same-pairs has to be zero. 00, 11, 22, 33, etc. This removes a total of sixteen numbers (including the ones where all four are the same). \n",
    "\n",
    "However, what of things of the form xxyz? These and their transformations also all have to be zero, since one of the transforms in 6.69 shuffles only the first pair, so all other combinations therein must be lost. \n",
    "\n",
    "xxyz, xxzy are automatically zero. So is yzxx but that's true due to another reason so we don't need to count it twice. \n",
    "\n",
    "So every number which so much as contains a direct pair is toast. Counting only numbers with ONE pair in the first location, gives us six more zeroes for each pair, so six times four is 24. these are completely separate from the 16 before. \n",
    "\n",
    "We also grab 24 from the second pair. \n",
    "\n",
    "24+24+16 = 64. There are 64 zeroes in the matrix, which are simply not counted at all. This still leaves 192 potential values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b792a2d",
   "metadata": {},
   "source": [
    "The cases of indeces with only one number in them are already proven to be zero. \n",
    "\n",
    "What about cases with only two? Well, anything of xxxy, xyyy, xxyy form is automatically zero, but what of xyxy or xyyx? \n",
    "\n",
    "xyxy = -yxxy = -xyyx = xyxy\n",
    "\n",
    "These are perfectly safe, no self-equalizations here. But keep in mind each result of the identity can also be acted upon as well, meaning:\n",
    "\n",
    "yxxy = -xyxy = -yxyx = xyyx\n",
    "yxyx = -xyyx = -yxxy = yxyx\n",
    "xyyx = -yxyx = -xyxy = yxxy\n",
    "\n",
    "There are, in this shuffle, four numbers. So every unique combination of two different indeces will consume 4 indeces. There are six of these: 01, 02, 03, 12, 13, 23. So we have (+6) independent values (finally, we're not at zero!) and we reduce hte total number of elements we are considering by 24 again, leaving us 168.\n",
    "\n",
    "The consideration of three indeces is complicated, four is actually much easier. \n",
    "\n",
    "(Forgive us for not using zero here, we wrote this part first)\n",
    "\n",
    "So all posisble combinations of four different numbers will be divided by 4... 4 times 3 times 2 times 1 divided by 4, or just 6 independent values. Or that's what you'd THINK, but no, each of the values here can also twist into even more values with a sort of cascading effect of crazyness! We can apply the cycle again and again and again, oh boy! So instead of four numbers, we get quite a bit more. Start with 1234, 2134, 1243, 3412... and then apply it all to 2134! (and then the others) see how many we get!\n",
    "\n",
    "1234, 2134, 1243, 3412\n",
    "\n",
    "**2134**, **1234**, 2143, 4321\n",
    "\n",
    "**1243**, **2143**, **1234**, 4312\n",
    "\n",
    "**3412**, **4312**, 3421, **1234**\n",
    "\n",
    "And the last one only produces things that already exist. But wait, NOW we have to check the new numbers and see what they produce! But that's it, there are only 8. This could even have been reasoned out: we either swap the first two, swap the last two, or swap the locations of the first and last two, of course there are only eight combinations.\n",
    "\n",
    "For the 4-number combinations, we have 4 times 3 times 2 times 1 divided by 8 is just 3. (+3) to the total, giving us 9 total, and now we only have 144 values left to consider. \n",
    "\n",
    "Which now... is only the three-index-case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77748573",
   "metadata": {},
   "source": [
    "We already know that all dual-indeces are zero, so we only concern ourselves with non-dual-indeces:, which by nature have to take the forms xyyz, xyzy, yxyz, yxzy. We suspect that each individual one is goign to give us all four options, but let's try it out:\n",
    "\n",
    "xyyz = -yxyz = -xyzy = yzxy\n",
    "yxyz = -xyyz = -yxzy = yzyx\n",
    "xyzy = -yxzy = -xyyz = zyxy\n",
    "yzxy = -zyxy = -yzyx = xyyz\n",
    "yxzy = -xyzy = -yxyz = zyyx\n",
    "yzyx = -zyyx = -yzxy = yxyz\n",
    "zyxy = -yzxy = -zyyx = xyzy\n",
    "zyyx = -yzyx = -zyxy = yxzy\n",
    "\n",
    "Each unique set of three will provide *eight* combined indeces. So what are the unique combinations of 3? We have to be careful here, since 1223 and 1332 are distinct, but 1223 and 3221 are not. So let's just write them all out:\n",
    "\n",
    "0112 0113 2113 0221 0223 1223 0331 0332 1332 1002 1003 2003\n",
    "\n",
    "So there are (+12). 12 + 9 = 21. Which is exactly the number we wanted!\n",
    "\n",
    "Let's go ahead and list \"representative\" values from all 21:\n",
    "\n",
    "2 combos:\n",
    "0101 0202 0303 1212 1313 2323\n",
    "\n",
    "3 combos: \n",
    "0112 0113 2113 0221 0223 1223 0331 0332 1332 1002 1003 2003\n",
    "\n",
    "4 combos:\n",
    "0123 0231 0132"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e78d2d",
   "metadata": {},
   "source": [
    "*c) Show that 6.70 imposes only one further relation independent of 6.69 on teh components, reducing the total of independent ones to 20.*\n",
    "\n",
    "In the notation we've been using to be fast at typing, 6.70 correlates:\n",
    "\n",
    "xyzw + xwyz + xzwy = 0\n",
    "\n",
    "First of all this can't possibly relate numbers together that don't share numbers. All our 2-combos are completely unique, so they can't be related to each other this way. Also even though they can be shuffled into 0011 situations, this is perfectly fine--this does not demand that they be zero because of this, just that one be the reverse of the other! \n",
    "\n",
    "In the case of our 2-patterns, we get xyyx + xxyy + xyxy = 0 and while the middle one is zero the last is the negative of the first. This will apply to all of them. \n",
    "\n",
    "3-combos are the same way, but it's not as obvious. However, shuffling indeces around, no matter how it's done, can't change the number of each type of index, keeping them all firmly planetd within their \"classes\". The three-way sum doesn't change anythign either, as they take the same \"shapes\" as the 2-combos. \n",
    "\n",
    "So now we go to the 4 combos, and there *are* no zeroes hanging around the 4 combos, and they certainly *can* be shuffled outside their group. That would mean all 4-combos are related, right, making the independent indeces 19 rather than 20? No! The relation of 6.70 is a + b + c = 0. To find one of them, TWO of the others must be defined. It's like a function f(x,y). Two indepenent parameters are inserted to find the third. So we areduce from 21... to 20. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be814e39",
   "metadata": {},
   "source": [
    "<a id='P19'></a>\n",
    "\n",
    "# Problem 19 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P19}$$ \n",
    "\n",
    "*Prove that $R^\\alpha_{\\beta\\mu\\nu}=0$ for polar coordinates in the Euclidean plane. Use 5.45 or equivalent results.*\n",
    "\n",
    "5.45 just gives the Christoffel symbols. Not writing them down again, but 1/r, 1/r, and -r are the only three solid values. \n",
    "\n",
    "The metric has a diagonal of 1, $r^2$. The inverse 1, $1/r^2$.\n",
    "\n",
    "$\\Gamma^\\alpha_{\\mu\\nu,\\sigma} = \\frac12 g^{\\alpha\\beta} \\left( g_{\\beta\\mu,\\nu\\sigma} + g_{\\beta\\nu,\\mu\\sigma} - g_{\\mu\\nu,\\beta\\sigma} \\right)$\n",
    "\n",
    "$$ R^\\lambda_{\\beta\\mu\\nu} = \\Gamma^\\gamma_{\\beta\\nu,\\mu} - \\Gamma^\\gamma_{\\beta\\mu,\\nu} + \\Gamma^\\gamma_{\\sigma\\mu} \\Gamma^\\sigma_{\\beta\\nu} - \\Gamma^\\gamma_{\\sigma\\nu} \\Gamma^\\sigma_{\\beta\\mu}  $$\n",
    "\n",
    "Thus we combine everything together to get the result. (this was originally indexed wrong so above versions may also be indexed wrong.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2f60a",
   "metadata": {},
   "source": [
    "R is 2x2x2x2 which means we'll have a grand total of 16 elements here. ALL of them need to be zero. Regardless it should be obvious how to carry out the problem now, it'll just take this thing called TIME.\n",
    "\n",
    "Let's handle the last terms first since we already know the Christoffel numbers for the non-derivatives. \n",
    "\n",
    "There are only five resulting terms that exist, and they exist at different \"times\", never does the sum have more than one component in it. Represent $\\theta$ by t since we're going to be typing it out a lot. \n",
    "trt = 1/r\n",
    "ttr = 1/r\n",
    "rtt = -r\n",
    "\n",
    "The combinations require middle term to match the first term of the second. \n",
    "\n",
    "(rtt)(trt) = -1\n",
    "(trt)(rtt) = -1\n",
    "(rtt)(ttr) = -1\n",
    "(ttr)(trt) = $1/r^2$\n",
    "(ttr)(ttr) = $1/r^2$\n",
    "\n",
    "The last term in R's definition is closely related. the only difference is that it swaps the last indeces.\n",
    "\n",
    "(rtt)(trt) = -1\n",
    "(trt)(rtt) = -1\n",
    "(rtr)(ttt) = 0 (!)\n",
    "(ttt)(trr) = 0 (!)\n",
    "(ttr)(ttr) = $1/r^2$\n",
    "\n",
    "This reveals *two cases* where they simply don't cancel. In terms of R, these cases are:\n",
    "\n",
    "R(rttr) with -1, and R(trrt) with $1/r^2$. There are also their converses in R(rtrt) with +1 and R(trtr) with $-1/r^2$. With luck these will cancel with the derivative terms. \n",
    "\n",
    "Now while we originally tried to find the derivatives of hte coefficients with respect to the equation, we realized something rather basic. We have the coefficients. Just take the derivatives directly. -r becomes -1, 1/r becomes $-1/r^2$, and only when the derivative is taken with respect to r. This results in three separate places where the derivative coefficients are not zero.\n",
    "\n",
    "At one, all of the coefficients are ttr,r, and ttr,r - ttr,r is just zero, so they cancel. (uh oh...)\n",
    "\n",
    "At the others, we have trt,r standing alone in two cases, and then rtt,r standing alone in two cases. R(trtr) has $1/r^2$, R(trrt) has $-1/r^2$. Then we have R(rttr) with 1, and R(rtrt) with -1. \n",
    "\n",
    "You will note that when the location of R matches, the actual result is opposite for both of what we've calculated. Which means EVERYTHING IS ZERO! WOOHOO YEAH!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198002f0",
   "metadata": {},
   "source": [
    "<a id='P20'></a>\n",
    "\n",
    "# Problem 20 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P20}$$ \n",
    "\n",
    "*Fill in the algebra necessary to establish 6.73*\n",
    "\n",
    "6.73: $\\nabla_\\alpha \\nabla_\\beta V^\\mu = V^\\mu_{,\\beta\\alpha} + \\Gamma^\\mu_{\\nu\\beta,\\alpha} V^\\nu$\n",
    "\n",
    "okay so this isn't as simple as it looks. The previous step, 6.72, provides:\n",
    "\n",
    "$$ \\nabla_\\alpha \\nabla_\\beta V^\\mu = \\nabla_\\alpha (V^\\mu_{;\\beta}) = (V^\\mu_{;\\beta})_{,\\alpha} + \\Gamma^\\mu_{\\sigma\\alpha} V^\\sigma_{;\\beta} + \\Gamma^\\sigma_{\\beta\\alpha} V^\\mu_{;\\sigma} $$\n",
    "\n",
    "But we're evaluating this at the point P so any actual $\\Gamma$ are zero. Which means we just have...\n",
    "\n",
    "$$= (V^\\mu_{;\\beta})_{,\\alpha} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e8e11",
   "metadata": {},
   "source": [
    "Which we can expand into:\n",
    "\n",
    "$$ = V^\\mu_{,\\beta\\alpha} + \\Gamma^mu_{\\nu\\beta}V^\\mu_{,\\alpha} +  \\Gamma^mu_{\\nu\\beta,\\alpha}V^\\mu $$\n",
    "$$ = V^\\mu_{,\\beta\\alpha} + \\Gamma^mu_{\\nu\\beta,\\alpha}V^\\mu $$\n",
    "\n",
    "And hey look that's what we wanted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e563e04",
   "metadata": {},
   "source": [
    "<a id='P21'></a>\n",
    "\n",
    "# Problem 21 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P21}$$ \n",
    "\n",
    "*Consider the sentences following 6.78. Why does the argument in parenthesis not aply to the signs in:*\n",
    "\n",
    "$$ V^\\alpha_{;\\beta} = V^\\alpha_{,\\beta} + \\Gamma^\\alpha_{\\mu\\beta} V^\\mu ;; V_{\\alpha;\\beta} = V_{\\alpha,\\beta} - \\Gamma^\\mu_{\\alpha\\beta} V_\\mu$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099594ae",
   "metadata": {},
   "source": [
    "6.78 it essentially pointing out that the double covariant derivative acting on a $1\\choose1$ tensor produces components of that tensor acted upon by the R-tensor, but always with positive sign. We note above that the relation there shows that, no, it does not have to be positive in the case of a total derivative acting on a vector (or one-form). the one-form version produces a minus sign. \n",
    "\n",
    "The argument in parentehsis is \"They must all have the same sign because rasiing and lowering indices with g is unaffected by $\\nabla_\\alpha$ since $\\nabla g = 0$.\"\n",
    "\n",
    "It seems as though the reason this doesn't work is because we're not applying a coefficient to every term, like we are in 6.78. The partial derivative still remains, and its not multiplied by any tensor or tensor-like component. \n",
    "\n",
    "In fact we recall from earlier that the Christoffel coefficietns aren't even a tensor at *all*, so the entire thing falls apart as the term with the sign is not invariant (although the total is.) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80433ac4",
   "metadata": {},
   "source": [
    "<a id='P22'></a>\n",
    "\n",
    "# Problem 22 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P22}$$ \n",
    "\n",
    "*Fill in the algebra necessary to establish 6.84, 6.85, and 6.86*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b0c2f6",
   "metadata": {},
   "source": [
    "Right, rather than trying to funble our way through this, since this problem is basically asking us to work out the details of \"non-paralellism\", we're going to start from teh beginning, which is 6.79, and derive *every* part of it since as of starting this problem we are not sure what exactly we did to get here. \n",
    "\n",
    "We start by considering two geodesics, let htem be V and V' so their tangents are $\\vec V$ and $\\vec V'$. They start paralell to each other, at points A and A'. Let the affine parameter be $\\lambda$. \n",
    "\n",
    "Let there be another vector $\\vec\\xi$ which connects the two geodesics at a single value of the parameter $\\lambda$. Think of it as a line straddling the distance between the two geodesics. At the 'start' it connects A and A', and will move on to connect B and B', etcetera.\n",
    "\n",
    "To make this a simple version, we create a local inertial coordiante system at A itself, and also say that the coordinate $x^0$ points along geodesic V and that the coordinate is scaled to match the progression $\\lambda$. One case of this would be traveling in the x direction on the cartesian plane at one unit distance per unit time. We have $V^\\alpha = dx^\\alpha / d\\lambda$ which is just the definition of the tangent vector, but because of the way we've defined everything we have made at A the vector have components $V^\\alpha = \\delta^\\alpha_0$ which is to say we are pointing directly in the (1,0,0,...) direction. \n",
    "\n",
    "Then we note the equation of the geodesic at A is $ \\frac{d^2x^\\alpha}{d\\lambda^2} |_A = 0$. But before we move on, let's see where this comes from. The actual definition of the geodesic is \n",
    "\n",
    "$$ \\frac{d^2 x^\\alpha}{d\\lambda^2} + \\Gamma^\\alpha_{\\mu\\beta} \\frac{x^\\mu}{d\\lambda} \\frac{x^\\beta}{d\\lambda} = 0 $$. \n",
    "\n",
    "However as we're evaluating this at a specific point A, the Christoffel symbols vanish as they are all zero, thus our geodesic is correct. AT A. \n",
    "\n",
    "At A' we have a different story, the symbols most certainly do not vanish. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06406768",
   "metadata": {},
   "source": [
    "Fortunately for us it does simplify quite a bit, as we defined the vector V to be (1,0,0,...) and since the geodesics start OUT tangent, this is $\\vec V'$ as well. This means that only the $x^0$ components evaluate, leaving a single Christoffel symbol.\n",
    "\n",
    "$$ \\frac{d^2 x^\\alpha}{d\\lambda^2}|_{A'} + \\Gamma^\\alpha_{00}(A') = 0 $$. \n",
    "\n",
    "Where the \"of A'\" portion reminds us that the Christoffel symbols change based on what point they're at."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d831c",
   "metadata": {},
   "source": [
    "The next step is a minor approximation. We don't know what $\\Gamma$ is at A', but we do know A' is separated from A by our connecting vector $\\vec\\xi$. The approximation we make is that we assume the derivative is mostly constnat over the path between A and A' which, if the separation is small, is a pretty good approximation. This is, in math:\n",
    "\n",
    "$$\\Gamma^\\alpha_{00}(A') \\approx \\Gamma^\\alpha_{00,\\beta} \\xi^\\beta$$\n",
    "\n",
    "Note that while the Christoff symbol at A is zero, its derivative is not (necessarily), which is why we can make the above statement. Also note that there is a sum here over all directions that the connecting vector points. Ideally we start the situaiton in such a way that there's only one term, though. \n",
    "\n",
    "We now have at A'...\n",
    "\n",
    "$$ \\frac{d^2 x^\\alpha}{d\\lambda^2}|_{A'}  = -\\Gamma^\\alpha_{00,\\beta}\\xi^\\beta $$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bfa95c",
   "metadata": {},
   "source": [
    "Now we can combine our A and A' equations to say:\n",
    "\n",
    "$$ \\frac{d^2 x^\\alpha}{d\\lambda^2}|_{A'} - \\frac{d^2x^\\alpha}{d\\lambda^2} |_A  = -\\Gamma^\\alpha_{00,\\beta}\\xi^\\beta $$. \n",
    "\n",
    "Curiuosly, since A and A' are separated by $\\vec\\xi$ we can also say\n",
    "\n",
    "$$ \\frac{d^2 x^\\alpha}{d\\lambda^2}|_{A'} - \\frac{d^2x^\\alpha}{d\\lambda^2} |_A  = \\frac{d^2\\xi^\\alpha}{d\\lambda^2} $$. \n",
    "\n",
    "Which combines to\n",
    "\n",
    "$$ -\\Gamma^\\alpha_{00,\\beta}\\xi^\\beta  = \\frac{d^2\\xi^\\alpha}{d\\lambda^2}$$.\n",
    "\n",
    "Which gives us a more explicit description of how $\\vec\\xi$ changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040188c",
   "metadata": {},
   "source": [
    "Now we go grab another equation: 6.48. Which states:\n",
    "\n",
    "$$U^\\beta V^\\alpha_{;\\beta} = 0 \\Leftrightarrow \\frac{d}{d\\lambda} \\vec{V} = \\nabla_{\\vec U}\\vec V = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35036d",
   "metadata": {},
   "source": [
    "Our ultimate goal here is the full second covariant derivative of $\\xi$. Using the above, we can actually write out\n",
    "\n",
    "$$ \\nabla_V \\nabla_V \\xi^\\alpha = \\nabla_V (\\nabla_V \\xi^\\alpha)  = \\frac{d}{d\\lambda}(\\nabla_V \\xi^\\alpha) $$\n",
    "\n",
    "But this really doesn't seem right, if we extract it as we know we should using $V^\\alpha_{;\\beta} = V^\\alpha_{,\\beta} + \\Gamma^\\alpha_{\\mu\\beta} V^\\mu$, we get:\n",
    "\n",
    "$$ = \\frac{d}{d\\lambda}(\\nabla_V \\xi^\\alpha) + \\Gamma^\\alpha_{\\beta 0}(\\nabla_V \\xi^\\beta) $$\n",
    "\n",
    "IF this turns out well, this means 6.84 has a typo, an = instead of a +. Now we can expand each internal term as well...\n",
    "\n",
    "$$ = \\frac{d}{d\\lambda}(\\frac{d}{d\\lambda} \\xi^\\alpha + \\Gamma^\\alpha_{\\beta 0} \\xi^\\beta) + \\Gamma^\\alpha_{\\beta 0}(\\frac{d}{d\\lambda} \\xi^\\alpha + \\Gamma^\\alpha_{\\beta 0} \\xi^\\beta) $$\n",
    "\n",
    "That term on the right is 0 since it's a Christoffel symbol without a derivative being taken, and we are working in the A frame. \n",
    "\n",
    "$$ = \\frac{d}{d\\lambda}(\\frac{d}{d\\lambda} \\xi^\\alpha + \\Gamma^\\alpha_{\\beta 0} \\xi^\\beta)$$\n",
    "\n",
    "Note that since we set the parameter to be in the same direction as $x^0$ we can adjust notation for it as \"0\"\n",
    "\n",
    "$$ = \\frac{d^2}{d\\lambda^2} \\xi^\\alpha + \\Gamma^\\alpha_{\\beta 0,0} \\xi^\\beta + \\Gamma^\\alpha_{\\beta 0} \\xi^\\beta_{,0} $$\n",
    "\n",
    "$$ = \\frac{d^2}{d\\lambda^2} \\xi^\\alpha + \\Gamma^\\alpha_{\\beta 0,0} \\xi^\\beta$$\n",
    "\n",
    "This is 6.85. Which means that yes there was a typo up there. Hooo boy. \n",
    "\n",
    "Anyway we can finally substitute in our second derivative to get:\n",
    "\n",
    "$$ = -\\Gamma^\\alpha_{00,\\beta} \\xi^\\beta + \\Gamma^\\alpha_{\\beta 0,0} \\xi^\\beta$$\n",
    "$$ = (\\Gamma^\\alpha_{\\beta 0,0}-\\Gamma^\\alpha_{00,\\beta}) \\xi^\\beta$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d429015",
   "metadata": {},
   "source": [
    "now the problem claims that this equals $R^\\alpha_{00\\beta}$. While it does you have to take the first two indeces as fungible to make it work. The derivative coefficients remain, the non-derivative ones cancel each other out as they are symmetric across our little point here. \n",
    "\n",
    "$$ = R^\\alpha_{00\\beta} \\xi^\\beta$$\n",
    "$$ = R^\\alpha_{\\mu\\nu\\beta} V^\\mu V^\\nu \\xi^\\beta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83561bb3",
   "metadata": {},
   "source": [
    "Okay this last step needs some jusitifcation. Why does acting on our vectors reduce their indeces to zero? Well, after all, we've excessively defined V in terms of the point A, going in (1,0,0,0,...) so there WERE no other indeces. So yeah going that way checks out.\n",
    "\n",
    "The question now is why we can go from 00 to genral indeces and the equation isn't messed up... but think of it this way. We could ALWAYS define V to be in a singular direction, so naturally it has to hold in general as well.\n",
    "\n",
    "And now... we are done. \n",
    "\n",
    "Ooogh. What does this even SAY? Well, since R is zero in a flat space, paralell lines remain parallel. However, R on a non-flat space have their separation values change, as R scales it somehow. \n",
    "\n",
    "And that's all this needed to show."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd688b1b",
   "metadata": {},
   "source": [
    "<a id='P23'></a>\n",
    "\n",
    "# Problem 23 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P23}$$ \n",
    "\n",
    "*Prove 6.88* (oh no.) *Be careful: one cannot simply differentiate 6.67 since it is valid only at P, not in the neighborhood of P.*\n",
    "\n",
    "6.88: $R_{\\alpha\\beta\\mu\\nu,\\lambda} = \\frac12 (g_{\\alpha\\nu,\\beta\\mu\\lambda} - g_{\\alpha\\mu,\\beta\\nu\\lambda} + g_{\\beta\\mu,\\alpha\\nu\\lambda} - g_{\\beta\\nu,\\alpha\\mu\\lambda})$\n",
    "\n",
    "Oh BOY. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608bba8d",
   "metadata": {},
   "source": [
    "Anyway, we are proving that the partial derivative of R is is the derivative of all the g components that make it up. However, if we back way way up, we note that all the equations we've been using so far are only valid at P, since we've been removing the extra coefficients. So we need to back up to:\n",
    "\n",
    "$$ R^\\lambda_{\\beta\\mu\\nu} = \\Gamma^\\gamma_{\\beta\\nu,\\mu} - \\Gamma^\\gamma_{\\beta\\mu,\\nu} + \\Gamma^\\gamma_{\\sigma\\mu} \\Gamma^\\sigma_{\\beta\\nu} - \\Gamma^\\gamma_{\\sigma\\nu} \\Gamma^\\sigma_{\\beta\\mu}  $$\n",
    "\n",
    "We can see obviously from the mentioned 6.67 and 6.68 that the already-differentiated terms will become exactly the relation we want. It's the terms we ignored at P that we need to prove cancel, that is:\n",
    "\n",
    "$$ \\Gamma^\\gamma_{\\sigma\\mu} \\Gamma^\\sigma_{\\beta\\nu} - \\Gamma^\\gamma_{\\sigma\\nu} \\Gamma^\\sigma_{\\beta\\mu}  $$\n",
    "\n",
    "These guys. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac56191e",
   "metadata": {},
   "source": [
    "Which we then apply the product rule to to actually take their derivatives:\n",
    "\n",
    "$$ \\Gamma^\\gamma_{\\sigma\\mu} \\Gamma^\\sigma_{\\beta\\nu,\\lambda} + \\Gamma^\\gamma_{\\sigma\\mu,\\lambda} \\Gamma^\\sigma_{\\beta\\nu} - \\Gamma^\\gamma_{\\sigma\\nu} \\Gamma^\\sigma_{\\beta\\mu,\\lambda} - \\Gamma^\\gamma_{\\sigma\\nu,\\lambda} \\Gamma^\\sigma_{\\beta\\mu} $$\n",
    "\n",
    "Unfortunately it's not obvioust that they cancel, which means we'll have to *expand* them. \n",
    "\n",
    "$$ \\Gamma^\\alpha_{\\mu\\nu,\\sigma}  = \\frac12 g^{\\alpha\\beta} \\left( g_{\\beta\\mu,\\nu\\sigma} + g_{\\beta\\nu,\\mu\\sigma} - g_{\\mu\\nu,\\beta\\sigma} \\right) $$\n",
    "\n",
    "$$ \\Gamma^\\gamma_{\\beta\\mu} = \\frac{1}{2} g^{\\alpha\\gamma} (g_{\\alpha\\beta,\\mu} + g_{\\alpha\\mu,\\beta} - g_{\\beta\\mu,\\alpha})  $$\n",
    "\n",
    "At which point we went \"we're not tpying that up\" and wrote down the substitutions in a notebook. Index salad, index salad..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899a939",
   "metadata": {},
   "source": [
    "First we noted the leading terms are all 1/4 inverse-g. The inverse-g terms combined into two distinct types, meaning that the first and third could add, as could the second and fourth. Meaning that if one of them canceled, both of them would cancel. Furthermore, the only swap between the pairs was a $\\mu\\nu$ swap, so all we needed to find was the result for ONE of the terms. This still wasn't exactly trivial. \n",
    "\n",
    "Work implies that nothing cancels. Then we realize that the two \"different\" leading coefficients we found really are not, since the metric is by definition SYMMETRIC. So really all of them can add together as they wish. \n",
    "\n",
    "We showed (on the paper) that the pairs 13 and 24 did not cancel. HOWEVER, it is clear from the coefficietns $\\mu\\nu$ swap AND the term the derivative acts on swaps, then everything is in fact equal and cancels.\n",
    "\n",
    "Here's an example term: $g_{\\alpha\\sigma,\\mu}g_{\\iota\\beta,\\nu\\lambda}$. If we perform the swap we end up with $g_{\\alpha\\sigma,\\nu\\lambda}g_{\\iota\\beta,\\nu}$ which actually IS the same because by index salading we can set all the dummy indeces to anything.\n",
    "\n",
    "Note: wouldn't this change R? It seems like for an arbitrary R these wouldn't line up perfectly. Ah, but let's look at which indeces are being adjusted: $\\alpha\\iota$ are summation indeces, they have no relevance on R. Which leaves $\\sigma$ and $\\beta$. The thing is, by swapping it on one term, we have to swap it on all terms, which makes them fly past each other except when $\\sigma$ = $\\beta$, which can't always be true as $\\beta$ only takes one value on any given sum. \n",
    "\n",
    "And so we are at a loss but think that maybe spending more time isn't worth it. \n",
    "\n",
    "HOLD ON A SECOND.\n",
    "\n",
    "WE'RE STUPID. \n",
    "\n",
    "We're still evaluating at point P. Which means, while we needed to open up the Christoffel symbols to take their derivatives, WE ARE STILL IN P. EVERY ONE OF THOSE TERMS IS ZERO. EVERY ONE OF THEM.\n",
    "\n",
    "**AGH**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a876960",
   "metadata": {},
   "source": [
    "<a id='P24'></a>\n",
    "\n",
    "# Problem 24 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P24}$$ \n",
    "\n",
    "*Establish 6.89 from 6.88*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d19ca",
   "metadata": {},
   "source": [
    "6.88 is what we were yelling at in the previous problem.\n",
    "\n",
    "$R_{\\alpha\\beta\\mu\\nu,\\lambda} = \\frac12 (g_{\\alpha\\nu,\\beta\\mu\\lambda} - g_{\\alpha\\mu,\\beta\\nu\\lambda} + g_{\\beta\\mu,\\alpha\\nu\\lambda} - g_{\\beta\\nu,\\alpha\\mu\\lambda})$\n",
    "\n",
    "Now we wish to show that $R_{\\alpha\\beta\\mu\\nu,\\lambda} + R_{\\alpha\\beta\\lambda\\mu,\\nu} + R_{\\alpha\\beta\\nu\\lambda,\\mu}= 0$ Which, since we are really tired of typing out all these greek letters, we shall just represent as R(1234,5) + R(1253,4) + R(1245,3) = 0.\n",
    "\n",
    "Expanding we don't care about the fractional coefficient. We end up with:\n",
    "\n",
    "g(14,235) - g(13,245) + g(23,145) - g(24,135)\n",
    "\n",
    "+g(13,254) - g(15,234) + g(25,134) - g(23,154)\n",
    "\n",
    "+g(15,243) - g(14,253) + g(24,153) - g(25,143)\n",
    "\n",
    "Now we can re-arrange on eitehr side of the comma. Ascending order seems reasonable.\n",
    "\n",
    "g(14,235) - g(13,245) + g(23,145) - g(24,135)\n",
    "\n",
    "+g(13,245) - g(15,234) + g(25,134) - g(23,145)\n",
    "\n",
    "+g(15,234) - g(14,235) + g(24,135) - g(25,134)\n",
    "\n",
    "Now, does EVERYTHING cancel? \n",
    "\n",
    "YES! And we're done. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ae5f14",
   "metadata": {},
   "source": [
    "<a id='P25'></a>\n",
    "\n",
    "# Problem 25 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P25}$$ \n",
    "\n",
    "*a) Prove that the Ricci tensor is the only independent contraction of $R^\\alpha_{\\beta\\mu\\nu}$, all others are multiples of it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579be147",
   "metadata": {},
   "source": [
    "The Ricci tensor is $R_{\\alpha\\beta}$ derived from $R^\\mu_{\\alpha\\mu\\beta}$, which is to say a contraction along two indeces. (We'll just assume we're always contracting along two indeces and not worry about other options, such as three.)\n",
    "\n",
    "We wish to show that all other possible contractions are either null, or some multiple of the Ricci tensor. For now we shall *assume* the tensor is symmetric so 12 and 21 would be the same tensor, but notably in the next part we have to prove that property. \n",
    "\n",
    "Regardless, let's label our indeces xyzw since we're lazy. The 2-combinations on offer are:\n",
    "\n",
    "xy \n",
    "xz\n",
    "xw\n",
    "yz\n",
    "yw (the definition)\n",
    "zw\n",
    "\n",
    "So there are five other options. Using \"a\" as the \"singular\" element, these become:\n",
    "\n",
    "xyaa\n",
    "xaza\n",
    "xaaw\n",
    "ayza\n",
    "ayaw (definition)\n",
    "aazw\n",
    "\n",
    "So first of all from **Problem 18** we know that anything with \"aa\" in on either the left or right side just flat out reduces to zero. So that gets rid of two of our options right away. \n",
    "\n",
    "xaza\n",
    "xaaw\n",
    "ayza\n",
    "ayaw (definition)\n",
    "\n",
    "So now the trick is to show that these are equivalent to each other, give or take a sign. This can actually be shown simply by the \"shuffling\" of combinations we once did. Like so:\n",
    "\n",
    "a1a2 = -1aa2 = -a12a = a2a1\n",
    "\n",
    "And as we know from **Problem 18** the three-combinations will cycle through EVERY possible option. Thus, every other combination has to be plus or minus the others. \n",
    "\n",
    "We don't even have to assume symmetry to know this, actually, as the inverted versions will also be hit! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e5088",
   "metadata": {},
   "source": [
    "*b) Show that the Ricci tensor is symmetric*\n",
    "\n",
    "So, basically, $R^\\mu_{\\alpha\\mu\\beta} = R^\\mu_{\\beta\\mu\\alpha}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac222f55",
   "metadata": {},
   "source": [
    "So basically, can we say a1a2 = a2a1? Well... let's see.\n",
    "\n",
    "a1a2 = -1aa2 = -a12a = a2a1.\n",
    "\n",
    "Hey look at that, we've shown it trivially. Wow. Glad we did **Problem 18** to completion, it made thinking about this easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd80ad3",
   "metadata": {},
   "source": [
    "<a id='P26'></a>\n",
    "\n",
    "# Problem 26 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P26}$$ \n",
    "\n",
    "*Use **Problem 17** to prove 6.94*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec19bb8",
   "metadata": {},
   "source": [
    "6.94 states, simply, that $g^{\\alpha\\beta}_{;\\mu} = 0$\n",
    "\n",
    "Which. This is extremely trivial, it seems, as  **Problem 17** has $g^{\\alpha\\beta}_{,\\mu}(P)=0$\n",
    "\n",
    "The trivial adjustment is that while the partial derivative at P is zero, that means the Chrsitoffel symbol is zero since we are at P, so the partial derivative is equal to the total derivative. \n",
    "\n",
    "So. Uh. Yeah. That's it. Go home, it's over."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9604c",
   "metadata": {},
   "source": [
    "<a id='P27'></a>\n",
    "\n",
    "# Problem 27 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P27}$$ \n",
    "\n",
    "*Fill in the algebra necessary to establish 6.95, 6.97, 6.99.*\n",
    "\n",
    "So since this is an extended derivation, we're going to start from the beginning of the section, that is, by applying the Ricci contraction to the Bianchi identities. The Bianchi identities are $R_{\\alpha\\beta\\mu\\nu;\n",
    "\\lambda} + R_{\\alpha\\beta\\lambda\\mu;\\nu} + R_{\\alpha\\beta\\nu\\lambda;\\mu} = 0$\n",
    "\n",
    "The actual Ricci concentraiton is given by $R_{\\alpha\\beta} = R^\\mu_{\\alpha\\mu\\beta}$. \n",
    "\n",
    "We specifically accomplish this applicaiton by applying a raising metric to the Bianchi identities. We can apply it independently of the derivative since the full derivative of the metric is zero and can thus be treated as a cosntant. All the contraction really does is adjust indeces. \n",
    "\n",
    "$$g^{\\alpha\\mu}(R_{\\alpha\\beta\\mu\\nu;\\lambda} + R_{\\alpha\\beta\\lambda\\mu;\\nu} + R_{\\alpha\\beta\\nu\\lambda;\\mu}) = 0$$\n",
    "\n",
    "$$\\Rightarrow (R^\\mu_{\\beta\\mu\\nu;\\lambda} + R^\\mu_{\\beta\\lambda\\mu;\\nu} + R^\\mu_{\\beta\\nu\\lambda;\\mu}) = 0$$\n",
    "\n",
    "$$\\Rightarrow R{\\beta\\nu;\\lambda} - R_{\\beta\\lambda;\\nu} + R^\\mu_{\\beta\\nu\\lambda;\\mu} = 0$$\n",
    "\n",
    "The subtraction is there because we had to shuffle some indeces to get the right form for conversion. Which apparently is 6.95, but that's trivially true, at least it seems so. Shuffle index 3 and 4, get a minus sign. \n",
    "\n",
    "We now have the contracted Bianchi identities. \n",
    "\n",
    "Apparently this isn't sueful, so we contract AGAIN, this time to the Ricci Scalar, which is $R = g^{\\mu\\nu}R_{\\mu\\nu}$. If we apply another raising metric...\n",
    "\n",
    "$$g^{\\beta\\nu} (R{\\beta\\nu;\\lambda} - R_{\\beta\\lambda;\\nu} + R^\\mu_{\\beta\\nu\\lambda;\\mu}) = 0$$\n",
    "\n",
    "$$\\Rightarrow R_{;\\lambda} - R^\\nu_{\\lambda;\\nu} + g^{\\beta\\nu}R^\\mu_{\\beta\\nu\\lambda;\\mu} = 0$$\n",
    "\n",
    "$$\\Rightarrow R_{;\\lambda} - R^\\nu_{\\lambda;\\nu} - g^{\\beta\\nu}R^\\mu_{\\beta\\lambda\\nu;\\mu} = 0$$\n",
    "\n",
    "$$\\Rightarrow R_{;\\lambda} - R^\\nu_{\\lambda;\\nu} - R^{\\mu}_{\\lambda;\\mu} = 0$$\n",
    "\n",
    "That last step was us essentially defining a new contraction. (Mildly confused on validity... need to do it in the same order as the metric perhaps? Addendum: what apears to be happening is an ignoring of the first term, and using the last four terms to do the collapse. This involves swapping $\\nu\\lambda$ positions which are the 34 index, and there you have it) To match the 9.96 given in the book, we adjust indeces.\n",
    "\n",
    "$$\\Rightarrow R_{;\\lambda} - R^\\mu_{\\lambda;\\mu} - R^{\\mu}_{\\lambda;\\mu} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f817c23",
   "metadata": {},
   "source": [
    "Which we can simplify to\n",
    "\n",
    "$$ (2R^\\mu_\\lambda - \\delta^\\mu_\\lambda R)_{;\\mu} = 0$$\n",
    "\n",
    "the 2R term is obvious, thos parts add, and the signs can be inverted by carrying everything across the equals sign. But where did the delta come from? Well, do note that we are SUMMING over $\\mu$, so it hits every value. The point is to say that the R term only exists when $\\mu = \\lambda$. And then we have our result. This is 6.97. \n",
    "\n",
    "To get to 6.99 we have to define a symmetric tensor, specifically G. \n",
    "\n",
    "$$ G^{\\alpha\\beta} = R^{\\alpha\\beta} - \\frac12 g^{\\alpha\\beta}R = G^{\\beta\\alpha} $$\n",
    "\n",
    "Our goal is to find G hidden within 6.97. Let's work it out.\n",
    "\n",
    "$$ (2R^\\mu_\\lambda - \\delta^\\mu_\\lambda R)_{;\\mu} = 0$$\n",
    "$$ \\Rightarrow 2(R^\\mu_\\lambda - \\frac12\\delta^\\mu_\\lambda R)_{;\\mu} = 0$$\n",
    "$$ \\Rightarrow 2g^{\\lambda\\beta}(R^\\mu_\\lambda - \\frac12g^\\mu_\\lambda R)_{;\\mu} = 0$$\n",
    "\n",
    "Here we remembered that the dirac is the metric with but up and down indeces.\n",
    "\n",
    "$$ \\Rightarrow 2(R^{\\mu\\beta} - \\frac12g^{\\mu\\beta} R)_{;\\mu} = 0$$\n",
    "\n",
    "Change index.\n",
    "\n",
    "$$ \\Rightarrow 2(R^{\\alpha\\beta} - \\frac12g^{\\alpha\\beta} R)_{;\\mu} = 0$$\n",
    "\n",
    "Hey look, that's G. \n",
    "\n",
    "$$ \\Rightarrow 2(G^{\\alpha\\beta})_{;\\mu} = 0$$\n",
    "$$ \\Rightarrow 2G^{\\alpha\\beta}_{;\\mu} = 0$$\n",
    "$$ \\Rightarrow G^{\\alpha\\beta}_{;\\mu} = 0$$\n",
    "\n",
    "And we're done here, that is 6.99."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42572a9a",
   "metadata": {},
   "source": [
    "<a id='P28'></a>\n",
    "\n",
    "# Problem 28 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P28}$$ \n",
    "\n",
    "*a) Derive 6.19 by using the usual coordiante transformation from Cartesian to spherical polars.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6706f3",
   "metadata": {},
   "source": [
    "6.19 is the spherical metric, that is, the metric with the diagonal $1, r^2, r^2sin\\theta$. However, we need to actually find it from scratch to truly solve the problem. So basically, we just know the answer: now we need to derive it. \n",
    "\n",
    "The \"simple\" way to find the metric is 6.11, $(g) = (\\Lambda)(\\eta)(\\Lambda)^T$, where $\\eta$ is the standard metric, (1,1,1) diagonal in this case. In tensor notaiton, this is $g_{\\alpha\\beta} = \\Lambda^\\mu_\\alpha \\Lambda^\\nu_\\beta \\eta_{\\mu\\nu}$ \n",
    "\n",
    "This requires knowing the translation matrix from cartesian to spherical, which is defined by the Jacobian. 5.13 gives the exact format for 2x2, which we extend into 3x3. We do admit to having to look up the exact relations for xyz to spherical. [7](#7) reveals...\n",
    "\n",
    "$$x=rsin\\theta cos\\phi; y = rsin\\theta sin\\phi; z = rcos\\theta$$\n",
    "\n",
    "Which we now put into a Jacobian matrix. Rows are by cartesian xyz, rows are by r$\\theta\\phi$.\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "sin\\theta cos\\phi & rcos\\theta cos\\phi & - rsin\\theta sin\\phi \\\\\n",
    "sin\\theta sin\\phi & rcos\\theta sin\\phi & rsin\\theta cos\\phi \\\\\n",
    "cos\\theta & -rsin\\theta & 0 \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Since the cartesian metric is the identity, our operation is the same as multiplying this matrix by its transpose. \n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "sin\\theta cos\\phi & sin\\theta sin\\phi & cos\\theta \\\\\n",
    "rcos\\theta cos\\phi & rcos\\theta sin\\phi & -rsin\\theta \\\\\n",
    "- rsin\\theta sin\\phi & rsin\\theta cos\\phi & 0 \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "This took some notebook work to fully calculate, as there were nine separate terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f917422",
   "metadata": {},
   "source": [
    "After reviewing the definitions we realized we had the transpose backwards. Whoops. This rather quickly gave us our diagonal, though, just reverse the transposes and out pop $1, r^2, r^2sin\\theta$, tah-dah! \n",
    "\n",
    "We did not test every single off-diagonal to see if they were zero because it should be automatic, but we did test one just to see. And yes it was zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b11c3",
   "metadata": {},
   "source": [
    "*b) Deduce from 6.19 that the metric of the surface of a sphere of radius r has components $ g_{\\theta\\theta} = r^2, g_{\\phi\\phi} = r^2 sin^2\\theta, g_{\\theta\\phi}=0 $ in the usual spherical coordinates.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addb15db",
   "metadata": {},
   "source": [
    "Obviously the transform the metric provides must still hold even for points restricted to a spherical shell of constant radius, so the diagonal becomes ($r^2, r^2sin^2\\theta$) rather trivially. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ffe5b5",
   "metadata": {},
   "source": [
    "*c) Find the componetnst $g^{\\alpha\\beta}$ for the sphere.*\n",
    "\n",
    "Finding the inverse is simple: invert everything, the diagonal is now $1/r^2, 1/(r^2sin^2\\theta)$. Tah-dah! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd89af95",
   "metadata": {},
   "source": [
    "<a id='P29'></a>\n",
    "\n",
    "# Problem 29 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P29}$$ \n",
    "\n",
    "*In polar coordinates, calculate the Reimann curvature tensor of the spehre of unit radius, whose metric is given in **Problem 28**. Note that in two dimensions there is onely one independent component, by the same argument as **Problem 18b**. So calculate $R_{\\theta\\phi\\theta\\phi}$ and obtain all other components in terms of it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dcb879",
   "metadata": {},
   "source": [
    "Right, so, R has 16 components in a two-dimensional case. We can actually write them all out in BINARY! \n",
    "\n",
    "0000, 0001, 0010, 0011, 0100, 0101, 0110, 0111, 1000, 1001, 1010, 1011, 1100, 1101, 1110, 1111\n",
    "\n",
    "Naturally anything with any doubled anything is zero, so we ignore those. \n",
    "\n",
    "0101, 0110, 1001, 1010\n",
    "\n",
    "only four components are potentially independent, and we know from **Problem 18** shuffling that they are all related to each other. By the suggestion in the problem, we have:\n",
    "\n",
    "0101 = -1001 = -0110 = 0101\n",
    "\n",
    "-1001 = 0101 = 1010 = -0110\n",
    "\n",
    "Which correlates all four of the values. Which means... now we have to figure out how to CALCULATE one of the terms. *Shocked and terrified gasp,*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c7d1c",
   "metadata": {},
   "source": [
    "From 6.62 we know the tensor is defined by the christoffel coefficients and their derivatives. Which means we're gonna have to grab everything and do some tedious calculaitons... but since we've never found an actual value for R before, we're gonna actually do it. \n",
    "\n",
    "$$ R^\\lambda_{\\beta\\mu\\nu} = \\Gamma^\\gamma_{\\beta\\nu,\\mu} - \\Gamma^\\gamma_{\\beta\\mu,\\nu} + \\Gamma^\\gamma_{\\sigma\\mu} \\Gamma^\\sigma_{\\beta\\nu} - \\Gamma^\\gamma_{\\sigma\\nu} \\Gamma^\\sigma_{\\beta\\mu}  $$\n",
    "\n",
    "$$ \\Gamma^\\alpha_{\\mu\\nu,\\sigma}  = \\frac12 g^{\\alpha\\beta} \\left( g_{\\beta\\mu,\\nu\\sigma} + g_{\\beta\\nu,\\mu\\sigma} - g_{\\mu\\nu,\\beta\\sigma} \\right) $$\n",
    "\n",
    "$$ \\Gamma^\\gamma_{\\beta\\mu} = \\frac{1}{2} g^{\\alpha\\gamma} (g_{\\alpha\\beta,\\mu} + g_{\\alpha\\mu,\\beta} - g_{\\beta\\mu,\\alpha})  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c12e0c",
   "metadata": {},
   "source": [
    "So, just calculate ONE. \n",
    "\n",
    "R(0101) is our starting point. This becomes\n",
    "\n",
    "$$R^0_{101} = \\Gamma^0_{11,0} - \\Gamma^0_{10,1} + \\Gamma^0_{\\sigma 0} \\Gamma^\\sigma_{11} - \\Gamma^0_{\\sigma 1} \\Gamma^\\sigma_{10} $$\n",
    "\n",
    "$$ = \\Gamma^0_{11,0} - \\Gamma^0_{10,1} + \\Gamma^0_{0 0} \\Gamma^0_{11} - \\Gamma^0_{0 1} \\Gamma^0_{10} + \\Gamma^0_{1 0} \\Gamma^1_{11} - \\Gamma^0_{1 1} \\Gamma^1_{10} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19435c",
   "metadata": {},
   "source": [
    "Now all these coefficients are given by the various metrics within them. Rather than writing it all down, since that would be qutie tedious, we talk it out. The only metrics that exist are on the diagonals. Lower metric is $r^2, r^2sin^2\\theta$ and the upper metric is $1/r^2, 1/(r^2sin^2\\theta)$. All off-diagonal terms are zero, which will reduce quite a lot to actually zero. In fact, the \"sum\" in every one of the coefficients reduces to a single number, since the upper metric in each one only exists on one of the terms. \n",
    "\n",
    "After all of it, only one of the derivative coefficients and one of the non-derivative terms remains, combining to be\n",
    "\n",
    "$$cos^2\\theta - sin^2\\theta + \\frac{1}{tan^2\\theta}$$\n",
    "\n",
    "Which, with a sign adjustment, are all the terms in the R tensor. \n",
    "\n",
    "Most of this was just double and triple checking indeces. It takes time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e527f",
   "metadata": {},
   "source": [
    "<a id='P30'></a>\n",
    "\n",
    "# Problem 30 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P30}$$ \n",
    "\n",
    "*Calculate the Reimann curvature tensor of the cylinder. Since the cylidner is flat, this should vanish. Use whatever coordinates you likem and make sure you write down the metric properly!*\n",
    "\n",
    "Tempting to move on past this one, but more metric calculation is worthwhile. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7faf5c7",
   "metadata": {},
   "source": [
    "So rather than working out each part, we work out all possible coefficients that contain the only terms that exist and see if they cancel or not. \n",
    "\n",
    "Of the standard coefficients there are only 1/r, 1/r, -r. Which makes a lot of sense, really. \n",
    "\n",
    "The signs seem a slight bit off, but the derivatives have $1/r^2, 1/r^2, -1$\n",
    "\n",
    "There is significant annoyance in showing that all these things cancel. \n",
    "\n",
    "The singular coefficients pair up to form three -1 terms, and one $1/r^2$ term. Two of those -1 terms are entirely self-canceling. \n",
    "\n",
    "The rest better cancel with the derivatives. The -1 term in fact cancels with the -1 term from the derivatives in both cases. \n",
    "\n",
    "One of the derivatives' $1/r^2$ case cancels with itself $\\Gamma^\\theta_{\\theta r,r}$.\n",
    "\n",
    "However, the last two seem to add. This problem woudl be fixed if the derivative coefficietns were NEGATIVE. Which ostentiably they should be, as they are the derivatives of hte other coefficients, which should just be able to be taken without issue. The derivative of 1/r is flat out $-1/r^2$. But the result we get from the formula up above is positive, no sign change. Is it typed down wrong...? No...\n",
    "\n",
    "Well clearly we've shown that it does cancel, but the issue of why the formula above doesn't put in the right sign is greatly concerning. \n",
    "\n",
    "This would be fixed if the inverse metric was $-1/r^2$. But it's not. Because that doesn't reduce to the 111 diagonal.\n",
    "\n",
    "Annoyingly looking things up doesn't help here since everyone else just uses symmetry. Faster, to be sure...\n",
    "\n",
    "No multiplying by the lowering metric at the end to get R into a different form doesn't change anything.\n",
    "\n",
    "So, in conclusion, yes the cylidner is flat. We are not sure why the derivative formula doesn't do the proper negative stuff. Concerning. \n",
    "\n",
    "Man even using it in a different metric didn't work... the sign error still occurs... \n",
    "\n",
    "So basically let's take derivatives directly and not use that equation. There may be some validity criteria we have forgotten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b6b37",
   "metadata": {},
   "source": [
    "The nice thing about cylindrical is that it's basically just fancy polar. \n",
    "\n",
    "x = $rcos\\theta$\n",
    "\n",
    "y = $rsin\\theta$\n",
    "\n",
    "z = z (nice!)\n",
    "\n",
    "The polar metric is just a condensed version of this one. The only change is the addition of z=z, which makes a rather interesting addition of just... 1. Thus the full metric has diagonal (1, $r^2$, 1), in terms of $r\\theta z$. \n",
    "\n",
    "Notably, every portion of the Reimann curvature tensor is composed of derivatives of these metrics with respect to the coordinates. *Only the middle term has a derivative that survives: 2r, and then a second derivative of 2.* Virtually everything goes to zero. We only need to concern oursevles with $g_{\\theta\\theta,r}$ and $g_{\\theta\\theta,rr}$\n",
    "\n",
    "Thus, we might be able to LOOK BACKWARD. Our equations:\n",
    "\n",
    "$$ R^\\gamma_{\\beta\\mu\\nu} = \\Gamma^\\gamma_{\\beta\\nu,\\mu} - \\Gamma^\\gamma_{\\beta\\mu,\\nu} + \\Gamma^\\gamma_{\\sigma\\mu} \\Gamma^\\sigma_{\\beta\\nu} - \\Gamma^\\gamma_{\\sigma\\nu} \\Gamma^\\sigma_{\\beta\\mu}  $$\n",
    "\n",
    "$$ \\Gamma^\\alpha_{\\mu\\nu,\\sigma}  = \\frac12 g^{\\alpha\\beta} \\left( g_{\\beta\\mu,\\nu\\sigma} + g_{\\beta\\nu,\\mu\\sigma} - g_{\\mu\\nu,\\beta\\sigma} \\right) $$\n",
    "\n",
    "$$ \\Gamma^\\gamma_{\\beta\\mu} = \\frac{1}{2} g^{\\alpha\\gamma} (g_{\\alpha\\beta,\\mu} + g_{\\alpha\\mu,\\beta} - g_{\\beta\\mu,\\alpha})  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b871e2",
   "metadata": {},
   "source": [
    "<a id='P31'></a>\n",
    "\n",
    "# Problem 31 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P31}$$ \n",
    "\n",
    "*Prove that covariant differnetiation obeys the usual product rule.*\n",
    "\n",
    "Skipped. Would be tedious. Is kind of obvious. Also already proven in other math courses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba072c9",
   "metadata": {},
   "source": [
    "<a id='P32'></a>\n",
    "\n",
    "# Problem 32 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P32}$$ \n",
    "\n",
    "*A four-dimensional manifold has coordinsates (u,v,w,p) in which the metric has components $g_{uv}=g_{ww}=g_{pp}=1$, all other indepdendent componetns vanishing.*\n",
    "\n",
    "*a) Show that the manifold is flat and the signature is +2*\n",
    "\n",
    "The signature is usually the sum of the diagonals, and that is the same as taking the determinant... except apparently not, as the determinant is shown to be zero. So let's go back and figure out what exactly signature MEANS. \n",
    "\n",
    "ALSO metrics are symmetric by definition so $g_{vu}$ better also be 1. \n",
    "\n",
    "The signature is just the sum of the diagonal elements. So +2. That was much easier than we thought it was. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fb87a",
   "metadata": {},
   "source": [
    "*b) The result in a) implies the manifold must be Minkowski spacetime. Find a coordinate transformation to the usual coordinates (t,x,y,z). Hint: you may find it useful to calculate $\\vec e_v \\cdot \\vec e_v$ and $\\vec e_u \\cdot \\vec e_u$*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70123d22",
   "metadata": {},
   "source": [
    "well w=y p=z, so we can just ignore them.\n",
    "\n",
    "So what matrix transforms (0,1)(1,0) to (-1,0)(0,1)? \n",
    "\n",
    "That matrix is (0,1)(-1,0)\n",
    "\n",
    "Which basically states t = -v and x = u. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ab8c3",
   "metadata": {},
   "source": [
    "<a id='P33'></a>\n",
    "\n",
    "# Problem 33 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P33}$$ \n",
    "\n",
    "*A 'three-sphere' is the three-dimensional surface in four-dimensional Euclidean space (coordinates x y z w) given by the equation $x^2+y^2+z^2+w^2 = r^2$, where r is the radius of the sphere.*\n",
    "\n",
    "*a) Define new coordinates ($r,\\theta,\\phi,\\chi$) by the equations $w=rcos\\chi, z=rsin\\chi cos\\theta, x=rsin\\chi sin\\theta cos\\phi, y = rsin\\chi sin\\theta sin\\phi$ Show that $(\\theta,\\phi,\\chi)$ are coordinates for the sphere. These genrealize to the familiar polar coordinates.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef37b7f9",
   "metadata": {},
   "source": [
    "Tempting to do a by-words argument, but this is 4D, so let's try to figure out how to show it mathematically. \n",
    "\n",
    "Perhaps the best way is to take the definition of r and show it's independent from the values of the angles. Which is actually pretty easy! insert the definitions of x, y, z, and w into the r definition, the radius completely cancels out. However, we will need to prove that the sum of all the squares equals 1 to confirm this. \n",
    "\n",
    "$$ cos^2\\chi + sin^2\\chi cos^2\\theta + sin^2\\chi sin^2\\theta cos^2\\phi + sin^2\\chi sin^2\\theta sin^2\\phi$$\n",
    "$$ = cos^2\\chi + sin^2\\chi cos^2\\theta + sin^2\\chi sin^2\\theta$$\n",
    "$$ = cos^2\\chi + sin^2\\chi$$\n",
    "$$ = 1$$\n",
    "\n",
    "Well would you look at that, the equality is satisfied and adjusting any of the three angles does absolutely nothing to the radius. Therefore, the three angles are all *on* the three-sphere. \n",
    "\n",
    "There is a minor point that remains though: how can we show that the angles span the entire three-sphere, and that we haven't just gotten part of it? Well, we can reason this one out. Since r is always positive, it can't provide the sign to the various x, y, z, w components, to the sign must come from the angles. So every possible x w y z can be made with them, given an r, there's no bounds they can't reach. \n",
    "\n",
    "Arguably this points to a much simpler two-line proof: the sphere is defined by constant r, thus the other three coordinates have to characterize it. Since they span Cartesian space, they must span the entire sphere. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb3e6eb",
   "metadata": {},
   "source": [
    "*b) Show that the metric of the three-sphere of radius r has components in these coordinates $g_{\\chi\\chi} = r^2, g_{\\theta\\theta} = r^2sin^2\\chi, g_{\\phi\\phi} = r^2sin^2\\chi sin^2\\theta$, all other components vanishing. (Use the same method as **Problem 28**.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1936e0d",
   "metadata": {},
   "source": [
    "Basically, find the conversion from cartesian metric. Except we aren't exactly converting from cartesian, but rather the matrix with the (1,1,1,1) diagonal.\n",
    "\n",
    "This actually will be a lot of steps and not particuarly illuminating. The method to be outlined is simple: take the Jacobian. Since the 4-cartesian metric is just the identity, to find the terms all one has to do is multiply the transformation matrix (Jacobian) with its own transpose. This will result in 16 rather long evaluations that should result in the 4-metric. Whatever portion of the metric is on the radius section can be ignored. (It'll probably be 1 anyway). \n",
    "\n",
    "Actually let's go ahead and calculate the radius portion of the metric, since it's not given. All we need to do is find the dot product of everything with a derivative taken with respect to r...\n",
    "\n",
    "...\n",
    "\n",
    "...we arleady calculated this in part a). The metric $g_{rr}=1$. Nice. \n",
    "\n",
    "Anyway this means we can actually find rather easily the diagonals by taking dot products of the obvious derivatives. The $g_{\\phi\\phi}$ result is actually self evident, since the first two become zero and the last two have the same terms affixed to the usual trig addition to 1 rule.\n",
    "\n",
    "But still, we're not going to show the diagonals are zero. Let someone else do that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14466a0b",
   "metadata": {},
   "source": [
    "<a id='P34'></a>\n",
    "\n",
    "# Problem 34 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P34}$$ \n",
    "\n",
    "*Establish the following identities for a general metric tensor in a general coordinate system. You may find 6.39 and 6.40 useful.*\n",
    "\n",
    "6.39: $g_{,\\mu} = gg^{\\alpha\\beta}g_{\\beta\\alpha,\\mu}$\n",
    "\n",
    "6.40: $\\Gamma^\\alpha_{\\mu\\alpha} = \\frac{\\sqrt{-g}_{,\\mu}}{\\sqrt{-g}}$\n",
    "\n",
    "*a) $\\Gamma^\\mu_{\\mu\\nu} = \\frac12 (ln|g|)_{,\\nu}$*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91003de",
   "metadata": {},
   "source": [
    "Okay so first of all Christoff Symbols are symmetric, $\\Gamma^{a}_{bc} = \\Gamma^{a}_{cb, so really what we want to show is\n",
    "\n",
    "$$ \\frac{\\sqrt{-g}_{,\\mu}}{\\sqrt{-g}} = \\frac12 (ln|g|)_{,\\nu} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e1dc0",
   "metadata": {},
   "source": [
    "By the rule of the logarithmic derivative...\n",
    "\n",
    "$$ \\frac12 \\frac{g_{,\\mu}}{g}  = \\frac12 (ln|g|)_{,\\nu} $$\n",
    "\n",
    "And by **Problem 8** we know this correlates to:\n",
    "\n",
    "$$ \\frac{\\sqrt{-g}_{,\\mu}}{\\sqrt{-g}} = \\frac12 \\frac{g_{,\\mu}}{g} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55846fb",
   "metadata": {},
   "source": [
    "*b) $g^{\\mu\\nu}\\Gamma^\\alpha_{\\mu\\nu} = -\\frac{(g^{\\alpha\\beta}\\sqrt{-g})_{,\\beta}}{\\sqrt{-g}}$*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bea9f",
   "metadata": {},
   "source": [
    "This looks trivial at first, but it turns out to be something else entirely. Namely, we note that the indexes aren't the same as 6.40 or part a. \n",
    "\n",
    "So the steps here are a little obtuse and strange, so let's go through them slowly. \n",
    "\n",
    "First, we note that $g^{\\alpha\\beta}_{;\\beta}=0$ for all metrics in all refernce frames, so $g^{\\alpha\\beta}_{,\\beta} + \\Gamma^\\alpha_{\\mu\\beta}g^{\\mu\\beta} + \\Gamma^\\beta_{\\mu\\beta}g^{\\mu\\alpha} = 0$, or perhaps more importantly phrased as\n",
    "\n",
    "$$ \\Gamma^\\alpha_{\\mu\\beta}g^{\\mu\\beta} = - g^{\\alpha\\beta}_{,\\beta} - \\Gamma^\\beta_{\\mu\\beta}g^{\\mu\\alpha} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb93627",
   "metadata": {},
   "source": [
    "Which gives us a direct substitute. The tricky thing to do is to reverse transform the second Christoffel symbol. We also multiply the first term by 1. Because reasons that will become obvious.\n",
    "\n",
    "$$ = - g^{\\alpha\\beta}_{,\\beta} \\frac{\\sqrt{-g}}{\\sqrt{-g}} - \\frac{g^{\\alpha\\beta}(\\sqrt{-g})_{,\\beta}}{\\sqrt{-g}} $$\n",
    "\n",
    "Which we can just use the product rule backwards on to get..\n",
    "\n",
    "$$ g^{\\mu\\nu}\\Gamma^\\alpha_{\\mu\\nu} = -\\frac{(g^{\\alpha\\beta}\\sqrt{-g})_{,\\beta}}{\\sqrt{-g}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564516be",
   "metadata": {},
   "source": [
    "*c) for an antisymmetric tensor $F^{\\mu\\nu}, F^{\\mu\\nu}_{;\\nu} = \\frac{(\\sqrt{-g}F^{\\mu\\nu})_{,\\nu}}{\\sqrt{-g}}$*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c98b8c",
   "metadata": {},
   "source": [
    "As before, we note: $F^{\\alpha\\beta}_{,\\beta} + \\Gamma^\\alpha_{\\mu\\beta}F^{\\mu\\beta} + \\Gamma^\\beta_{\\mu\\beta}F^{\\alpha\\mu} = F^{\\alpha\\beta}_{;\\beta}$. Notably it doesn't equal zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9c065",
   "metadata": {},
   "source": [
    "Antisymmetry time! the middle term is 0. All flipped terms cancel, and all diagonal terms are zero. Thus...\n",
    "\n",
    "$\\Rightarrow F^{\\alpha\\beta}_{,\\beta} + \\Gamma^\\beta_{\\mu\\beta}F^{\\alpha\\mu} = F^{\\alpha\\beta}_{;\\beta}$.\n",
    "\n",
    "$\\Rightarrow F^{\\alpha\\beta}_{,\\beta} + \\frac{\\sqrt{-g}_{,\\mu}}{\\sqrt{-g}}F^{\\alpha\\mu} = F^{\\alpha\\beta}_{;\\beta}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a858f15e",
   "metadata": {},
   "source": [
    "We note that this is effectively the same inverse derivative as before. All we have to do is adjust indeces, let $\\beta \\mu -> \\nu$ and then we get what we sought.\n",
    "\n",
    "Finally. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a637c61",
   "metadata": {},
   "source": [
    "*d) $g^{\\alpha\\beta}g_{\\beta\\mu,\\nu} = -g^{\\alpha\\beta}_{,\\nu} g_{\\beta\\mu}$ (hint, what is $g^{\\alpha\\beta}g_{\\beta\\mu}$?)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049e056",
   "metadata": {},
   "source": [
    "Actually we can show this one by argument. This ALSO suggests that the Cirstoffel equation for the derviative is wrong since this relation is taken without adjusting the minus sign. HAH. Funny.\n",
    "\n",
    "Regardless we can think of this like taking the derivative of the whole. Take the metric and inverse metric as g and G for simplicity. (Gg)' = gG' + g'G. except gG is just the identity matrix, which becomes the zero matrix. This is only possible if gG' = -g'G or vice versa. Proven. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bedb279",
   "metadata": {},
   "source": [
    "*e) $g^{\\mu\\nu}_{,\\alpha} = -\\Gamma^{\\mu}_{\\beta\\alpha}g^{\\beta\\nu} - \\Gamma^{\\nu}_{\\beta\\alpha}g^{\\mu\\beta}$ Hint: use 6.31*\n",
    "\n",
    "6.31: $g_{\\alpha\\beta;\\gamma}=0$ in any basis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b81316",
   "metadata": {},
   "source": [
    "First, we note that $g^{\\mu\\nu}_{;\\alpha}=0$ for all metrics in all refernce frames, so $g^{\\mu\\nu}_{,\\alpha} + \\Gamma^\\mu_{\\beta\\alpha}g^{\\beta\\nu} + \\Gamma^\\nu_{\\beta\\alpha}g^{\\beta\\mu} = 0$. Which trivially becomes what we want.\n",
    "\n",
    "Turns out this hint applies to the problems above too!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1993538",
   "metadata": {},
   "source": [
    "<a id='P35'></a>\n",
    "\n",
    "# Problem 35 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P35}$$ \n",
    "\n",
    "*Compute 20 independent ocmponetns of $R_{\\alpha\\beta\\mu\\nu}$...*\n",
    "\n",
    "I'm going to put this nicely. \n",
    "\n",
    "Heck no. It was hard enough and annoying enough to compute *ONE* component in **Problem 30**. \n",
    "\n",
    "The method is simple enough. Calculate metric and inverse metric (which, for this problem, are provided via the length of the line element. The integration factor is everyone's friend!) From that calculate the Christoffel symbols that we have done MULTIPLE TIMES already. And then the derivatives. Since we're actually calculating we can take the derivatives directly. Do this twenty times. \n",
    "\n",
    "My goodness that would be beyond tedious..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16edd9ba",
   "metadata": {},
   "source": [
    "<a id='P36'></a>\n",
    "\n",
    "# Problem 36 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P36}$$ \n",
    "\n",
    "*A four-dimensional manifold has coordinates (t,x,y,z) and line element $ds^2 = -(1+2\\phi)dt^2 + (1-2\\phi)(dx^2,dy^2,dz^2)$, where $|\\phi(t,x,y,z)|$ << 1 everywhere. At any point P with coordinates $(t_0,x_0,y_0,z_0)$, find a coordinate transformation to a locally inertial coordinate system, to first order in $\\phi$. At what rate does such a frame accelerate with respect to the original coordinates, agian to first order in $\\phi$?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ce1e1",
   "metadata": {},
   "source": [
    "Following work *might* rely on some results from **Chapter 7** since this is the Newtonian gravity field metric. (the name is not exact.) \n",
    "\n",
    "The goal is, given txyz, to find the transformation to that frame. Which as a matrix equation is given by:\n",
    "\n",
    "$$ (g) = (\\Lambda)(\\eta)(\\Lambda)^T $$\n",
    "\n",
    "(oh boy, I was answering the wrong problem last time! That's just great!)\n",
    "\n",
    "g itself is given by the metric with line element  $(-1-2\\phi, 1-2\\phi, 1-2\\phi, 1-2\\phi)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef49eb",
   "metadata": {},
   "source": [
    "We're actually already pretty close to this, all things considered. And we know from **Problem 3** that such a matrix always exists. In fact **Problem 3** gives us a pretty good idea on the method for finding such a matrix! Both metrics are already diagonalized in ascending order, so we just need to \"unitize\" them with a matrix N. The way we solved this in **Problem 3** was to create a set of matrices that themselves were diagonal, and make them  square roots of the absolute values in question. There actually isn't even a step here, we can just up and make it!\n",
    "\n",
    "This makes the transformation matrix itself a metric with diagonal $(\\sqrt{1+2\\phi},\\sqrt{1-2\\phi},\\sqrt{1-2\\phi},\\sqrt{1-2\\phi})$, at least as it is shown in the above matrix equation. Also it's its own transpose, so that's all fine. \n",
    "\n",
    "Now, the problem *does* mention doing the transofmation TO the locally inertial coordinate system, not from. This would just be the inverse matrix. Which would have the diagonal $(\\frac{1}{\\sqrt{1+2\\phi}},\\frac{1}{\\sqrt{1-2\\phi}},\\frac{1}{\\sqrt{1-2\\phi}},\\frac{1}{\\sqrt{1-2\\phi}})$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49adfd",
   "metadata": {},
   "source": [
    "The only concern about this we have is that we didn't use the \"first order\" approximation later, but that might just be a notation that the Newton metric is only valid to first order, as noted in **Chapter 7**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e80886",
   "metadata": {},
   "source": [
    "Fools that we were, we had been trying to solve this problem by finding each component of the matrix by hand.... without knowing how the coordinates related to each other. now that we have it it's clear that the coordinates relate in a linear fashion, with t correlating directly with t', and no other variables are used. This is easy enough to do when both metrics are already diagonalized and in ascending order. If they were NOT the problem would not be so trivial, but see **Problem 3** for the method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9457e4",
   "metadata": {},
   "source": [
    "<a id='P37'></a>\n",
    "\n",
    "# Problem 37 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P37}$$ \n",
    "\n",
    "*a) \"Proper Volume\" of a two-dimensional manifold is usually called \"proper area\". Using the metric in **Problem 28**, integrate 6.18 to find the proper area of a sphere of radius r.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395bf6d3",
   "metadata": {},
   "source": [
    "Ah, this is a matter of the integration factor!\n",
    "\n",
    "The diagonal was $r^2, r^2sin^2\\theta$. Multiply it all together and then square root to get the actual integration factor of $r^2sin\\theta$ which we've used before. \n",
    "\n",
    "For our bounds, we have two angles: $\\theta$ goes from 0 to $\\pi$ and $\\phi$ goes twice that. The integral over $sin\\theta$ gives 2, so the total is $4\\pi r^2$, the well known surface area of a sphere. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be02183",
   "metadata": {},
   "source": [
    "*b) Do the same for the three-sphere of **Problem 33**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7f72e0",
   "metadata": {},
   "source": [
    "See the problem here is that we don't know our bounds. \n",
    "\n",
    "The integration factor itself isn't that difficult: $r^3sin^2\\chi sin\\theta$. But what are the limits on our angles? We can DEDUCE it from the original coordinate transforms. Parameters that are only inside a cosine function only need to vary from 0 to $\\pi$ to span all possible values, but sine functions have to go further. So we posit that only $\\phi$ goes to $2\\pi.$ Let's see if this is reasonable. \n",
    "\n",
    "We do need the integral of $sin^2\\chi$ from 0 to $\\pi$. Geogebra gives $\\pi/2$ This gets rid of the 2 from the $sin\\theta$, suggesting that the \"surface area\" of a 3-sphere is... $2\\pi^2r^3$.\n",
    "\n",
    "And Wikipedia agrees YES! Boo-yeah."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed206c4e",
   "metadata": {},
   "source": [
    "<a id='P38'></a>\n",
    "\n",
    "# Problem 38 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P38}$$ \n",
    "\n",
    "*Integrate 6.8 to find the length of a circle of constant coordinate $\\theta$ on a sphere of radius r.*\n",
    "\n",
    "6.8: $l = \\int_{\\lambda_0}^{\\lambda_1} |\\vec V \\cdot \\vec V|^{1/2} d\\lambda $\n",
    "\n",
    "The dot product of the tangent vector of a circle to itself would be $(0,1) \\cdot (0,1)$ The metric is (1,$r^2$) in the case of a circle. And yes, we are aware the problem says constant $\\theta$ but we don't have to listen to that, we can turn this into a purely polar problem with no loss of generality. \n",
    "\n",
    "Thus, the dot product is $r^2$. We take the root of this and are just left with r. \n",
    "\n",
    "So the full integral is $r(\\lambda_1 - \\lambda_0)$\n",
    "\n",
    "Which means the REAL question is how much $\\lambda$ do we have on this integral? Well... 2$\\pi$. We're going all the way around once. Though we should probably find the mathematical reason for this rather than just because \"we know the trig functions.\"\n",
    "\n",
    "To do that we leave polar coordinates behind for a moment. We know that a circle in parametric cartesian is some form of $(sin\\lambda,cos\\lambda)$ for (x,y). It is easy to show that this cycles every $2\\pi$, and in cartesian coordinates the integration is direct 1 to 1. And if we increased the \"speed\", we would need to increase the vectors we used at the start! So that's why it's this way. \n",
    "\n",
    "Just to prove it to ourselves, let the circle be given by $(sin2\\lambda,cos2\\lambda)$. The tengent vector given by the derivative will be $(2sin2\\lambda,2cos2\\lambda)$. In pola, this is (0,2). Which would make our dot product $4r^2$ which is square rooted to 2r. Then we integrate and since we're going twice as fast, we should in the same \"time\" lambda get twice as much distance. And we do, $8\\pi$. Tah-dah!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60b3e2",
   "metadata": {},
   "source": [
    "<a id='P39'></a>\n",
    "\n",
    "# Problem 39 \\[Back to [top](#toc)\\]\n",
    "$$\\label{P39}$$ \n",
    "\n",
    "*a) For any two vector fields $\\vec U$ and $\\vec V$, their **Lie Bracket** is defined to be the vector field $[\\vec U, \\vec V]$ with components*\n",
    "\n",
    "$$ [\\vec U, \\vec V]^\\alpha = U^\\beta \\nabla_\\beta V^\\alpha - V^\\beta \\nabla_\\beta U^\\alpha $$\n",
    "\n",
    "*Show that*\n",
    "\n",
    "$$ [\\vec U, \\vec V] = -[\\vec V, \\vec U] $$\n",
    "\n",
    "$$ [\\vec U, \\vec V]^\\alpha = U^\\beta \\frac{\\partial V^\\alpha}{\\partial x^\\beta} - V^\\beta \\frac{\\partial U^\\alpha}{\\partial x^\\beta} $$\n",
    "\n",
    "*This is one tensor field in which partial derivatives need not be accompanied by Christoffel symbols!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20279003",
   "metadata": {},
   "source": [
    "This is... trivially true. Just flip U and V, note that it results in a sign change. Huh. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9f15f0",
   "metadata": {},
   "source": [
    "*b) Show that $[\\vec U, \\vec V]$ is a derivative operator on $\\vec V$ along $\\vec U$, i.e., show that for any scalar f*\n",
    "\n",
    "$$ [\\vec U, f\\vec V] = f[\\vec U, \\vec V] + \\vec V(\\vec U \\cdot \\nabla f). $$\n",
    "\n",
    "*This is sometimes called the **Lie Derivative** with respect to $\\vec U$ and is denoted by*\n",
    "\n",
    "$$ [\\vec U, \\vec V] = \\$_{\\vec U} \\vec V, \\vec U \\cdot \\nabla f = \\$_{\\vec U} f $$\n",
    "\n",
    "*Then eq 6.101 (the first one in this part) would be written in the more conventional form of the Leibnitz rule for the derivative operator $ \\$_{\\vec U} $ (agh, this is supposed to be the pound sign, but that can't be typed!)*\n",
    "\n",
    "$$ \\$_{\\vec U}(f\\vec V) = f\\$_{\\vec U}\\vec V + \\vec V \\$_{\\vec U}f $$\n",
    "\n",
    "*The result of a) shows that this derivative operator may be defined without a connection or metric, and is therefore very fundamental.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff3212",
   "metadata": {},
   "source": [
    "This actually isn't bad at all. Just physically evaluate it, though do so in tensor notaiton. \n",
    "\n",
    "$$ fU^\\beta \\nabla_\\beta V^\\alpha - fV^\\beta \\nabla_\\beta U^\\alpha + V^\\alpha U^\\beta\\nabla_\\beta f f$$\n",
    "First and last terms can be adjusted via product rule.\n",
    "$$ = U^\\beta \\nabla_\\beta fV^\\alpha - fV^\\beta \\nabla_\\beta U^\\alpha $$\n",
    "\n",
    "$$ = [\\vec U, f\\vec V]^\\alpha$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72971e7",
   "metadata": {},
   "source": [
    "*c)Calculate the components of the Lie Derivative of a one-form field $\\tilde\\omega$ from the knowledge that, for any vector field $\\vec V$, $\\tilde\\omega(\\vec V)$ is a scalar like f above, and from the definition that $ \\$_{\\vec U} \\tilde\\omega $ is a one-form field:*\n",
    "\n",
    "$$ \\$_{\\vec U}[\\tilde\\omega(\\vec V)] = (\\$_{\\vec U} \\tilde\\omega)(\\vec V) + (\\tilde\\omega)(\\$_{\\vec U} \\vec V) $$\n",
    "\n",
    "*This is the analog of 6.103.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f41fb1",
   "metadata": {},
   "source": [
    "So we're going to solve for the Lie Derivative. This is going to be a little funky. Treat the part we're going for as G, which means the middle term is $G(V^\\alpha)$. With this, we can start solving.\n",
    "\n",
    "$$ U^\\beta\\nabla_\\beta \\omega_\\alpha(V^\\alpha) - \\omega_\\beta( V^\\beta) \\nabla_\\beta  U^\\alpha = G_\\alpha(V^\\alpha) + \\omega_\\alpha \\left[ U^\\beta \\nabla_\\beta V^\\alpha - V^\\beta \\nabla_\\beta U^\\alpha \\right]  $$\n",
    "\n",
    "The simple and ugly answer is:\n",
    "\n",
    "$$ \\Rightarrow \\left( U^\\beta\\nabla_\\beta \\omega_\\alpha(V^\\alpha) - \\omega_\\beta( V^\\beta) \\nabla_\\beta  U^\\alpha - \\omega_\\alpha \\left[ U^\\beta \\nabla_\\beta V^\\alpha - V^\\beta \\nabla_\\beta U^\\alpha \\right] \\right)/V^\\alpha = G_\\alpha $$\n",
    "\n",
    "Let's at least try to simplify this. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417e09f",
   "metadata": {},
   "source": [
    "$$ \\Rightarrow \\left( U^\\beta\\nabla_\\beta \\omega_\\alpha V^\\alpha - \\omega_\\beta V^\\beta \\nabla_\\beta  U^\\alpha - \\omega_\\alpha U^\\beta \\nabla_\\beta V^\\alpha + \\omega_\\alpha V^\\beta \\nabla_\\beta U^\\alpha \\right)/V^\\alpha = G_\\alpha $$\n",
    "\n",
    "$$ \\Rightarrow \\left( U^\\beta\\nabla_\\beta \\omega_\\alpha V^\\alpha - \\omega_\\alpha U^\\beta \\nabla_\\beta V^\\alpha  \\right)/V^\\alpha = G_\\alpha $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd389b42",
   "metadata": {},
   "source": [
    "Good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df50096e",
   "metadata": {},
   "source": [
    "<a id='latex_pdf_output'></a>\n",
    "\n",
    "# Addendum: Output this notebook to $\\LaTeX$-formatted PDF file \\[Back to [top](#toc)\\]\n",
    "$$\\label{latex_pdf_output}$$\n",
    "\n",
    "The following code cell converts this Jupyter notebook into a proper, clickable $\\LaTeX$-formatted PDF file. After the cell is successfully run, the generated PDF may be found in the root NRPy+ tutorial directory, with filename\n",
    "[GR-06.pdf](GR-06.pdf) (Note that clicking on this link may not work; you may need to open the PDF file through another means.)\n",
    "\n",
    "**Important Note**: Make sure that the file name is right in all six locations, two here in the Markdown, four in the code below. \n",
    "\n",
    "* GR-06.pdf\n",
    "* GR-06.ipynb\n",
    "* GR-06.tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf583ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created GR-06.tex, and compiled LaTeX file to PDF file GR-06.pdf\n"
     ]
    }
   ],
   "source": [
    "import cmdline_helper as cmd    # NRPy+: Multi-platform Python command-line interface\n",
    "cmd.output_Jupyter_notebook_to_LaTeXed_PDF(\"GR-06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0db4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41264965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
